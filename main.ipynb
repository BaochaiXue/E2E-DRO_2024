{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")  # close all previous plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "cache_path: str = \"./cache/exp/\"\n",
    "data_frequency = \"weekly\"\n",
    "start = \"2000-01-01\"\n",
    "end = \"2021-09-30\"  # Data frequency and start/end dates\n",
    "split_ratio_list = [0.6, 0.4]  # Train, validation and test split percentage\n",
    "number_of_observe_per_window: int = 104\n",
    "number_of_asset: int = 20  # Number of assets n_y = 20\n",
    "AV_key: str = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainTest:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        number_of_observation_per_window: int,\n",
    "        split_ratio_list: list[float],\n",
    "    ) -> None:\n",
    "        self.data: pd.DataFrame = data\n",
    "        self.number_of_observation_per_window: int = number_of_observation_per_window\n",
    "        self.split_ratio: list[float] = split_ratio_list\n",
    "\n",
    "        num_total_observations: int = self.data.shape[\n",
    "            0\n",
    "        ]  # Calculate the total number of observations in the DataFrame\n",
    "        num_observations_cumulative_split: list[float] = (\n",
    "            num_total_observations * np.cumsum(split_ratio_list)\n",
    "        )  # np.cumsum([0.7, 0.2, 0.1]) = [0.7, 0.9, 1.0]\n",
    "        self.cumulative_number_window_observation: list[int] = [\n",
    "            round(num_observation_cumulative_split)\n",
    "            for num_observation_cumulative_split in num_observations_cumulative_split\n",
    "        ]\n",
    "\n",
    "    def split_update(self, split_ratio_list: list[float]) -> None:\n",
    "        self.split_ratio: list[float] = split_ratio_list\n",
    "        num_observations_total: int = self.data.shape[0]\n",
    "        num_observations_cumulative_split: list[float] = (\n",
    "            num_observations_total * np.cumsum(split_ratio_list)\n",
    "        )  # np.cumsum([0.7, 0.2, 0.1]) = [0.7, 0.9, 1.0]\n",
    "        self.cumulative_number_window_observation = [\n",
    "            round(i) for i in num_observations_cumulative_split\n",
    "        ]\n",
    "\n",
    "    def train(self) -> pd.DataFrame:\n",
    "        return self.data[\n",
    "            : self.cumulative_number_window_observation[0]\n",
    "        ]  # Return the training subset of observations\n",
    "\n",
    "    def test(self):\n",
    "        if (\n",
    "            self.cumulative_number_window_observation[0]\n",
    "            - self.number_of_observation_per_window\n",
    "            < 0\n",
    "        ):\n",
    "            raise ValueError(\n",
    "                \"The number of observations per window exceeds the number of observations of train data in the dataset.\"\n",
    "            )\n",
    "        return self.data[\n",
    "            self.cumulative_number_window_observation[0]\n",
    "            - self.number_of_observation_per_window : self.cumulative_number_window_observation[\n",
    "                1\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "    def shape(self):\n",
    "        return self.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_original_data: pd.DataFrame = pd.read_pickle(\n",
    "    \"./cache/factor_\" + data_frequency + \".pkl\"\n",
    ")\n",
    "Y_original_data: pd.DataFrame = pd.read_pickle(\n",
    "    \"./cache/asset_\" + data_frequency + \".pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mkt-RF</th>\n",
       "      <th>SMB</th>\n",
       "      <th>HML</th>\n",
       "      <th>RMW</th>\n",
       "      <th>CMA</th>\n",
       "      <th>Mom</th>\n",
       "      <th>ST_Rev</th>\n",
       "      <th>LT_Rev</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-16</th>\n",
       "      <td>-0.011300</td>\n",
       "      <td>0.010800</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>-0.004400</td>\n",
       "      <td>0.004700</td>\n",
       "      <td>-0.003600</td>\n",
       "      <td>0.011300</td>\n",
       "      <td>0.006900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-23</th>\n",
       "      <td>0.020479</td>\n",
       "      <td>0.006256</td>\n",
       "      <td>-0.012969</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>-0.009192</td>\n",
       "      <td>-0.006301</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>-0.010187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-30</th>\n",
       "      <td>0.004586</td>\n",
       "      <td>0.009719</td>\n",
       "      <td>-0.002068</td>\n",
       "      <td>-0.007190</td>\n",
       "      <td>-0.002321</td>\n",
       "      <td>-0.013056</td>\n",
       "      <td>0.005195</td>\n",
       "      <td>-0.002613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-06-06</th>\n",
       "      <td>0.011750</td>\n",
       "      <td>0.006133</td>\n",
       "      <td>0.009694</td>\n",
       "      <td>-0.003210</td>\n",
       "      <td>0.002265</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.011616</td>\n",
       "      <td>-0.000311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-06-13</th>\n",
       "      <td>0.033394</td>\n",
       "      <td>-0.025747</td>\n",
       "      <td>0.005692</td>\n",
       "      <td>0.001865</td>\n",
       "      <td>0.011632</td>\n",
       "      <td>0.009120</td>\n",
       "      <td>0.009935</td>\n",
       "      <td>0.001997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mkt-RF       SMB       HML       RMW       CMA    Mom     \\\n",
       "Date                                                                     \n",
       "1997-05-16 -0.011300  0.010800  0.003700 -0.004400  0.004700 -0.003600   \n",
       "1997-05-23  0.020479  0.006256 -0.012969  0.001595 -0.009192 -0.006301   \n",
       "1997-05-30  0.004586  0.009719 -0.002068 -0.007190 -0.002321 -0.013056   \n",
       "1997-06-06  0.011750  0.006133  0.009694 -0.003210  0.002265  0.003787   \n",
       "1997-06-13  0.033394 -0.025747  0.005692  0.001865  0.011632  0.009120   \n",
       "\n",
       "              ST_Rev    LT_Rev  \n",
       "Date                            \n",
       "1997-05-16  0.011300  0.006900  \n",
       "1997-05-23  0.000178 -0.010187  \n",
       "1997-05-30  0.005195 -0.002613  \n",
       "1997-06-06  0.011616 -0.000311  \n",
       "1997-06-13  0.009935  0.001997  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ticker</th>\n",
       "      <th>AMZN</th>\n",
       "      <th>MSFT</th>\n",
       "      <th>LMT</th>\n",
       "      <th>JNJ</th>\n",
       "      <th>DIS</th>\n",
       "      <th>XOM</th>\n",
       "      <th>MCD</th>\n",
       "      <th>T</th>\n",
       "      <th>CAT</th>\n",
       "      <th>ED</th>\n",
       "      <th>WMT</th>\n",
       "      <th>BAC</th>\n",
       "      <th>COST</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>JPM</th>\n",
       "      <th>NEM</th>\n",
       "      <th>HAL</th>\n",
       "      <th>PFE</th>\n",
       "      <th>VZ</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1997-05-16</th>\n",
       "      <td>-0.117028</td>\n",
       "      <td>-0.014408</td>\n",
       "      <td>-0.004144</td>\n",
       "      <td>-0.020803</td>\n",
       "      <td>-0.024132</td>\n",
       "      <td>-0.012739</td>\n",
       "      <td>-0.004785</td>\n",
       "      <td>0.002183</td>\n",
       "      <td>0.001271</td>\n",
       "      <td>-4.292430e-03</td>\n",
       "      <td>-0.020493</td>\n",
       "      <td>-0.018292</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>-0.028167</td>\n",
       "      <td>-0.036036</td>\n",
       "      <td>-0.026229</td>\n",
       "      <td>-0.008238</td>\n",
       "      <td>-0.017073</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.013394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-23</th>\n",
       "      <td>-0.132527</td>\n",
       "      <td>0.064429</td>\n",
       "      <td>0.033287</td>\n",
       "      <td>-0.006224</td>\n",
       "      <td>0.029366</td>\n",
       "      <td>0.030108</td>\n",
       "      <td>-0.016827</td>\n",
       "      <td>-0.008714</td>\n",
       "      <td>-0.010152</td>\n",
       "      <td>2.220446e-16</td>\n",
       "      <td>0.008368</td>\n",
       "      <td>-0.022774</td>\n",
       "      <td>-0.007783</td>\n",
       "      <td>-0.021737</td>\n",
       "      <td>0.016021</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>0.006645</td>\n",
       "      <td>-0.002482</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-05-30</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009156</td>\n",
       "      <td>0.009683</td>\n",
       "      <td>0.002087</td>\n",
       "      <td>-0.016517</td>\n",
       "      <td>-0.010438</td>\n",
       "      <td>-0.015517</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.001282</td>\n",
       "      <td>4.310934e-03</td>\n",
       "      <td>-0.008299</td>\n",
       "      <td>-0.002119</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>-0.014814</td>\n",
       "      <td>-0.006570</td>\n",
       "      <td>0.022876</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>0.024876</td>\n",
       "      <td>0.016334</td>\n",
       "      <td>-0.026548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-06-06</th>\n",
       "      <td>0.104173</td>\n",
       "      <td>0.000504</td>\n",
       "      <td>-0.006676</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>-0.006107</td>\n",
       "      <td>0.033754</td>\n",
       "      <td>-0.044776</td>\n",
       "      <td>0.008548</td>\n",
       "      <td>0.025608</td>\n",
       "      <td>1.716604e-02</td>\n",
       "      <td>0.050210</td>\n",
       "      <td>0.080264</td>\n",
       "      <td>-0.014815</td>\n",
       "      <td>0.007518</td>\n",
       "      <td>0.062169</td>\n",
       "      <td>-0.038546</td>\n",
       "      <td>0.055105</td>\n",
       "      <td>0.038835</td>\n",
       "      <td>0.046429</td>\n",
       "      <td>0.052273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-06-13</th>\n",
       "      <td>-0.044027</td>\n",
       "      <td>0.044836</td>\n",
       "      <td>0.030914</td>\n",
       "      <td>0.103950</td>\n",
       "      <td>0.026114</td>\n",
       "      <td>0.040817</td>\n",
       "      <td>0.046875</td>\n",
       "      <td>0.027542</td>\n",
       "      <td>0.086142</td>\n",
       "      <td>2.531654e-02</td>\n",
       "      <td>0.019920</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.045113</td>\n",
       "      <td>-0.055973</td>\n",
       "      <td>0.009963</td>\n",
       "      <td>0.043332</td>\n",
       "      <td>-0.024578</td>\n",
       "      <td>0.052570</td>\n",
       "      <td>0.054607</td>\n",
       "      <td>0.099352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ticker          AMZN      MSFT       LMT       JNJ       DIS       XOM  \\\n",
       "Date                                                                     \n",
       "1997-05-16 -0.117028 -0.014408 -0.004144 -0.020803 -0.024132 -0.012739   \n",
       "1997-05-23 -0.132527  0.064429  0.033287 -0.006224  0.029366  0.030108   \n",
       "1997-05-30  0.000000  0.009156  0.009683  0.002087 -0.016517 -0.010438   \n",
       "1997-06-06  0.104173  0.000504 -0.006676  0.002084 -0.006107  0.033754   \n",
       "1997-06-13 -0.044027  0.044836  0.030914  0.103950  0.026114  0.040817   \n",
       "\n",
       "Ticker           MCD         T       CAT            ED       WMT       BAC  \\\n",
       "Date                                                                         \n",
       "1997-05-16 -0.004785  0.002183  0.001271 -4.292430e-03 -0.020493 -0.018292   \n",
       "1997-05-23 -0.016827 -0.008714 -0.010152  2.220446e-16  0.008368 -0.022774   \n",
       "1997-05-30 -0.015517  0.028571  0.001282  4.310934e-03 -0.008299 -0.002119   \n",
       "1997-06-06 -0.044776  0.008548  0.025608  1.716604e-02  0.050210  0.080264   \n",
       "1997-06-13  0.046875  0.027542  0.086142  2.531654e-02  0.019920  0.065217   \n",
       "\n",
       "Ticker          COST      AAPL       JPM       NEM       HAL       PFE  \\\n",
       "Date                                                                     \n",
       "1997-05-16  0.011811 -0.028167 -0.036036 -0.026229 -0.008238 -0.017073   \n",
       "1997-05-23 -0.007783 -0.021737  0.016021  0.030303  0.006645 -0.002482   \n",
       "1997-05-30  0.058824 -0.014814 -0.006570  0.022876  0.021452  0.024876   \n",
       "1997-06-06 -0.014815  0.007518  0.062169 -0.038546  0.055105  0.038835   \n",
       "1997-06-13  0.045113 -0.055973  0.009963  0.043332 -0.024578  0.052570   \n",
       "\n",
       "Ticker            VZ         C  \n",
       "Date                            \n",
       "1997-05-16  0.000000 -0.013394  \n",
       "1997-05-23  0.000000  0.022624  \n",
       "1997-05-30  0.016334 -0.026548  \n",
       "1997-06-06  0.046429  0.052273  \n",
       "1997-06-13  0.054607  0.099352  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def AV(\n",
    "    start: str,\n",
    "    end: str,\n",
    "    split_ratio: list,\n",
    "    data_frequency: str = \"weekly\",\n",
    "    num_observations_per_window: int = 104,\n",
    "    num_assets=None,\n",
    "    use_cache: bool = False,\n",
    "    save_results: bool = False,\n",
    "    AV_key: str = None,\n",
    "):\n",
    "    if use_cache:\n",
    "        X: pd.DataFrame = pd.read_pickle(\"./cache/factor_\" + data_frequency + \".pkl\")\n",
    "        Y: pd.DataFrame = pd.read_pickle(\"./cache/asset_\" + data_frequency + \".pkl\")\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"We cannot download data from AlphaVantage without an API key.\"\n",
    "        )\n",
    "\n",
    "    # Partition dataset into training and testing sets. Lag the data by one observation, since we are predicting future returns, so we don't need the last observation that doesn't have a future return.\n",
    "    # we don't need the first Y observation that doesn't have a corresponding X observation.\n",
    "    return TrainTest(X[:-1], num_observations_per_window, split_ratio), TrainTest(\n",
    "        Y[1:], num_observations_per_window, split_ratio\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1429, 8)\n",
      "(857, 8)\n",
      "(857, 20)\n"
     ]
    }
   ],
   "source": [
    "X_data, Y_data = AV(\n",
    "    start,\n",
    "    end,\n",
    "    split_ratio_list,\n",
    "    data_frequency=data_frequency,\n",
    "    num_observations_per_window=number_of_observe_per_window,\n",
    "    num_assets=number_of_asset,\n",
    "    use_cache=True,\n",
    "    save_results=False,\n",
    "    AV_key=AV_key,\n",
    ")\n",
    "print(X_data.shape())\n",
    "print(X_data.train().shape)\n",
    "print(Y_data.train().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features:  8\n",
      "Number of assets:  20\n"
     ]
    }
   ],
   "source": [
    "# Number of features and assets\n",
    "n_X: int = X_data.train().shape[1]\n",
    "n_Y: int = Y_data.train().shape[1]\n",
    "print(\"Number of features: \", n_X)\n",
    "print(\"Number of assets: \", n_Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Low p-values (< 0.05) suggest that the factor significantly affects the stock returns.\n",
    "High p-values (> 0.05) suggest that the factor's effect on the stock returns is not statistically significant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Mkt-RF   SMB   HML   RMW   CMA  Mom     ST_Rev  LT_Rev\n",
      "Ticker                                                        \n",
      "AMZN      0.20  0.03  0.60  0.30  0.22    0.36    0.24    0.28\n",
      "MSFT      0.36  0.37  0.81  0.53  0.05    0.28    0.74    0.46\n",
      "LMT       0.49  0.80  0.05  0.03  0.93    0.40    0.34    0.49\n",
      "JNJ       0.00  0.44  0.06  0.09  0.22    0.95    0.24    0.45\n",
      "DIS       0.64  0.95  0.82  0.05  0.85    0.49    0.37    0.10\n",
      "XOM       0.00  0.09  0.57  0.34  0.08    0.08    0.37    0.24\n",
      "MCD       0.81  0.07  0.64  0.01  0.61    0.37    0.64    0.02\n",
      "T         0.66  0.28  0.01  0.83  0.02    0.35    0.87    0.00\n",
      "CAT       0.87  0.35  0.50  0.33  0.23    0.57    0.55    0.35\n",
      "ED        0.18  0.83  0.49  0.00  0.58    0.97    0.55    0.35\n",
      "WMT       0.00  0.19  0.09  0.00  0.09    0.81    0.15    0.23\n",
      "BAC       0.22  0.43  0.03  0.23  0.81    0.25    0.26    0.09\n",
      "COST      0.00  0.25  0.88  0.00  0.40    0.77    0.86    0.10\n",
      "AAPL      0.37  0.61  0.56  0.92  0.72    0.37    0.15    0.68\n",
      "JPM       0.19  0.97  0.00  0.49  0.33    0.18    0.59    0.01\n",
      "NEM       0.09  0.07  0.11  0.01  0.51    0.06    0.28    0.55\n",
      "HAL       0.30  0.78  0.69  0.18  0.06    0.53    0.85    0.08\n",
      "PFE       0.01  0.43  0.34  0.74  0.41    0.95    0.99    0.40\n",
      "VZ        0.47  0.73  0.01  0.10  0.22    0.13    0.30    0.01\n",
      "C         0.18  0.99  0.03  0.04  0.23    0.06    0.05    0.23\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "def statanalysis(X: pd.DataFrame, Y: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Initialize an empty DataFrame to store p-values\n",
    "    # Rows correspond to assets (Y.columns) and columns correspond to features (X.columns)\n",
    "    stats = pd.DataFrame(\n",
    "        columns=X.columns, index=Y.columns\n",
    "    )  # Create an empty DataFrame to store the p-values\n",
    "    for ticker in Y.columns:\n",
    "        for feature in X.columns:\n",
    "            stats.loc[ticker, feature] = (\n",
    "                sm.OLS(Y[ticker].values, sm.add_constant(X[feature]).values)\n",
    "                .fit()\n",
    "                .pvalues[1]  # Get the p-value of the feature\n",
    "            )\n",
    "\n",
    "    return stats.astype(float).round(2)\n",
    "\n",
    "\n",
    "statistical_analysis: pd.DataFrame = statanalysis(X_data.train(), Y_data.train())\n",
    "print(statistical_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cvxpy as cp\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class SlidingWindow(Dataset):\n",
    "    \"\"\"Sliding window dataset constructor for time series data.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        XData: pd.DataFrame,\n",
    "        YData: pd.DataFrame,\n",
    "        num_observations: int,\n",
    "        performance_window: int,\n",
    "    ) -> None:\n",
    "        # Convert the feature DataFrame to a PyTorch tensor with double precision\n",
    "        self.X: torch.Tensor = torch.tensor(XData.values, dtype=torch.float64)\n",
    "        # Convert the asset return DataFrame to a PyTorch tensor with double precision\n",
    "        self.Y: torch.Tensor = torch.tensor(YData.values, dtype=torch.float64)\n",
    "        # Store the number of observations (scenarios) in the sliding window\n",
    "        self.num_observations: int = num_observations\n",
    "        # Store the number of scenarios in the performance window\n",
    "        self.perf_period: int = performance_window\n",
    "\n",
    "    def __getitem__(\n",
    "        self, index: int\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n",
    "        # Extract the feature window starting at 'index' and spanning 'n_obs + 1' time steps\n",
    "        x: torch.Tensor = self.X[index : index + self.num_observations + 1]\n",
    "        # Extract the realizations window starting at 'index' and spanning 'n_obs' time steps\n",
    "        y: torch.Tensor = self.Y[index : index + self.num_observations]\n",
    "        # Extract the performance window starting after the observations window and spanning 'perf_period + 1' time steps\n",
    "        y_future_performance: torch.Tensor = self.Y[\n",
    "            index\n",
    "            + self.num_observations : index\n",
    "            + self.num_observations\n",
    "            + self.perf_period\n",
    "            + 1\n",
    "        ]\n",
    "        # Return the extracted windows as a tuple\n",
    "        return x, y, y_future_performance\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        # Calculate the effective length by subtracting the window sizes from the total data length\n",
    "        total_length: int = len(self.X) - self.num_observations - self.perf_period\n",
    "        # Return the calculated length\n",
    "        return total_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackTest:\n",
    "    \"\"\"Backtest object to store out-of-sample results.\"\"\"\n",
    "\n",
    "    def __init__(self, len_test: int, n_y: int, dates: pd.DatetimeIndex) -> None:\n",
    "        # Initialize the weights array with zeros; dimensions are (len_test, n_y)\n",
    "        self.weights: np.ndarray = np.zeros((len_test, n_y))\n",
    "        # Initialize the returns array with zeros; length is len_test\n",
    "        self.rets: np.ndarray = np.zeros(len_test)\n",
    "        # Store the dates corresponding to the out-of-sample period\n",
    "        self.dates: pd.DatetimeIndex = pd.DatetimeIndex(dates[-len_test:])\n",
    "\n",
    "    def stats(self) -> None:\n",
    "        # Calculate the cumulative product of returns plus one to get the total return index\n",
    "        tri: np.ndarray = np.cumprod(self.rets + 1)\n",
    "        # Calculate the geometric mean return over the out-of-sample period\n",
    "        self.mean: float = (tri[-1]) ** (1 / len(tri)) - 1\n",
    "        # Calculate the volatility (standard deviation) of the returns\n",
    "        self.vol: float = np.std(self.rets)\n",
    "        # Calculate the pseudo-Sharpe ratio, handling division by zero\n",
    "        self.sharpe: float = self.mean / self.vol if self.vol != 0 else np.nan\n",
    "        # Create a DataFrame with dates, realized returns, and total return index\n",
    "        self.returns = pd.DataFrame({\"Date\": self.dates, \"rets\": self.rets, \"tri\": tri})\n",
    "        # Set the 'Date' column as the index of the DataFrame\n",
    "        self.returns = self.returns.set_index(\"Date\")\n",
    "\n",
    "    def plot_cumulative_returns(\n",
    "        self,\n",
    "        figsize: tuple = (12, 6),\n",
    "        resample_freq: str | None = None,\n",
    "        title: str | None = None,\n",
    "    ) -> None:\n",
    "        if self.returns is None:\n",
    "            raise ValueError(\n",
    "                \"Returns DataFrame not initialized. Run 'compute_stats' after populating 'rets' and 'weights'.\"\n",
    "            )\n",
    "\n",
    "        data_to_plot = self.returns[\"tri\"]\n",
    "        label = \"Cumulative Return\"\n",
    "\n",
    "        if resample_freq:\n",
    "            # Resample the cumulative return\n",
    "            # For cumulative returns, resampling can be tricky. We'll resample the returns first,\n",
    "            # then compute cumulative returns on the resampled data.\n",
    "            resampled_rets = (\n",
    "                self.returns[\"rets\"]\n",
    "                .resample(resample_freq)\n",
    "                .apply(lambda x: (x + 1).prod() - 1)\n",
    "            )\n",
    "            data_to_plot = (resampled_rets + 1).cumprod()\n",
    "            label = f\"Cumulative Return ({resample_freq})\"\n",
    "\n",
    "        plt.figure(figsize=figsize)\n",
    "        plt.plot(data_to_plot, label=label, color=\"blue\")\n",
    "        plt.title(title if title else \"Cumulative Return Over Time\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Cumulative Return\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()  # Adjust layout to prevent clipping of labels\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "import cvxpy as cp\n",
    "from cvxpylayers.torch import CvxpyLayer\n",
    "\n",
    "\n",
    "# Define the Sharpe loss function\n",
    "def sharpe_loss(z_star: torch.Tensor, y_perf: torch.Tensor) -> torch.Tensor:\n",
    "    loss = -torch.mean(y_perf @ z_star) / torch.std(y_perf @ z_star)\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Define the portfolio variance risk function\n",
    "def p_var(z: cp.Variable, c: cp.Variable, x: cp.Expression) -> cp.Expression:\n",
    "    return cp.square(x @ z - c)\n",
    "\n",
    "\n",
    "# Define the Hellinger distance-based DRO optimization layer\n",
    "def hellinger(num_assets: int, num_observations: int, prisk) -> CvxpyLayer:\n",
    "    # Define decision variables\n",
    "    z = cp.Variable((num_assets, 1), nonneg=True)  # Portfolio weights\n",
    "    c_aux = cp.Variable()  # Centering parameter\n",
    "    lambda_aux = cp.Variable(nonneg=True)\n",
    "    xi_aux = cp.Variable()\n",
    "    beta_aux = cp.Variable(num_observations, nonneg=True)\n",
    "    tau_aux = cp.Variable(num_observations, nonneg=True)\n",
    "    mu_aux = cp.Variable()\n",
    "\n",
    "    # Define parameters\n",
    "    ep = cp.Parameter((num_observations, num_assets))  # Residuals matrix\n",
    "    y_hat = cp.Parameter(num_assets)  # Predicted returns\n",
    "    gamma = cp.Parameter(nonneg=True)  # Risk-return trade-off parameter\n",
    "    delta = cp.Parameter(nonneg=True)  # Ambiguity size parameter\n",
    "\n",
    "    # Define constraints\n",
    "    constraints = [\n",
    "        cp.sum(z) == 1,  # Total budget constraint\n",
    "        mu_aux == y_hat @ z,  # Expected return constraint\n",
    "    ]\n",
    "    for i in range(num_observations):\n",
    "        # Constraints based on the risk function\n",
    "        constraints += [xi_aux + lambda_aux >= prisk(z, c_aux, ep[i, :]) + tau_aux[i]]\n",
    "        constraints += [\n",
    "            beta_aux[i] >= cp.quad_over_lin(lambda_aux, tau_aux[i])\n",
    "        ]  # Constraint on the ambiguity set\n",
    "\n",
    "    # Define the objective function\n",
    "    objective = cp.Minimize(\n",
    "        xi_aux\n",
    "        + (delta - 1) * lambda_aux\n",
    "        + (1 / num_observations) * cp.sum(beta_aux)\n",
    "        - gamma * mu_aux\n",
    "    )\n",
    "\n",
    "    # Define the problem\n",
    "    problem = cp.Problem(objective, constraints)\n",
    "\n",
    "    # Create a CVXPY layer\n",
    "    cvxpylayer = CvxpyLayer(\n",
    "        problem, parameters=[ep, y_hat, gamma, delta], variables=[z]\n",
    "    )\n",
    "\n",
    "    return cvxpylayer\n",
    "\n",
    "\n",
    "# Define mappings for performance loss functions, risk functions, and optimization layers\n",
    "perf_loss_functions = {\n",
    "    \"sharpe_loss\": sharpe_loss,\n",
    "    # Add other performance loss functions here if needed\n",
    "}\n",
    "\n",
    "risk_functions = {\n",
    "    \"p_var\": p_var,\n",
    "    # Add other risk functions here if needed\n",
    "}\n",
    "\n",
    "opt_layer_functions = {\n",
    "    \"hellinger\": hellinger,\n",
    "    # Add other optimization layer functions here if needed\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def compute_annualized_sharpe_ratio(\n",
    "    returns: pd.Series | np.ndarray,\n",
    "    risk_free_rate: float = 0.02,\n",
    "    periods_per_year: int = 52,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the annualized Sharpe Ratio.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.Series | np.ndarray): Periodic returns of the portfolio.\n",
    "        risk_free_rate (float, optional): Annual risk-free rate (e.g., 0.02 for 2%). Defaults to 0.02.\n",
    "        periods_per_year (int, optional): Number of return periods in a year (e.g., 52 for weekly). Defaults to 52.\n",
    "\n",
    "    Returns:\n",
    "        float: Annualized Sharpe Ratio.\n",
    "    \"\"\"\n",
    "    if isinstance(returns, pd.Series):\n",
    "        returns = returns.dropna().values\n",
    "    else:\n",
    "        returns = np.array(returns)\n",
    "        returns = returns[~np.isnan(returns)]\n",
    "\n",
    "    if len(returns) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate excess returns by subtracting the per-period risk-free rate\n",
    "    excess_returns = returns - (risk_free_rate / periods_per_year)\n",
    "\n",
    "    # Calculate mean and standard deviation of excess returns\n",
    "    mean_excess_return = np.mean(excess_returns) * periods_per_year  # Annualize mean\n",
    "    std_excess_return = np.std(excess_returns, ddof=1) * np.sqrt(\n",
    "        periods_per_year\n",
    "    )  # Annualize std\n",
    "\n",
    "    # Compute Sharpe Ratio with numerical stability\n",
    "    sharpe_ratio = mean_excess_return / (\n",
    "        std_excess_return + 1e-18\n",
    "    )  # Add epsilon to prevent division by zero\n",
    "\n",
    "    return sharpe_ratio\n",
    "\n",
    "\n",
    "def analyze_returns(\n",
    "    returns: pd.DataFrame, risk_free_rate: float = 0.02, frequency: int = 52\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze the returns DataFrame to verify date index, count total weeks,\n",
    "    identify years covered, count weeks per year, and compute Sharpe Ratio per year.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame containing portfolio returns with a DatetimeIndex.\n",
    "        risk_free_rate (float, optional): Annual risk-free rate (default is 2%). Defaults to 0.02.\n",
    "        frequency (int, optional): Number of periods per year (default is 52 for weekly data). Defaults to 52.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary containing analysis results.\n",
    "    \"\"\"\n",
    "    analysis_results: Dict[str, Any] = {}\n",
    "\n",
    "    # 1. Verify that the DataFrame is indexed by dates\n",
    "    if not isinstance(returns.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"The DataFrame index must be a pandas DatetimeIndex.\")\n",
    "    analysis_results[\"DateIndexValid\"] = True\n",
    "\n",
    "    # 2. Count the total number of weeks\n",
    "    total_weeks: int = len(returns)\n",
    "    analysis_results[\"TotalWeeks\"] = total_weeks\n",
    "\n",
    "    # 3. Identify all the years covered in the dataset\n",
    "    years: list[int] = returns.index.year.unique().tolist()\n",
    "    years.sort()  # Sort the years in ascending order\n",
    "    analysis_results[\"YearsCovered\"] = years\n",
    "\n",
    "    # 4. Count the number of weeks for each individual year\n",
    "    weeks_per_year: Dict[int, int] = {}\n",
    "    grouped = returns.groupby(returns.index.year)\n",
    "\n",
    "    for year, group in grouped:\n",
    "        weeks_count = len(group)\n",
    "        weeks_per_year[year] = weeks_count\n",
    "\n",
    "    analysis_results[\"WeeksPerYear\"] = weeks_per_year\n",
    "\n",
    "    # 5. Compute Sharpe Ratio for each year\n",
    "    sharpe_ratios_per_year: Dict[int, float] = {}\n",
    "    for year, group in grouped:\n",
    "        sharpe = compute_annualized_sharpe_ratio(\n",
    "            returns=group[\"rets\"],\n",
    "            risk_free_rate=risk_free_rate,\n",
    "            periods_per_year=analysis_results[\"WeeksPerYear\"][year],\n",
    "        )\n",
    "        sharpe_ratios_per_year[year] = sharpe\n",
    "\n",
    "    analysis_results[\"SharpeRatiosPerYear\"] = sharpe_ratios_per_year\n",
    "\n",
    "    return analysis_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class E2E_net(nn.Module):\n",
    "    \"\"\"End-to-end Distributionally Robust Optimization (DRO) learning neural net module.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_features: int,\n",
    "        num_assets: int,\n",
    "        num_observations: int,\n",
    "        optimization_layer: str = \"hellinger\",\n",
    "        prisk: str = \"p_var\",\n",
    "        performance_objective: str = \"sharpe_loss\",\n",
    "        pred_model: str = \"3layer\",\n",
    "        prediction_loss_factor: float | None = 0.5,\n",
    "        performance_period: int = 13,\n",
    "        train_pred: bool = True,\n",
    "        train_gamma: bool = True,\n",
    "        train_delta: bool = True,\n",
    "        set_seed: int | None = None,\n",
    "        cache_path: str = \"./cache/\",\n",
    "        model_name: str = \"E2E_net_Eps_Control\",\n",
    "    ) -> None:\n",
    "        super(E2E_net, self).__init__()\n",
    "\n",
    "        # Set random seed for reproducibility\n",
    "        if set_seed is not None:\n",
    "            torch.manual_seed(set_seed)\n",
    "            self.seed: int = set_seed\n",
    "\n",
    "        self.num_features: int = num_input_features  # Number of input features\n",
    "        self.num_assets: int = num_assets  # Number of assets\n",
    "        self.num_observations: int = (\n",
    "            num_observations  # Number of observations/scenarios\n",
    "        )\n",
    "\n",
    "        # Prediction loss function\n",
    "        if prediction_loss_factor is not None:\n",
    "            self.pred_loss_factor: float = prediction_loss_factor\n",
    "            self.pred_loss = nn.MSELoss()  # Mean squared error loss\n",
    "        else:\n",
    "            self.pred_loss = None\n",
    "\n",
    "        # Performance loss function\n",
    "        if performance_objective in perf_loss_functions:\n",
    "            self.perf_loss = perf_loss_functions[performance_objective]\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown perf_loss function: {performance_objective}\")\n",
    "\n",
    "        self.perf_period: int = performance_period\n",
    "\n",
    "        # Initialize gamma parameter\n",
    "        self.gamma: nn.Parameter = nn.Parameter(\n",
    "            torch.FloatTensor(1).uniform_(0.02, 0.1)\n",
    "        )\n",
    "        self.gamma.requires_grad = train_gamma\n",
    "        self.gamma_init: float = self.gamma.item()\n",
    "\n",
    "        ub: float = (1 - 1 / (num_observations**0.5)) / 2\n",
    "        lb: float = (1 - 1 / (num_observations**0.5)) / 10\n",
    "        self.delta: nn.Parameter = nn.Parameter(torch.FloatTensor(1).uniform_(lb, ub))\n",
    "        self.delta.requires_grad = train_delta\n",
    "        self.delta_init: float = self.delta.item()\n",
    "        self.model_type = \"dro\"\n",
    "\n",
    "        self.pred_model: str = pred_model\n",
    "\n",
    "        if pred_model == \"2layer\":\n",
    "            hidden_size = int(0.5 * (num_input_features + num_assets))\n",
    "            self.pred_layer = nn.Sequential(\n",
    "                nn.Linear(num_input_features, hidden_size),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size, num_assets),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(num_assets, num_assets),\n",
    "            )\n",
    "        elif pred_model == \"3layer\":\n",
    "            hidden_size1 = int(0.5 * (num_input_features + num_assets))\n",
    "            hidden_size2 = int(0.6 * (num_input_features + num_assets))\n",
    "            self.pred_layer = nn.Sequential(\n",
    "                nn.Linear(num_input_features, hidden_size1),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size1, hidden_size2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(hidden_size2, num_assets),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(num_assets, num_assets),\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown pred_model type: {pred_model}\")\n",
    "\n",
    "        # Define the optimization layer\n",
    "        if optimization_layer in opt_layer_functions:\n",
    "            if prisk in risk_functions:\n",
    "                self.opt_layer = opt_layer_functions[optimization_layer](\n",
    "                    num_assets, num_observations, risk_functions[prisk]\n",
    "                )\n",
    "            else:\n",
    "                raise ValueError(f\"Unknown prisk function: {prisk}\")\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown opt_layer function: {optimization_layer}\")\n",
    "\n",
    "        self.cache_path: str = cache_path\n",
    "        self.model_name: str = model_name\n",
    "\n",
    "    def forward(\n",
    "        self, X: torch.Tensor, Y: torch.Tensor\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        # Generate predictions for each time step in X\n",
    "        Y_hat: torch.Tensor = self.pred_layer(X)  # Shape: (n_obs + 1, n_y)\n",
    "        # Calculate residuals\n",
    "        ep: torch.Tensor = Y - Y_hat[:-1]  # Shape: (n_obs, n_y)\n",
    "        # Extract the last prediction\n",
    "        y_hat: torch.Tensor = Y_hat[-1]  # Shape: (n_y,)\n",
    "\n",
    "        # Solver arguments\n",
    "        solver_args: Dict[str, Any] = {\n",
    "            \"solve_method\": \"ECOS\",\n",
    "            \"max_iters\": 120,\n",
    "            \"abstol\": 1e-7,\n",
    "        }\n",
    "\n",
    "        # Optimize z_star\n",
    "        z_star: torch.Tensor\n",
    "        (z_star,) = self.opt_layer(\n",
    "            ep, y_hat, self.gamma, self.delta, solver_args=solver_args\n",
    "        )\n",
    "\n",
    "        return z_star, y_hat\n",
    "\n",
    "    def net_train(\n",
    "        self,\n",
    "        train_set: DataLoader,\n",
    "        val_set: DataLoader | None = None,\n",
    "        epochs: int | None = None,\n",
    "        lr: float | None = None,\n",
    "    ) -> float | None:\n",
    "        # Assign number of epochs and learning rate\n",
    "        if epochs is None:\n",
    "            epochs = self.epochs\n",
    "        if lr is None:\n",
    "            lr = self.lr\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "        n_train: int = len(train_set)\n",
    "        self.train()\n",
    "        for epoch in range(epochs):\n",
    "            train_loss: float = 0.0\n",
    "            optimizer.zero_grad()\n",
    "            for _, (x, y, y_perf) in enumerate(train_set):\n",
    "                # Move tensors to the same device as the model\n",
    "                x = x.to(next(self.parameters()).device)\n",
    "                y = y.to(next(self.parameters()).device)\n",
    "                y_perf = y_perf.to(next(self.parameters()).device)\n",
    "\n",
    "                # Forward pass\n",
    "                z_star, y_hat = self(x.squeeze(), y.squeeze())\n",
    "\n",
    "                # Compute loss\n",
    "                if self.pred_loss is None:\n",
    "                    loss = (1 / n_train) * self.perf_loss(z_star, y_perf.squeeze())\n",
    "                else:\n",
    "                    loss = (1 / n_train) * (\n",
    "                        self.perf_loss(z_star, y_perf.squeeze())\n",
    "                        + (self.pred_loss_factor / self.num_assets)\n",
    "                        * self.pred_loss(y_hat, y_perf.squeeze()[0])\n",
    "                    )\n",
    "\n",
    "                # Backward pass\n",
    "                loss.backward()\n",
    "\n",
    "                # Accumulate loss\n",
    "                train_loss += loss.item()\n",
    "\n",
    "            # Update parameters\n",
    "            optimizer.step()\n",
    "            print(f\"Epoch {epoch+1}/{epochs}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "            # Ensure gamma and delta remain positive\n",
    "            for name, param in self.named_parameters():\n",
    "                if name == \"gamma\":\n",
    "                    param.data.clamp_(min=0.0001)\n",
    "\n",
    "        # Validation\n",
    "        if val_set is not None:\n",
    "            n_val: int = len(val_set)\n",
    "            val_loss: float = 0.0\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                for t, (x, y, y_perf) in enumerate(val_set):\n",
    "                    # Forward pass\n",
    "                    z_val, y_val = self(x.squeeze(), y.squeeze())\n",
    "\n",
    "                    # Compute loss\n",
    "                    if self.pred_loss is None:\n",
    "                        loss = (1 / n_val) * self.perf_loss(z_val, y_perf.squeeze())\n",
    "                    else:\n",
    "                        loss = (1 / n_val) * (\n",
    "                            self.perf_loss(z_val, y_perf.squeeze())\n",
    "                            + (self.pred_loss_factor / self.num_assets)\n",
    "                            * self.pred_loss(y_val, y_perf.squeeze()[0])\n",
    "                        )\n",
    "\n",
    "                    # Accumulate validation loss\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            return val_loss\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # net_roll_test: Test the e2e neural net\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    def net_roll_test(\n",
    "        self,\n",
    "        X: TrainTest,\n",
    "        Y: TrainTest,\n",
    "        n_roll: int,\n",
    "        lr: float,\n",
    "        epochs: list[int] = [100, 100, 100, 100],\n",
    "        load_state: list[bool] = [False, False, False, False],\n",
    "        save_state: list[bool] = [False, False, False, False],\n",
    "    ) -> None:\n",
    "        # Initialize backtest object\n",
    "        portfolio = BackTest(\n",
    "            len(Y.test()) - Y.number_of_observation_per_window,\n",
    "            self.num_assets,\n",
    "            Y.test().index[Y.number_of_observation_per_window :],\n",
    "        )\n",
    "\n",
    "        # Initialize lists to store trained parameters\n",
    "        self.gamma_trained = []\n",
    "        self.delta_trained = []\n",
    "\n",
    "        # Store initial split\n",
    "        init_split = Y.split_ratio\n",
    "\n",
    "        # Calculate window size\n",
    "        win_size = init_split[1] / n_roll\n",
    "\n",
    "        split = [0, 0]\n",
    "        t = 0\n",
    "        for i in range(n_roll):\n",
    "\n",
    "            print(f\"Out-of-sample window: {i+1} / {n_roll}\")\n",
    "\n",
    "            split[0] = init_split[0] + win_size * i\n",
    "            if i < n_roll - 1:\n",
    "                split[1] = win_size\n",
    "            else:\n",
    "                split[1] = 1 - split[0]\n",
    "\n",
    "            X.split_update(split)\n",
    "            Y.split_update(split)\n",
    "            train_set = DataLoader(\n",
    "                SlidingWindow(\n",
    "                    X.train(), Y.train(), self.num_observations, self.perf_period\n",
    "                )\n",
    "            )\n",
    "            test_set = DataLoader(\n",
    "                SlidingWindow(X.test(), Y.test(), self.num_observations, 0)\n",
    "            )\n",
    "            if load_state[i]:\n",
    "                # Reset model parameters to initial state\n",
    "                self.load_state_dict(\n",
    "                    torch.load(\n",
    "                        self.cache_path + self.model_name + \"_\" + str(i) + \".pt\",\n",
    "                        weights_only=True,\n",
    "                    )\n",
    "                )\n",
    "                print(f\"Loaded model state from {self.model_name}_{i}.pt\")\n",
    "            # Train the model\n",
    "            self.train()\n",
    "            self.net_train(train_set, lr=lr, epochs=epochs[i])\n",
    "            # Save the trained model\n",
    "            if save_state[i]:\n",
    "                torch.save(\n",
    "                    self.state_dict(),\n",
    "                    self.cache_path + self.model_name + \"_\" + str(i) + \".pt\",\n",
    "                )\n",
    "                print(f\"Saved model state to {self.model_name}_{i}.pt\")\n",
    "            self.gamma_trained.append(self.gamma.item())\n",
    "            self.delta_trained.append(self.delta.item())\n",
    "            # Test the model\n",
    "            self.eval()\n",
    "            with torch.no_grad():\n",
    "                for __, (x, y, y_perf) in enumerate(test_set):\n",
    "                    # Move tensors to the same device as the model\n",
    "                    x = x.to(next(self.parameters()).device)\n",
    "                    y = y.to(next(self.parameters()).device)\n",
    "                    y_perf = y_perf.to(next(self.parameters()).device)\n",
    "\n",
    "                    z_star, _ = self(x.squeeze(), y.squeeze())\n",
    "                    if not np.isclose(torch.sum(z_star).cpu().numpy(), 1.0, atol=1e-2):\n",
    "                        print(z_star)\n",
    "\n",
    "                    portfolio.weights[t] = z_star.squeeze().cpu().numpy()\n",
    "                    portfolio.rets[t] = (\n",
    "                        y_perf.squeeze().cpu().numpy() @ portfolio.weights[t]\n",
    "                    ).item()\n",
    "                    t += 1\n",
    "\n",
    "        # Reset dataset splits\n",
    "        X.split_update(init_split)\n",
    "        Y.split_update(init_split)\n",
    "\n",
    "        # Calculate portfolio statistics\n",
    "        portfolio.stats()\n",
    "        self.portfolio = portfolio\n",
    "\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    # load_cv_results: Load cross-validation results\n",
    "    # -----------------------------------------------------------------------------------------------\n",
    "    def load_cv_results(self, cv_results):\n",
    "        self.cv_results = cv_results\n",
    "\n",
    "        # Select and store the optimal hyperparameters\n",
    "        idx = cv_results.val_loss.idxmin()\n",
    "        self.lr = cv_results.lr[idx]\n",
    "        self.epochs = cv_results.epochs[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_16008\\3624931760.py:90: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  factor_5 = pdr.get_data_famafrench(\n",
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_16008\\3624931760.py:99: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  mom_df = pdr.get_data_famafrench(\n",
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_16008\\3624931760.py:106: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  st_df = pdr.get_data_famafrench(\n",
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_16008\\3624931760.py:113: FutureWarning: The argument 'date_parser' is deprecated and will be removed in a future version. Please use 'date_format' instead, or read your data in as 'object' dtype and then call 'to_datetime'.\n",
      "  lt_df = pdr.get_data_famafrench(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6888, 8) (6888, 20)\n",
      "(6198, 8) (6198, 20) (793, 8) (793, 20)\n",
      "            Mkt-RF     SMB     HML     RMW     CMA  Mom     ST_Rev  LT_Rev\n",
      "Date                                                                      \n",
      "1997-05-16 -0.0113  0.0108  0.0037 -0.0044  0.0047 -0.0036  0.0113  0.0069\n",
      "1997-05-19  0.0027 -0.0004 -0.0028 -0.0001  0.0006  0.0024  0.0016  0.0000\n",
      "1997-05-20  0.0091 -0.0055 -0.0021  0.0030 -0.0079 -0.0001 -0.0050 -0.0078\n",
      "1997-05-21 -0.0013  0.0073 -0.0073 -0.0013 -0.0006 -0.0056  0.0022  0.0010\n",
      "1997-05-22 -0.0027  0.0064  0.0041 -0.0008  0.0008 -0.0011  0.0029  0.0005             Mkt-RF     SMB     HML     RMW     CMA  Mom     ST_Rev  LT_Rev\n",
      "Date                                                                      \n",
      "2024-09-23  0.0021 -0.0083 -0.0008  0.0045 -0.0023 -0.0062 -0.0013 -0.0015\n",
      "2024-09-24  0.0024 -0.0010 -0.0058 -0.0030  0.0078  0.0003  0.0031 -0.0037\n",
      "2024-09-25 -0.0029 -0.0093 -0.0070 -0.0004  0.0015  0.0100 -0.0003 -0.0028\n",
      "2024-09-26  0.0042  0.0023  0.0043 -0.0053  0.0053 -0.0065  0.0042  0.0060\n",
      "2024-09-27 -0.0008  0.0071  0.0055  0.0009 -0.0007 -0.0166  0.0056  0.0017\n",
      "Ticker           JPM       JNJ         C       MCD         T       LMT  \\\n",
      "Date                                                                     \n",
      "1997-05-19 -0.010681  0.016597  0.009049  0.002404  0.002179  0.016644   \n",
      "1997-05-20  0.041836 -0.006122  0.033632 -0.016786  0.006522  0.013642   \n",
      "1997-05-21 -0.034975 -0.024641 -0.030369 -0.007317 -0.017279  0.008075   \n",
      "1997-05-22  0.016107  0.002105 -0.006711  0.000000 -0.017582  0.005341   \n",
      "1997-05-23  0.005284  0.006303  0.018018  0.004914  0.017897 -0.010624   \n",
      "\n",
      "Ticker            VZ      COST       WMT       HAL       DIS       XOM  \\\n",
      "Date                                                                     \n",
      "1997-05-19  0.000000  0.038910  0.020920 -0.009967  0.029367  0.017204   \n",
      "1997-05-20  0.000000  0.029963  0.000000  0.006711  0.003003  0.000000   \n",
      "1997-05-21 -0.001815 -0.040000 -0.016394  0.008333 -0.016467  0.006342   \n",
      "1997-05-22 -0.014546 -0.020833 -0.008333  0.001653  0.000000 -0.016806   \n",
      "1997-05-23  0.016605 -0.013540  0.012605  0.000000  0.013699  0.023505   \n",
      "\n",
      "Ticker           BAC      AMZN      MSFT       CAT       NEM      AAPL  \\\n",
      "Date                                                                     \n",
      "1997-05-19 -0.016563 -0.012040 -0.002707 -0.005076  0.016835 -0.014492   \n",
      "1997-05-20  0.012632 -0.042685  0.034744 -0.010204  0.003311  0.014705   \n",
      "1997-05-21 -0.027028 -0.127392  0.010494 -0.002577 -0.003300 -0.021738   \n",
      "1997-05-22  0.000000 -0.021891  0.002077  0.007752  0.000000 -0.014814   \n",
      "1997-05-23  0.008548  0.074622  0.018653  0.000000  0.013245  0.015036   \n",
      "\n",
      "Ticker            ED       PFE  \n",
      "Date                            \n",
      "1997-05-19  0.012931 -0.003722  \n",
      "1997-05-20  0.000000  0.004982  \n",
      "1997-05-21 -0.008511 -0.006196  \n",
      "1997-05-22 -0.017167 -0.008729  \n",
      "1997-05-23  0.013100  0.011321   Ticker           JPM       JNJ         C       MCD         T       LMT  \\\n",
      "Date                                                                     \n",
      "2024-09-24  0.000709 -0.002696 -0.019335  0.004046  0.004653 -0.003239   \n",
      "2024-09-25 -0.006617 -0.013392 -0.016132  0.000666 -0.001390 -0.001192   \n",
      "2024-09-26 -0.001951  0.004919  0.022027  0.010583  0.004174 -0.000934   \n",
      "2024-09-27  0.003432  0.000062  0.002593  0.000132  0.011547  0.008590   \n",
      "2024-09-30  0.001710  0.004089  0.011799  0.002700  0.004566  0.003778   \n",
      "\n",
      "Ticker            VZ      COST       WMT       HAL       DIS       XOM  \\\n",
      "Date                                                                     \n",
      "2024-09-24  0.009038 -0.016945  0.004232  0.000668  0.007744 -0.002641   \n",
      "2024-09-25 -0.002463  0.007631  0.009049 -0.036703  0.002455 -0.019479   \n",
      "2024-09-26  0.001571 -0.007684 -0.018182 -0.036716  0.013629 -0.017165   \n",
      "2024-09-27  0.006051 -0.017550 -0.001752  0.030205  0.008508  0.026773   \n",
      "2024-09-30  0.000446  0.001016  0.012158  0.013962  0.001875  0.012088   \n",
      "\n",
      "Ticker           BAC      AMZN      MSFT       CAT       NEM      AAPL  \\\n",
      "Date                                                                     \n",
      "2024-09-24 -0.010534  0.000413 -0.010011  0.039766  0.025147  0.003974   \n",
      "2024-09-25 -0.005070 -0.007373  0.006850 -0.019900 -0.010564 -0.004398   \n",
      "2024-09-26  0.006879 -0.007116 -0.001851  0.033602  0.004886  0.005080   \n",
      "2024-09-27 -0.003036 -0.016688 -0.007628  0.000307 -0.029353  0.001187   \n",
      "2024-09-30  0.007107 -0.008725  0.005327  0.000102 -0.008349  0.022872   \n",
      "\n",
      "Ticker            ED       PFE  \n",
      "Date                            \n",
      "2024-09-24 -0.011536  0.006482  \n",
      "2024-09-25  0.003307 -0.019322  \n",
      "2024-09-26 -0.000388  0.001383  \n",
      "2024-09-27  0.009019  0.004142  \n",
      "2024-09-30  0.000769 -0.005156  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import List, Optional, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pandas_datareader import data as pdr\n",
    "\n",
    "# Assuming TrainTest is defined elsewhere in your codebase\n",
    "# from your_module import TrainTest\n",
    "\n",
    "\n",
    "def AV_yFinance(\n",
    "    start: str,\n",
    "    end: str,\n",
    "    split: List[float],\n",
    "    freq: str = \"weekly\",\n",
    "    n_obs: int = 104,\n",
    "    n_y: Optional[int] = None,\n",
    "    use_cache: bool = False,\n",
    "    save_results: bool = False,\n",
    ") -> Tuple[TrainTest, TrainTest]:\n",
    "\n",
    "    if use_cache:\n",
    "        X = pd.read_pickle(f\"./cache/factor_{freq}.pkl\")\n",
    "        Y = pd.read_pickle(f\"./cache/asset_{freq}.pkl\")\n",
    "    else:\n",
    "        # Define the list of tickers\n",
    "        tick_list = [\n",
    "            \"AAPL\",\n",
    "            \"MSFT\",\n",
    "            \"AMZN\",\n",
    "            \"C\",\n",
    "            \"JPM\",\n",
    "            \"BAC\",\n",
    "            \"XOM\",\n",
    "            \"HAL\",\n",
    "            \"MCD\",\n",
    "            \"WMT\",\n",
    "            \"COST\",\n",
    "            \"CAT\",\n",
    "            \"LMT\",\n",
    "            \"JNJ\",\n",
    "            \"PFE\",\n",
    "            \"DIS\",\n",
    "            \"VZ\",\n",
    "            \"T\",\n",
    "            \"ED\",\n",
    "            \"NEM\",\n",
    "        ]\n",
    "\n",
    "        if n_y is not None:\n",
    "            tick_list = tick_list[:n_y]\n",
    "\n",
    "        # Download asset data using yfinance\n",
    "        data = yf.download(\n",
    "            tick_list,\n",
    "            start=start,\n",
    "            end=end,\n",
    "            progress=False,\n",
    "            group_by=\"ticker\",\n",
    "            auto_adjust=True,  # Adjusted close prices\n",
    "            threads=True,  # Enable multi-threading for faster downloads\n",
    "        )\n",
    "\n",
    "        if data.empty:\n",
    "            raise ValueError(\n",
    "                \"No data downloaded. Please check the ticker symbols and date range.\"\n",
    "            )\n",
    "\n",
    "        # Extract Adjusted Close prices\n",
    "        if len(tick_list) == 1:\n",
    "            # For single ticker, data['Close'] is a Series, convert to DataFrame\n",
    "            adj_close = data[\"Close\"].to_frame()\n",
    "            adj_close.columns = tick_list\n",
    "        else:\n",
    "            # For multiple tickers, use xs to extract 'Close' for all tickers\n",
    "            try:\n",
    "                adj_close = data.xs(\"Close\", level=1, axis=1)\n",
    "            except KeyError:\n",
    "                raise KeyError(\"Close prices not found in the downloaded data.\")\n",
    "\n",
    "        # Compute daily returns as percentage change\n",
    "        Y = adj_close.pct_change().dropna()\n",
    "\n",
    "        # Download factor data from Kenneth French's data library\n",
    "        dl_freq = \"_daily\"\n",
    "\n",
    "        try:\n",
    "            # 5-Factor Model\n",
    "            factor_5 = pdr.get_data_famafrench(\n",
    "                \"F-F_Research_Data_5_Factors_2x3\" + dl_freq,\n",
    "                start=start,\n",
    "                end=end,\n",
    "            )[0]\n",
    "            rf_df = factor_5[\"RF\"]\n",
    "            factor_5 = factor_5.drop([\"RF\"], axis=1)\n",
    "\n",
    "            # Momentum Factor\n",
    "            mom_df = pdr.get_data_famafrench(\n",
    "                \"F-F_Momentum_Factor\" + dl_freq,\n",
    "                start=start,\n",
    "                end=end,\n",
    "            )[0]\n",
    "\n",
    "            # Short-Term Reversal Factor\n",
    "            st_df = pdr.get_data_famafrench(\n",
    "                \"F-F_ST_Reversal_Factor\" + dl_freq,\n",
    "                start=start,\n",
    "                end=end,\n",
    "            )[0]\n",
    "\n",
    "            # Long-Term Reversal Factor\n",
    "            lt_df = pdr.get_data_famafrench(\n",
    "                \"F-F_LT_Reversal_Factor\" + dl_freq,\n",
    "                start=start,\n",
    "                end=end,\n",
    "            )[0]\n",
    "\n",
    "            # Concatenate all factors and convert to decimal\n",
    "            X = pd.concat([factor_5, mom_df, st_df, lt_df], axis=1) / 100\n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Failed to download factor data: {e}\")\n",
    "\n",
    "        # Align factor data (X) with asset returns (Y) based on dates\n",
    "\n",
    "        # Remove timezone from Y.index if present\n",
    "        if Y.index.tz is not None:\n",
    "            Y.index = Y.index.tz_convert(None)\n",
    "\n",
    "        # Ensure X.index is also timezone-naive\n",
    "        if X.index.tz is not None:\n",
    "            X.index = X.index.tz_convert(None)\n",
    "\n",
    "        # Now, perform the alignment\n",
    "        try:\n",
    "            X = X.loc[Y.index]\n",
    "        except KeyError as e:\n",
    "            missing_dates = Y.index.difference(X.index)\n",
    "            if not missing_dates.empty:\n",
    "                print(f\"Missing dates in factor data: {missing_dates}\")\n",
    "                # Optionally, you can drop missing dates or handle them differently\n",
    "                Y = Y.loc[Y.index.intersection(X.index)]\n",
    "                X = X.loc[X.index.intersection(Y.index)]\n",
    "            else:\n",
    "                raise e  # Re-raise if no missing dates found\n",
    "\n",
    "        # Resample data if frequency is not daily\n",
    "        freq_lower = freq.lower()\n",
    "        if freq_lower in [\"weekly\", \"wk\", \"1wk\"]:\n",
    "            Y = Y.resample(\"W-FRI\").apply(lambda x: (x + 1).prod() - 1)\n",
    "            X = X.resample(\"W-FRI\").apply(lambda x: (x + 1).prod() - 1)\n",
    "        elif freq_lower in [\"monthly\", \"1mo\"]:\n",
    "            Y = Y.resample(\"M\").apply(lambda x: (x + 1).prod() - 1)\n",
    "            X = X.resample(\"M\").apply(lambda x: (x + 1).prod() - 1)\n",
    "        # Add more resampling frequencies if needed\n",
    "\n",
    "        # Handle missing values by forward and backward filling using ffill() and bfill()\n",
    "        Y = Y.ffill().bfill()\n",
    "        X = X.ffill().bfill()\n",
    "\n",
    "        # Convert the index to 'YYYY-MM-DD' format\n",
    "        X.index = X.index.strftime(\"%Y-%m-%d\")\n",
    "        X.index = pd.DatetimeIndex(X.index)\n",
    "        Y.index = Y.index.strftime(\"%Y-%m-%d\")\n",
    "        X.index = pd.DatetimeIndex(Y.index)\n",
    "\n",
    "        # Optionally save the results to cache\n",
    "        if save_results:\n",
    "            os.makedirs(\"./cache\", exist_ok=True)\n",
    "            X.to_pickle(f\"./cache/factor_{freq}.pkl\")\n",
    "            Y.to_pickle(f\"./cache/asset_{freq}.pkl\")\n",
    "    print(X.shape, Y.shape)\n",
    "    # Partition dataset into training and testing sets. Lag the data by one observation\n",
    "    # Using the provided TrainTest class\n",
    "    X_train_test = TrainTest(X[:-1], n_obs, split)\n",
    "    Y_train_test = TrainTest(Y[1:], n_obs, split)\n",
    "\n",
    "    return X_train_test, Y_train_test\n",
    "\n",
    "\n",
    "start_paddling = \"1997-04-01\"\n",
    "end_paddling = \"2024-10-01\"  # Data frequency and start/end dates\n",
    "daily_frequency = \"daily\"\n",
    "xf_train_test, yf_train_test = AV_yFinance(\n",
    "    start=start_paddling,\n",
    "    end=end_paddling,\n",
    "    split=[0.9, 0.1],\n",
    "    freq=daily_frequency,\n",
    "    n_obs=104,\n",
    "    n_y=20,\n",
    "    use_cache=False,\n",
    "    save_results=True,\n",
    ")\n",
    "print(\n",
    "    xf_train_test.train().shape,\n",
    "    yf_train_test.train().shape,\n",
    "    xf_train_test.test().shape,\n",
    "    yf_train_test.test().shape,\n",
    ")\n",
    "print(xf_train_test.train().head(), xf_train_test.test().tail())\n",
    "print(yf_train_test.train().head(), yf_train_test.test().tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n",
      "Out-of-sample window: 1 / 4\n",
      "Loaded model state from e2e_net_full_data2_0.pt\n"
     ]
    }
   ],
   "source": [
    "n_roll: int = 4  # Number of rolling windows\n",
    "dr_net_full_data = E2E_net(\n",
    "    num_input_features=n_X,\n",
    "    num_assets=n_Y,\n",
    "    num_observations=number_of_observe_per_window,\n",
    "    prisk=\"p_var\",\n",
    "    train_pred=True,\n",
    "    train_gamma=True,\n",
    "    train_delta=True,\n",
    "    set_seed=19260817,\n",
    "    optimization_layer=\"hellinger\",\n",
    "    performance_objective=\"sharpe_loss\",\n",
    "    cache_path=\"./cache/\",\n",
    "    performance_period=13,\n",
    "    prediction_loss_factor=0.5,\n",
    "    model_name=\"e2e_net_full_data2\",\n",
    ").double()\n",
    "# Move the model to the appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)\n",
    "dr_net_full_data.to(device)\n",
    "dr_net_full_data.net_roll_test(\n",
    "    X=xf_train_test,\n",
    "    Y=yf_train_test,\n",
    "    n_roll=n_roll,\n",
    "    lr=0.005,\n",
    "    epochs=[100] * n_roll,\n",
    "    load_state=[True] + [False] * (n_roll - 1),\n",
    "    save_state=[True] * (n_roll),\n",
    ")\n",
    "portfolio_0 = dr_net_full_data.portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAJOCAYAAABm7rQwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADd0ElEQVR4nOzdd3hU1drG4WfSgNBL6L0JSBVEBEVA6aBg44CK4tEPe0UBOx5UxN7LUeFYsBxFRSkHFFApFnpHSgApoUMIAdLm+2O5s2dSZ5Kpmd99XVx7z562yE6ZeeZd73I4nU6nAAAAAAAAgACKCvYAAAAAAAAAEHkIpQAAAAAAABBwhFIAAAAAAAAIOEIpAAAAAAAABByhFAAAAAAAAAKOUAoAAAAAAAABRygFAAAAAACAgCOUAgAAAAAAQMARSgEAAAAAACDgCKUAACgB1qxZo1GjRqlRo0YqXbq0ypUrp3POOUeTJ0/WkSNHgj28Aj3xxBNyOBxFuu+sWbP0xBNP5Hldw4YNdcMNNxR9YEXUo0cPORyO7H+lS5dWq1atNHHiRKWlpRXpMadNm6aXX37ZtwP1sb/++kt33HGHmjRpotKlS6ty5crq0aOHPvnkEzmdzmAPL5v1/VbYvx49emjHjh1yOByaOnVqsIcNAECJFBPsAQAAgOL597//rdtuu01nnXWWHnjgAbVq1Urp6elatmyZ3n77bS1dulRff/11sIfpF7NmzdIbb7yRZzD19ddfq0KFCoEflKTGjRvrk08+kSQdPHhQ7733nh599FHt2rVL7777rtePN23aNK1bt0733HOPj0fqG4sXL9agQYNUrlw5PfDAA2rbtq2OHz+uL774Qtdee62+++47TZs2TVFRwf889KabblK/fv2yL+/bt0+XX3657rzzTo0YMSL7eIUKFVSrVi0tXbpUTZo0CcZQAQAo8QilAAAIY0uXLtWtt96q3r1765tvvlGpUqWyr+vdu7fuv/9+zZkzJ4gjDJ4OHToE7bnLlCmjLl26ZF/u37+/WrVqpf/85z969dVXVbp06aCNzVVqaqri4+OL9RjHjh3T5ZdfrooVK+q3335TjRo1sq+77LLL1LZtW40bN07t27fXuHHjijtkj2VmZiojI8PtZ0KS6tatq7p162Zf3rFjhySpfv36bufMktcxAADgG8H/uAoAABTZ008/LYfDoXfffTfXm29JiouL06WXXpp92eFw5FlVlHOq29SpU+VwODR//nzdfPPNqlq1qipUqKCRI0fq5MmTSkpK0tVXX61KlSqpVq1aGjNmjNLT07Pvv3DhQjkcDi1cuNDteTydDvX555+rT58+qlWrlsqUKaOWLVtq3LhxOnnyZPZtbrjhBr3xxhvZ/y/rnxUyuP6fDh48qLi4OD366KO5nmvTpk1yOBx69dVXs48lJSVp9OjRqlu3ruLi4tSoUSNNmDBBGRkZBY47PzExMWrfvr3S0tJ07Nix7ONOp1Nvvvmm2rdvrzJlyqhy5cq68sortX379uzb9OjRQzNnztTOnTvd/p+Sd1/nG264QeXKldPatWvVp08flS9fXhdffHH21++OO+7QRx99pJYtWyo+Pl7t2rXT999/X+j/7b333tOBAwc0adIkt0DK8uCDD6pFixZ67rnnlJ6e7pdzYf1/J0+erIkTJ6pRo0YqVaqUFixYUOj4C5LX19Ga/rdmzRpdddVVqlixoqpUqaL77rtPGRkZ2rx5s/r166fy5curYcOGmjx5cq7HTU5O1pgxY9SoUSPFxcWpTp06uueee9y+vwEAiARUSgEAEKYyMzM1f/58dezYUfXq1fPLc9x00026/PLL9dlnn2nlypV66KGHst94X3755fq///s//fDDD3r22WdVu3Zt3XfffT553i1btmjAgAG65557VLZsWW3atEnPPvusfv/9d82fP1+S9Oijj+rkyZP68ssvtXTp0uz71qpVK9fjJSQkaNCgQfrPf/6jCRMmuE0jmzJliuLi4nTNNddIMiFI586dFRUVpccee0xNmjTR0qVLNXHiRO3YsUNTpkwp0v8pMTFRlSpVUkJCQvax0aNHa+rUqbrrrrv07LPP6siRI3ryySfVtWtXrV69WjVq1NCbb76p//u//9O2bduKPQ0zLS1Nl156qUaPHq1x48a5BTszZ87UH3/8oSeffFLlypXT5MmTNXToUG3evFmNGzfO9zHnzZun6OhoDR48OM/rHQ6HLr30Uk2ePFnLly9Xly5d/HYuXn31VTVv3lzPP/+8KlSooGbNmhXny1Wgq6++Wtdee61Gjx6tefPmafLkyUpPT9cPP/yg2267TWPGjNG0adM0duxYNW3aVJdffrkkU5120UUXaffu3XrooYfUtm1brV+/Xo899pjWrl2rH374ocg91gAACDtOAAAQlpKSkpySnP/4xz88vo8k5+OPP57reIMGDZzXX3999uUpU6Y4JTnvvPNOt9sNGTLEKcn54osvuh1v376985xzzsm+vGDBAqck54IFC9xul5iY6JTknDJlSvaxxx9/3FnQS5KsrCxnenq686effnJKcq5evTr7uttvvz3f++b8P82YMcMpyTl37tzsYxkZGc7atWs7r7jiiuxjo0ePdpYrV865c+dOt8d7/vnnnZKc69evz3esTqfTedFFFznPPvtsZ3p6ujM9Pd25b98+52OPPeaU5Hz77bezb7d06VKnJOcLL7zgdv+//vrLWaZMGeeDDz6YfWzgwIHOBg0a5Houb77O119/vVOS84MPPsj1OJKcNWrUcCYnJ2cfS0pKckZFRTmfeeaZAv+/LVq0cNasWbPA27z11ltOSc7PP//c6XT6/lxY/98mTZo409LSChxLTtZ9n3vuuXyvy+v7Ned5a9++vVOSc/r06dnH0tPTnQkJCc7LL788+9gzzzzjjIqKcv7xxx9u9//yyy+dkpyzZs3yavwAAIQzpu8BAIB8DRo0yO1yy5YtJUkDBw7MdXznzp0+e97t27drxIgRqlmzpqKjoxUbG6uLLrpIkrRx48YiPWb//v1Vs2ZNt+qa//3vf9q7d69uvPHG7GPff/+9evbsqdq1aysjIyP7X//+/SVJP/30U6HPtX79esXGxio2Nla1atXSk08+qfHjx2v06NFuz+NwOHTttde6PU/NmjXVrl27XFPyfOWKK67I83jPnj1Vvnz57Ms1atRQ9erVfXJenX+vvmdVAPnrXFx66aWKjY0t9ng9kdfPhsPhyB6bZKZtNm3a1O1r+P3336t169Zq37692/+pb9++eU7FBACgJGP6HgAAYapatWqKj49XYmKi356jSpUqbpfj4uLyPX769GmfPGdKSoouvPBClS5dWhMnTlTz5s0VHx+vv/76S5dffrlOnTpVpMeNiYnRddddp9dee03Hjh1TpUqVNHXqVNWqVUt9+/bNvt3+/fv13Xff5RtuHDp0qNDnatKkiT777DM5nU7t3LlTEydO1DPPPKO2bdvqH//4R/bzOJ3OPPswSSpwylxRxcfH57siYdWqVXMdK1WqVKFf7/r162vLli06efKkypYtm+dtrD5f1jRTf52LvKZu+ktePwPx8fG5mtjHxcUpOTk5+/L+/fu1devWYn1/AQBQUhBKAQAQpqKjo3XxxRdr9uzZ2r17t9uKYvkpVaqUzpw5k+v44cOHfTo26415zufy5A33/PnztXfvXi1cuDC7OkqSW4Pwoho1apSee+45ffbZZxo2bJhmzJihe+65R9HR0dm3qVatmtq2baunnnoqz8eoXbt2oc9TunRpderUSZJ07rnnqmfPnjr77LN1zz33aNCgQSpXrpyqVasmh8OhX375Jc8m9Xkdy+t5JM+/zv7oVdS7d2/NnTtX3333XXbg5srpdGrGjBmqUqWKOnbsmH3cH+ciHHoxVatWTWXKlNEHH3yQ7/UAAEQKQikAAMLY+PHjNWvWLN1888369ttvsyuZLOnp6ZozZ052E+qGDRtqzZo1breZP3++UlJSfDquhg0bSpLWrFnjVvkyY8aMQu9rBQs5Q5l33nkn122t25w6dUplypQp9LFbtmyp8847T1OmTFFmZqbOnDmjUaNGud1m0KBBmjVrlpo0aaLKlSsX+pieqFq1qiZNmqRRo0bptdde0/jx4zVo0CBNmjRJe/bs0dVXX13g/fOrWCrO19lXbrrpJj333HMaP368evXqperVq7tdP3nyZG3atEmTJk1yqw4K1rkItkGDBunpp59W1apV1ahRo2APBwCAoCKUAgAgjJ1//vl66623dNttt6ljx4669dZbdfbZZys9PV0rV67Uu+++q9atW2eHUtddd50effRRPfbYY7rooou0YcMGvf7666pYsaJPx1WzZk1dcskleuaZZ1S5cmU1aNBAP/74o6ZPn17ofbt27arKlSvrlltu0eOPP67Y2Fh98sknWr16da7btmnTRpL07LPPqn///oqOjlbbtm1zhXOubrzxRo0ePVp79+5V165dddZZZ7ld/+STT2revHnq2rWr7rrrLp111lk6ffq0duzYoVmzZuntt9/2qCotp5EjR+rFF1/U888/r9tvv13dunXT//3f/2nUqFFatmyZunfvrrJly2rfvn1atGiR2rRpo1tvvTX7/zl9+nS99dZb6tixo6KiotSpU6difZ19pVKlSpo+fboGDRqkjh076oEHHlC7du2UnJyszz//XJ988omGDRumBx54INd9g3Uugumee+7RV199pe7du+vee+9V27ZtlZWVpV27dmnu3Lm6//77dd555wV7mAAABAShFAAAYe7mm29W586d9dJLL+nZZ59VUlKSYmNj1bx5c40YMUJ33HFH9m0feOABJScna+rUqXr++efVuXNnffHFF7rssst8Pq6PPvpId955p8aOHavMzEwNHjxYn376afa0tvxUrVpVM2fO1P33369rr71WZcuW1WWXXabPP/9c55xzjtttR4wYocWLF+vNN9/Uk08+KafTqcTExOwKorz84x//0D333KPdu3fr8ccfz3V9rVq1tGzZMv3rX//Sc889p927d6t8+fJq1KiR+vXrV+SKnaioKE2aNEkDBw7Uyy+/rMcee0zvvPOOunTponfeeUdvvvmmsrKyVLt2bXXr1k2dO3fOvu/dd9+t9evX66GHHtLx48fldDqzm4cX9evsS926ddOaNWv07LPP6pVXXtHu3btVpkwZtWvXTh9//LFGjBiR59S6YJ2LYCpbtqx++eUXTZo0Se+++64SExNVpkwZ1a9fX5dcckmB37sAAJQ0Dqf1igYAAAAAAAAIkKhgDwAAAAAAAACRh1AKAAAAAAAAAUcoBQAAAAAAgIAjlAIAAAAAAEDAEUoBAAAAAAAg4AilAAAAAAAAEHAxwR5AoGVlZWnv3r0qX768HA5HsIcDAAAAAABQojidTp04cUK1a9dWVFT+9VBBDaV+/vlnPffcc1q+fLn27dunr7/+WkOGDMn39osWLdLYsWO1adMmpaamqkGDBho9erTuvfdej59z7969qlevng9GDwAAAAAAgPz89ddfqlu3br7XBzWUOnnypNq1a6dRo0bpiiuuKPT2ZcuW1R133KG2bduqbNmyWrRokUaPHq2yZcvq//7v/zx6zvLly0syX5gKFSoUa/yRIj09XXPnzlWfPn0UGxsb7OHATzjPkYnzHlk435GB8xyZOO+RhfMdWTjfkacknPPk5GTVq1cvO4PJT1BDqf79+6t///4e375Dhw7q0KFD9uWGDRtq+vTp+uWXXzwOpawpexUqVCCU8lB6erri4+NVoUKFsP2BQOE4z5GJ8x5ZON+RgfMcmTjvkYXzHVk435GnJJ3zwtomhXVPqZUrV2rJkiWaOHFivrc5c+aMzpw5k305OTlZkjnJ6enpfh9jSWB9nfh6lWyc58jEeY8snO/IwHmOTJz3yML5jiyc78hTEs65p2N3OJ1Op5/H4hGHw1FoTylL3bp1dfDgQWVkZOiJJ57Qo48+mu9tn3jiCU2YMCHX8WnTpik+Pr44QwYAAAAAAEAOqampGjFihI4fP17gLLWwDKUSExOVkpKiX3/9VePGjdPrr7+u4cOH53nbvCql6tWrp0OHDjF9z0Pp6emaN2+eevfuHfalg8gf5zkycd4jC+c7MnCeIxPnPbJwviML5zvylIRznpycrGrVqhUaSoXl9L1GjRpJktq0aaP9+/friSeeyDeUKlWqlEqVKpXreGxsbIEnNzMzM6xL5XwpMzNTMTExyszMLHApR4SO2NhYRUdHF/m+4fqLD0XHeY8snO/IwHmOTJz3yML5jiyc78gTzufc03GHZSjlyul0ulVC+eLxkpKSdOzYMZ89ZrhzOp2qWbOm/vrrr0KblCF0VKpUSTVr1uScAQAAAABCUlBDqZSUFG3dujX7cmJiolatWqUqVaqofv36Gj9+vPbs2aMPP/xQkvTGG2+ofv36atGihSRp0aJFev7553XnnXf6bExWIFW9enXFx8fzhl5SVlaWUlJSVK5cOSqlwoDT6VRqaqoOHDggSapVq1aQRwQAAAAAQG5BDaWWLVumnj17Zl++7777JEnXX3+9pk6dqn379mnXrl3Z12dlZWn8+PFKTExUTEyMmjRpokmTJmn06NE+GU9mZmZ2IFW1alWfPGZJkJWVpbS0NJUuXZpQKkyUKVNGknTgwAFVr169yFP5AAAAAADwl6CGUj169FBBfdanTp3qdvnOO+/0aVVUTlYPKVblQ0lgfR+np6cTSgEAAAAAQg5lL3lgyh5KAr6PAQAAAAChjFAKAAAAAAAAAUcohYBxOBz65ptvQuZxAAAAAABA8BBKlSBJSUm688471bhxY5UqVUr16tXT4MGD9eOPPwZ7aEXyxBNPqH379rmO79u3T/379/frczds2FAOh0MOh0NlypRRixYt9NxzzxXYAy2nqVOnqlKlSv4bJAAAAAAAYSyojc7hOzt27FC3bt1UqVIlTZ48WW3btlV6err+97//6fbbb9emTZuCPUSfqVmzZkCe58knn9TNN9+s06dP64cfftCtt96qChUq+Gy1R2+kp6crNjY24M8LAAAAAIC/UClVQtx2221yOBz6/fffdeWVV6p58+Y6++yzdd999+nXX3+VZIIrh8OhVatWZd/v2LFjcjgcWrhwoSRp4cKFcjgc+t///qcOHTqoTJkyuuSSS3Tw4EHNnj1bLVu2VIUKFTR8+HClpqZmP07Dhg318ssvu42pffv2euKJJ/Id89ixY9W8eXPFx8ercePGevTRR7NXQJw6daomTJig1atXZ1csWasxuk7fO//88zVu3Di3xz148KBiY2O1YMECSVJaWpoefPBB1alTR2XLltV5552X/f8tSPny5VWzZk01bNhQN910k9q2bau5c+dmX1/Q4y5cuFCjRo3S8ePHs8dvfS3ymn5YqVKl7P+fdZ6++OIL9ejRQ6VLl9bHH3+sG264QUOGDNHzzz+vWrVqqWrVqrr99tuzv2YAAAAAAIQTKqUK4XRKLtlLQMXHS54soHbkyBHNmTNHTz31lMqWLZvr+qJMIXviiSf0+uuvKz4+XldffbVGjRql+Ph4TZs2TSkpKRo6dKhee+01jR071uvHtpQvX15Tp05V7dq1tXbtWt18880qX768HnzwQQ0bNkzr1q3TnDlz9MMPP0iSKlasmOsxrrnmGj333HN65plnsleb+/zzz1WjRg1ddNFFkqRRo0Zpx44d+uyzz1S7dm19/fXX6tevn9auXatmzZoVOk6n06mffvpJGzdudLt9QY/btWtXvfzyy3rssce0efNmSVK5cuW8+vqMHTtWL7zwgqZMmaJSpUrpp59+0oIFC1SrVi0tWLBAW7du1bBhw9S+fXvdfPPNXj02AAAAAADBRihViNRUycsswWdSUqQ8MqZctm7dKqfTqRYtWvjsuSdOnKhu3bpJkm688UY99NBD2rJli5o2bSpJuvLKK7VgwYJihVKPPPJI9n7Dhg11//336/PPP9eDDz6oMmXKqFy5coqJiSlwut6wYcN07733atGiRbrwwgslSdOmTdOIESMUFRWlbdu26dNPP9Xu3btVu3ZtSdKYMWM0Z84cTZkyRU8//XS+jz127Fg98sgjSktLU3p6ukqXLq277rpLkjx63IoVK8rhcBR5uuE999yjyy+/3O1Y5cqV9frrrys6OlotWrTQwIED9eOPPxJKAQAAAADCDqFUCWA133Z4UlblobZt22bvV69ePXuKnaVGjRr6/fffi/UcX375pV5++WVt3bpVKSkpysjIUIUKFbx6jISEBPXu3VuffPKJLrzwQiUmJmrp0qV66623JEkrVqyQ0+lU8+bN3e535swZVa1atcDHfuCBB3TDDTfo4MGDevjhh9WrVy917dq12I/rqU6dOuU6dvbZZys6Ojr7cq1atbR27VqfPB8AAAAAAIFEKFWI+HhTsRSs5/ZEs2bN5HA4tHHjRg0ZMiTf20VFmRZirivI5dePyLWptsPhUEyM+7eKw+FQVlaW22PnXJmuoF5Hv/76q/7xj39owoQJ6tu3rypWrKjPPvtML7zwQr73yc8111yju+++W6+99pqmTZums88+W+3atZMkZWVlKTo6WsuXL3cLc6TCp9NVq1ZNTZs2VdOmTfXVV1+padOm6tKliy655JJiPa7D4fDoa5XXVMyczc5zngcAAAAAAMIFoVQhHA7PptAFU5UqVdS3b1+98cYbuuuuu3KFGceOHVOlSpWUkJAgSdq3b586dOggSW5Nz4sjISFB+/bty76cnJysxMTEfG+/ePFiNWjQQA8//HD2sZ07d7rdJi4uTpmZmYU+95AhQzR69GjNmTNH06ZN03XXXZd9XYcOHZSZmakDBw5kT+8risqVK+vOO+/UmDFjtHLlSo8eN7/x5/xabdmyxa1pPAAAAAAAkYDV90qIN998U5mZmercubO++uorbdmyRRs3btSrr76q888/X5JUpkwZdenSRZMmTdKGDRv0888/u/V1Ko5evXrpo48+0i+//KJ169bp+uuvz1VB5Kpp06batWuXPvvsM23btk2vvvqqvv76a7fbNGzYUImJiVq1apUOHTqkM2fO5PlYZcuW1WWXXaZHH31UGzdu1IgRI7Kva968ua655hqNHDlS06dPV2Jiov744w89++yzmjVrllf/x9tvv12bN2/WV1995dHjNmzYUCkpKfrxxx916NCh7OCpV69eev3117VixQotW7ZMt9xyS64KKAAAAABAZLnxRumaa6R164I9ksAhlCohGjVqpBUrVqhnz566//771bp1a/Xu3Vs//vhjdn8lSfrggw+Unp6uTp066e6779bEiRN98vzjx49X9+7dNWjQIA0YMEBDhgxRkyZN8r39ZZddpnvvvVd33HGH2rdvryVLlujRRx91u80VV1yhfv36qWfPnkpISNCnn36a7+Ndc801Wr16tS688ELVr1/f7bopU6Zo5MiRuv/++3XWWWfp0ksv1W+//aZ69ep59X9MSEjQddddpyeeeEJZWVmFPm7Xrl11yy23aNiwYUpISNDkyZMlSS+88ILq1aun7t27a8SIERozZoziPZ2rCQAAAAAocbKypOnTpWnTpIyMYI8mcBzOnM1tSrjk5GRVrFhRx48fz9VU+/Tp00pMTFSjRo1UunTpII0w9GRlZSk5OVkVKlTI7kuF0Oft93N6erpmzZqlAQMGULkVQTjvkYXzHRk4z5GJ8x5ZON+RhfMdGbZskZo3l0qVko4cSde8eeF9zgvKXlyRMAAAAAAAAATR8uVm2769FKY5VJEQSgEAAAAAAATRsmVm26lTcMcRaIRSAAAAAAAAQUQoBQAAAAAAgIByOqVVq8z+OecEdSgBRygFAAAAAAAQJAcOSMePSw6HaXYeSQil8pCVlRXsIQDFxvcxAAAAAIS+zZvNtmFDyYOF00uUmGAPIJTExcUpKipKe/fuVUJCguLi4uRwOII9rKDLyspSWlqaTp8+ragocsxQ53Q6lZaWpoMHDyoqKkpxcXHBHhIAAAAAIA8PPig995zZP+us4I4lGAilXERFRalRo0bat2+f9u7dG+zhhAyn06lTp06pTJkyhHRhJD4+XvXr1ydIBAAAAIAQlJlpB1ISoRRkqqXq16+vjIwMZWZmBns4ISE9PV0///yzunfvrtjY2GAPBx6Ijo5WTEwMISIAAAAAhKikJPfLhFKQJDkcDsXGxhLA/C06OloZGRkqXbo0XxMAAAAAAHxgzx73y02aBGccwcS8HgAAAAAAgADbvdver1FDOu+84I0lWAilAAAAAAAAAsyqlLrsMhNQVawY3PEEA6EUAAAAAABAgFmVUg0bSjER2lyJUAoAAAAAACDArEqpunWDO45gIpQCAAAAAAAIMKtSilAKAAAAAAAAAWNVStWpE9xxBBOhFAAAAAAAQACdOCHt2mX269UL7liCiVAKAAAAAAAggP77XyktTTrrLKlBg2CPJngIpQAAAAAAAAJo6lSzveEGyeEI5kiCi1AKAAAAAAAgQLZulX75RYqKkq67LtijCS5CKQAAAAAAgAD5z3/Mtk+fyG5yLhFKAQAAAAAABERmph1K3XBDUIcSEgilAAAAAAAAAmDBAumvv6RKlaTLLgv2aIKPUAoAAAAAACAArAbnw4dLpUsHdSghgVAKAAAAAADAz1JSpOnTzf6oUcEdS6gglAIAAAAAAPCzmTOlU6ekpk2lTp2CPZrQQCgFAAAAAADgZ19+abZXXSU5HMEdS6gglAIAAAAAAPCjvXtNpZQkXXllcMcSSgilAAAAAAAA/OD4cWnAAKlOHTN1r3NnqUOHYI8qdMQEewAAAAAAAAAlQVaW9NRT0tq1prH5li3S1q3muthY6f33mbrnilAKAAAAAADAB775RnrsMfdjpUpJY8ZIl14qtW4dlGGFLEIpAAAAAACAYnI6pWeeMfvDhkl9+0ply0oXXijVqhXcsYUqQikAAAAAAIBiWr1aWrZMKl1aeu01KSEh2CMKfTQ6BwAAAAAAKKZFi8y2Rw8CKU8RSgEAAAAAABTT0qVme/75wR1HOCGUAgAAAAAAKKYlS8y2a9fgjiOcEEoBAAAAAAAUw7590o4dksMhde4c7NGED0IpAAAAAACAYrCm7rVpI1WoENyxhBNCKQAAAAAAgGKgn1TREEoBAAAAAAAUA/2kioZQCgAAAAAAoIjOnJGWLzf7VEp5h1AKAAAAAACgiNasMcFUtWpS06bBHk14IZQCAAAAAAAoovXrzbZtW7P6HjxHKAUAAAAAAFBEGzaYbcuWwR1HOCKUAgAAAAAAKKKNG82WUMp7hFIAAAAAAABFRChVdIRSAAAAAAAARXD6tJSYaPYJpbxHKAUAAAAAAFAEf/4pZWVJFStKNWsGezThh1AKAAAAAACgCBYtMtsOHVh5rygIpQAAAAAAAIpg3jyzveSS4I4jXBFKAQAAAAAAeCkjQ5o/3+z37h3csYQrQikAAAAAAAAvLVsmJSdLlStLHTsGezThiVAKAAAAAADAS9bUvV69pOjo4I4lXBFKAQAAAAAAeMkKpZi6V3SEUgAAAAAAAF44cUJautTsE0oVHaEUAAAAAACAF376yTQ6b9zY/EPREEoBAAAAAAB44YcfzJYqqeIhlAIAAAAAAPAC/aR8g1AKAAAAAADARXq6NGuWdPx47uv27JE2bJAcDqlnz8CPrSQhlAIAAAAAAHDx7LPSwIHSddflvu6XX8y2Y0epSpXAjqukIZQCAAAAAABw8dxzZvvdd7mvW7XKbDt1CthwSixCKQAAAAAAABenTuV/nRVKtW8fiJGUbIRSAAAAAAAALtLT87+OUMp3CKUAAAAAAAD+lpnpfjk11d5PSpL275eioqQ2bQI7rpKIUAoAAAAAAOBve/fmf3n1arNt1kyKjw/cmEoqQikAAAAAAIC/bdvmftk1lDpwwGzr1w/ceEoyQikAAAAAAIC/FRRKpaSYbblygRtPSUYoBQAAAAAA8LcdO9wv79lj7584YbblywdsOCUaoRQAAAAAAMDf/vrL/bJrpRShlG8RSgEAAAAAAPzNCqU6dDDbvKbvEUr5BqEUAAAAAADA33bvNtsuXcw2r+l79JTyDUIpAAAAAAAASU6nXSl13nlmS6WU/xBKAQAAAAAASDpyRDp1yux37my2e/easEqip5SvEUoBAAAAAADIrpKqXl1q2NDsnzolHTtm9pm+51uEUgAAAAAAALJDqbp1pTJlpCpVzGVrCh/T93yLUAoAAAAAAEB2KFWvntnWrm22VijF9D3fIpQCAAAAAACQvfJezlDKWoGP6Xu+RSgFAAAAAACg3JVSdeqYLdP3/INQCgAAAAAAQAVP38vKkk6eNJcJpXyDUAoAAAAAAEDujc4l91DKqpKSmL7nK4RSAAAAAAAg4mVl5e4pZU3f27PHDqWio6XSpQM/vpKIUAoAAAAAAES8gweltDTJ4bDDKNdKKdeV9xyO4IyxpCGUAgAAAAAAEc+qkqpZU4qNNftWKLVvn5ScbPaZuuc7hFIAAAAAACDi5WxyLkk1akhRUVJmprR9uzlGk3PfIZQCAAAAAAARL69QKibGBFOStGmT2RJK+Q6hFAAAAAAAiHh795qtNWXPYl1eu9ZsK1YM3JhKuqCGUj///LMGDx6s2rVry+Fw6Jtvvinw9tOnT1fv3r2VkJCgChUq6Pzzz9f//ve/wAwWAAAAAACUWIcOmW316u7Hrabnc+aYbcuWgRtTSRfUUOrkyZNq166dXn/9dY9u//PPP6t3796aNWuWli9frp49e2rw4MFauXKln0cKAAAAAABKMiuUqlbN/bhVKXXypNm2bx+wIZV4McF88v79+6t///4e3/7ll192u/z000/r22+/1XfffacOHTr4eHQAAAAAACBSFBZKWQilfCese0plZWXpxIkTqlKlSrCHAgAAAAAAwlh+oVTjxu6XW7UKzHgiQVArpYrrhRde0MmTJ3X11Vfne5szZ87ozJkz2ZeTk5MlSenp6UpPT/f7GEsC6+vE16tk4zxHJs57ZOF8RwbOc2TivEcWzndk4XwHzsGDMZIcqlgxXa5f7sGDJSk2+3JUlPv1vlYSzrmnY3c4nU6nn8fiEYfDoa+//lpDhgzx6PaffvqpbrrpJn377be65JJL8r3dE088oQkTJuQ6Pm3aNMXHxxd1uAAAAAAAoITIzJSuvPJSOZ0OTZkyR5Urn3G7fsuWSnr++U4aPHi7Bg3aHqRRho/U1FSNGDFCx48fV4UKFfK9XViGUp9//rlGjRql//73vxo4cGCBt82rUqpevXo6dOhQgV8Y2NLT0zVv3jz17t1bsbGxhd8BYYnzHJk475GF8x0ZOM+RifMeWTjfkYXzHRiHDkm1a5uv78mT6Qrml7oknPPk5GRVq1at0FAq7Kbvffrpp7rxxhv16aefFhpISVKpUqVUqlSpXMdjY2PD9uQGC1+zyMB5jkyc98jC+Y4MnOfIxHmPLJzvyML59q/jx822UiUpPj40vs7hfM49HXdQQ6mUlBRt3bo1+3JiYqJWrVqlKlWqqH79+ho/frz27NmjDz/8UJIJpEaOHKlXXnlFXbp0UVJSkiSpTJkyqlixYlD+DwAAAAAAILzl1+Qc/hXU1feWLVumDh06qEOHDpKk++67Tx06dNBjjz0mSdq3b5927dqVfft33nlHGRkZuv3221WrVq3sf3fffXdQxg8AAAAAAMIfoVRwBLVSqkePHiqopdXUqVPdLi9cuNC/AwIAAAAAABGHUCo4glopBQAAAAAAEExOp7R6tdknlAosQikAAAAAABCRfvtN6tZNev11c7lJk+COJ9KE3ep7AAAAAAAAxfXVV9KVV5r9+Hhp3DjpgQeCO6ZIQygFAAAAAAAizrRpZjtwoPTuu1Lt2sEdTyRi+h4AAAAAAIg4mzaZ7R13EEgFC6EUAAAAAACIKJmZ0tatZv+ss4I7lkhGKAUAAAAAACLKjh1SWppUurRUv36wRxO5CKUAAAAAAEBEsabuNWsmRUcHdyyRjFAKAAAAAABElM2bzbZFi+COI9IRSgEAAAAAgIiydq3Z0k8quAilAAAAAABAxHA6pXnzzP6FFwZ3LJGOUAoAAAAAAESM9eulPXukMmWk7t2DPZrIRigFAAAAAAAixpw5Ztujh1l9D8FDKAUAAAAAACLGihVme9FFwR0HCKUAAAAAAEAEOXDAbOvWDe44QCgFAAAAAAAiiBVKVa8e3HGAUAoAAAAAAEQQQqnQQSgFAAAAAAAiQlaWdPCg2SeUCj5CKQAAAAAAEBGOHDHBlCRVqxbcsYBQCgAAAAAARAhr6l7lylJsbHDHAkIpAAAAAAAQIZi6F1oIpQAAAAAAQESgyXloIZQCAAAAAAARgVAqtBBKAQAAAACAiGCFUgkJwR0HDEIpAAAAAAAQEaiUCi2EUgAAAAAAICIcO2a2lSsHdRj4G6EUAAAAAACICGlpZhsXF9xxwCCUAgAAAAAAESE93WwJpUIDoRQAAAAAAIgIVigVGxvcccAglAIAAAAAABGBUCq0EEoBAAAAAICIYPWUIpQKDYRSAAAAAAAgIlApFVoIpQAAAAAAQESg0XloIZQCAAAAAAARgUqp0EIoBQAAAAAAIgKhVGghlAIAAAAAABGBRuehhVAKCHPr10uHDwd7FAAAAAAQ+qiUCi2EUkAY27BBat1a6tw52CMBAAAAgNBHo/PQQigFhLG5c812+3Zp//7gjgUAAAAAQh2VUqGFUAoIYxkZ9v68eWZ+9MqV0gcfSPfdJ82YEbyxAQAAAECoIZQKLTHBHgCAotuzx96/807pxhvtX7KSNGWKdPRo4McFAAAAAKGIRuehhUopIIy5hlLHjplAqlIl6aKL7GOpqUEYGAAAAACEIHpKhRYqpYAwtnev2d5wg3TppVKHDlKDBuZY6dLmU4CDB+1jAAAAABCpnE67BQqVUqGBSikgCDIzffM4VqXUzTdLQ4dKDRtKDof5l5Bgrjt40DfPBQAAAADhzLUnL6FUaCCUAgLsrbek8uWlhQs9v8+BA9LFF0vTp9vHnE67Uqp27dz3IZQCAAAAAJvVT0oilAoVhFJAgM2eLZ06JX3+uef3efVVaf586YorpKwsc+zQIfuXal6hVPXqZnvgQPHGCwAAAAAlgeuiUIRSoYFQCgiwffvMdulSz+8T49L97ZdfzNaqkkpIyLtJH5VSAAAAAGAjlAo9hFJAgFmh1Nq10okTnt3n1Cl7/+OPzdbqJ5VXlZREKAUAAAAArqxQKjpaiiINCQmcBiCAsrKk/fvt/d9/N/u//iqdf37+1VPHjtn706ebX6ZWKFWnTt73IZQCAAAAAJsVSlElFToIpYAAOnTIfcWHJUvMtmdPE0z16ZP3/Y4etfePHJEWLLCn7xUWStFTCgAAAADsnryEUqEjpvCbAPAVa+qexaqMOn3abFNS8r6fFUqVLSudPCn997+Sw2GOUSkFAAAAAIWjUir0UCkFBJAVSpUqZbZLl9qr6RXEmr53881m+/XX0s6dZj+/nlLW6nuEUgAAAABgh1J5LRSF4CCUAgLICqW6dZPKlDFh0+bNhd/PqpQaMkSqVk06fNhM4ZOolAIAAAAAT1ApFXoIpYAASkoy23r1pM6dzb7VV0qyp+RJktMp/fijlJxsh1IJCdLQoWbf+oWaXyhVvrzZpqSYxwIAAACASEYoFXoIpYAAsiqlatWSunY1+z//bF/vWkb6wgvSJZdIjz5qT9+rVEm66ir3x8xv+l6ZMvb+mTPFGTUAAAAAhD8anYceQikggKwV82rVks4/3+x/9519fXS02Z46JT33nNn/5Re771TlylKPHlKVKuZyXJyZzpeX+Hh7/9QpnwwfAAAAAMIWlVKhh1AKCKBdu8y2fn07lLKm5klSaqqUkSF98IF04IA5tnat2ZYqZaqfYmPtKXy1a7tP+XMVG2uHXKmpvv1/AAAAAEC4odF56CGUAgLINZSqVk1q3jz3bQ4dsqukJBNSSWbqnuX6600Y1alTwc9nVUtRKQUAAAAg0lEpFXpigj0AIFKcPi3t32/269c3265dpT//dL/dW29JO3eapuaHDtlNyitXtm9z4YXS+vX595OylCkjnThBpRQAAAAAEEqFHiqlgADZvdts4+OlqlXN/vDhuW/35JNme++9Uo0a9nHXUEqSWraUKlYs+DmtZudUSgEAAACIdDQ6Dz2EUkCAuE7ds/pA9e6d920rVJBuu02qV88+5jp9z1PW9D0qpQAAAABEOiqlQg+hFBAgrqGUxeGQZs+WmjVzv+0//2mqoFxDqXPO8f45qZQCAAAAAING56GHUAoIECuUatDA/Xi/fqav1KBB9rE+fczWCpUk6ZprvH9OGp0DAAAAgEGlVOghlAICZOdOs3WtlHJ14oS9362b2dasaR9r2dL757RCLabvAQAAAIh0hFKhh9X3gABZudJsmzfP+/o1a+z98uXN9qGHpMOHpVtvLdpzUikFAAAAAAaNzkMPlVJAABw5Iq1aZfa7d8/7NuPHm+1NN9nHqlSRpkyROncu2vNSKQUAAAAABpVSoYdKKSAAfvlFcjqlFi3cp+S5uvdeqUuXogdQeaFSCgAAAEAkSkqS1q2TLrnEPkaj89BDpRQQAAsWmG3PnvnfJiZGuvBCqVQp3z0vlVIAAAAAIlHXrlLv3tL339vHqJQKPV5XSmVmZmrq1Kn68ccfdeDAAWVlZbldP3/+fJ8NDigp1q0z2/POC+zzWqEUlVIAAAAAIkVampSYaPanT7dXOieUCj1eh1J33323pk6dqoEDB6p169ZyOBz+GBdQoiQlmW2dOoF9XqbvAQAAAIg01iJTkpSRYe/T6Dz0eB1KffbZZ/riiy80YMAAf4wHKJH27TPbWrUC+7xM3wMAAAAQaZYutfc3bbL3qZQKPV73lIqLi1PTpk39MRagRDpzxqy+J+Xf5NxfqJQCAAAAUJLl6CgkSVqyxN7ftMksOiXR6DwUeR1K3X///XrllVfktM4qgALt32+2sbFSlSqBfW4qpQAAAACUVCNGSE2aSCkp7sc3bLD3T5yQ9uwx+1RKhR6vp+8tWrRICxYs0OzZs3X22WcrNsfZnD59us8GB5QEVj+pmjWlQLdgo1IKAAAAQEmUkSF9+qnZX7jQbmYuSbt3u992/Xqpbl16SoUir0OpSpUqaejQof4YC1AiuYZSgUalFAAAAICSaMcOe790aXs/JUU6ftzsDxkiffONNGOGdPHF0oED5jihVOjwKpTKyMhQjx491LdvX9UMxjtsIAwFq8m5ZIdSVEoBAAAAKEn+/NPed52+Z03VK19euuUWE0p98ok0a5YdZAW6rQry51VPqZiYGN166606c+aMv8YDlDjBrJRi+h4AAACAksg1lEpOtvetUKpOHVMdVauWqZzasUOqVk2aOFEaPjygQ0UBvG50ft5552nlypX+GAtQIlmVUkzfAwAAAADfyC+UsvpJ1a0rxcRIL7wgde8uvfGGtHOn9PDDTN8LJV73lLrtttt0//33a/fu3erYsaPKli3rdn3btm19NjigMElJ0ssvS7fdJtWvH+zR5C2Y0/eolAIAAABQEm3ZYu/nVyklmaooKqNCl9eh1LBhwyRJd911V/Yxh8Mhp9Mph8OhzMxM340OKESLFqYUc98+6T//CfZo8rZpk9k2bhz456ZSCgAAAEBJkpEhLVgg/fGHfSy/SimEPq9DqcTERH+MA/Da5s32qgrbtwd3LPlJTbUT/GAUEVqVUqmpktMpORyBHwMAAAAAFNe8edK//222x465X1dQpRRCm9ehVIMGDfwxDsBrn3xi7wejCskTGzaYMCghQapRI/DPX6GC2Tqd0smTUrlygR8DAAAAABTHyZPSpZdKp0+by1WqSFdeaVqkTJhgh1KZmdKaNWafSqnw4HUo9eGHHxZ4/ciRI4s8GMAbVlmmJIXqgpDWL8S2bYNTpRQfL0VHm1/Ox48TSgEAAAAIP7//bgKpmjWlr7+Wzj3XvM95/31zvRVKffqplJhoQqsePYI2XHjB61Dq7rvvdrucnp6u1NRUxcXFKT4+nlAKAXPwoL0f6qFUmzbBeX6HQ6pYUTpyxIRSlLACAAAACDeLFpltz55Sly72cWtmSHKy6TU1YYK5/MADUvnygR0jiibK2zscPXrU7V9KSoo2b96sCy64QJ9++qk/xgjkyTWUsso4Q83atWYbzEUpXX9RAwAAAEC4sUKpbt3cj7u+1/nkE2nrVqlaNemOOwI7PhSd16FUXpo1a6ZJkyblqqIC/CnUK6WcTmn1arMfzFCqYkWztZrCAwAAAEC4yMyUli41+xdc4H6dFUodPiw9+aTZf/BB2paEE6+n7+UnOjpae/fu9dXDAYUK9UqppCTzyzEqSmrVKnjjoFIKAAAAQLhau1Y6ccK8r2nd2v06673Orl1mW726dNttgR0fisfrUGrGjBlul51Op/bt26fXX39d3XLW0gF+cvq0+cVkCcVKKWvqXrNmUpkywRtHUSqldu6U/vxT6t3bP2MCAAAAAE9YU/fOP980N3dlhVKWBx+UypYNzLjgG16HUkOGDHG77HA4lJCQoF69eumFF17w1biAArlWSUmhGUq5rrwXTEUJpRo2NNsFC1i1AgAAAEDwWKFUzql7Uu5Q6p//9P944Fteh1JZWVn+GAfglZyhVChO3wuVUKo40/d++olQCgAAAEBwOJ35NzmX3HtHNWokVaoUkGHBh7xudP7kk08qNTU11/FTp07pSauzGOBn4VQp1aZNcMdRnEbnmZm+HQsAAAAAeOrPP6U9e6TYWKlz59zXu07nO/fcwI0LvuN1KDVhwgSlpKTkOp6amqoJEyb4ZFBAYaxQqmZNsw21Sqn0dGnjRrMf7EopK5QqSqUUoRQAAACAYPn+e7Pt0aPwXlGDB/t9OPADr6fvOZ1OORyOXMdXr16tKlWq+GRQQGGsUKpePbPKXahVSv35p5SWJpUvLzVoENyxWNP3qJQCAAAAEE6sUGrQoPxvM326tGqVNGJEQIYEH/M4lKpcubIcDoccDoeaN2/uFkxlZmYqJSVFt9xyi18GCeTkGkr98UfohVLW1L3WraUor+sRfSvcp+9NnmxWMBw6NNgjAQAAABAoJ09Kv/xi9gcOzP92Q4fyXiGceRxKvfzyy3I6nbrxxhs1YcIEVbTe6UqKi4tTw4YNdf755/tlkIhsv/8uvf229MwzUo0a5tiff5pt8+Zmm5YmZWX5PgD68EMzFe/GG6U8CgTztXat2QZ76p7kfaNzp9PeD/a6BkuWSGPHmn3XcQEAAAAo2XbuNB+SV6okNWkS7NHAXzwOpa6//npJUqNGjdStWzfFxHg98w8okvPOM9tjx0xppmRXIrk2s0tLk0qX9t3zHjwo3XCDCUN++UV6910pLs6z+4bKynuS95VSaWn2frArpf76K7jPDwAAACA4rPcC9eoFdxzwL6/rSi666CLt3LlTjzzyiIYPH64DBw5IkubMmaP169f7fICA5ddfzfbkSWnrVrPvGkrlNYUvj4UiPbZ2rV2d85//SH37SkePenbfUAylPK2Ucv06BjuUcq3UCnbVFgAAAIDA2bXLbOvXD+444F9eh1I//fST2rRpo99++03Tp0/PXolvzZo1evzxx30+QMBihSUbNpiwqEYNqW5d+/qcK/D98YcJZB59tGjPZ03Ba9nSNCxfuFC65JLCg5qjR+1Uv3Xroj23L1nT944d82yVwlANpU6dCt44AAAAAHjv6FFp+HBpzhzv70soFRm8DqXGjRuniRMnat68eYpzmcvUs2dPLV261KeDA1xZYYlVhdSmjenzVKqU+/WWm26SMjKkiROL9nxWKHXlldLixWbq3ooV9i/H/KxbZ7b165v5z8FWs6YZx+nTJlSzmsTnx/XrGOwG8q6hWHGq3gAAAAAE3ssvS599JvXv7/3reet9F9P3SjavQ6m1a9dqaB6t7RMSEnT48GGfDAqwuFb25AylrKlxVh+pnFVAhYUvhbFCqTZtzL9atczl/fsLvl8oTd2TpDJlpK++MlVjixdL558vbd6c/+1de0oFOwhyff5gjwUAAACAd1autPffece7+1qzT6iUKtm8DqUqVaqkffv25Tq+cuVK1alTxyeDAix/tyyTZKqeTp3KHfrkVyl16FDRnjMzU+ra1az6J9lT8KyV/5580jx3375mTDm5VnKFil69pKVLpYYNpW3bpD59zKqCeXH9OvojCDp0SBo8WJo5s/Db/j072G9jAQAAAOAfTqf9nkqSXnjB/QPwwjB9LzJ4HUqNGDFCY8eOVVJSkhwOh7KysrR48WKNGTNGI0eO9Oqxfv75Zw0ePFi1a9eWw+HQN998U+Dt9+3bpxEjRuiss85SVFSU7rnnHm+HjzDjGkpJJi33JJRyOvMPXQqze7cJcCQz9a1pU7NvhVKzZ5sqqrlzpU2bct/f6vcfSqGUZHpj/fabFB1tfsHn/NpaXL+O/ujj9MUX0vffS2PHFn5bQikAAAAgPG3fbs8yqVxZ2rNH+vTT3Lc7fVrq3VtKSJDuvNMcy8pi9b1I4XUo9dRTT6l+/fqqU6eOUlJS1KpVK3Xv3l1du3bVww8/7NVjnTx5Uu3atdPrr7/u0e3PnDmjhIQEPfzww2rXrp23Q0cYyjlV7rffpCNHTLDSsqU5Zk3fGzvW/sWVs0rKm3Dl5El7/9dfpdhYs1+9eu7bHj+e+5g1bTAUCwerV7f7XB07lvdt0tIc2fv+CIJ27zbb9eulnTsLvu2JE/Y+oRQAAAAQPpYsMdsuXaRx48z+c8/lXlX711+lH34w7+HeesuEVAsWmKqq2NjQfF8F3/E6lIqNjdUnn3yiP//8U1988YU+/vhjbdq0SR999JFiYmK8eqz+/ftr4sSJuvzyyz26fcOGDfXKK69o5MiRqmitc48SLWc1jzXlq3lzO4yyKqXmz5dGjTL7OXsmHTni+XNa1TkNGph/FqtSylVeoZR1zFr1LtRUrmy2+YVS/p6+t3evvV/YFD7XSilW3wMAAADCx+LFZtutmzR6tFnRfP16M/PElet7t8xMs7jU7beby6NH20UCKJm8DqUsTZo00ZVXXqmrr75azZo10/Tp09U2VDo7o8TIWSll/QJz/VazwilJ+vFHM7XOF6FUuXLux70NpUI1Ny2sUso1lFq5Urr2Wt+GU3v22PvehFJUSgEAAADhwzWUqlhRuuUWc/mNN9xvl/O92+jR5liNGkVfSR3hw6vSpn//+9+aO3euYmNjdffdd+u8887T/Pnzdf/992vz5s267rrr/DXOIjtz5ozOuLzLTk5OliSlp6crvahNhyKM9XUKxtcrKSlKUrSiopzKynLo79Ons8/OVHq6qfuMi4uWa7760ktZKlfOKSk6+9j+/Rlq0cLp0XMeP+6QFKP4+Cylp2dmH69a1Rx3dfiwPQ7JlJiePm2i/Pj49CL3tfKnihXN1+vQoQxNnSrt3u3Q2LFZ2ec3NTVDrv/PTz4xX+8xY7LyfDxv7dkTI8lMEZw/36njxzMUH5/3bZOT7XObnJyh9HTPziE8F8yfbwQe5zsycJ4jE+c9snC+I0s4nu9jx6T1683r/nPPNe+LBg506LnnYrRxo1Pp6faKUZs2mdf85cs7deKEQ+vWmeOTJ2coPt4Zku+p/C0cz3lOno7d41Dq+eef10MPPaS2bdtq48aN+vbbb/Xwww/rxRdf1J133qnbb79d1apVK/KA/eWZZ57RhAkTch2fO3eu4vN7J4w8zZs3L+DP+fvv50qqrZYtD2v9evv768yZPzRrlimjOnGiq6SE7Os+/tipOnVSJNmlSj/8sEInT+ZeNTIvixbVkdRJp08f1qxZS7KPJyZWlXRBjvFtVr16W7IvJyfHSeovSVq8eLaio0MvRDl1qpOkOlq0aIPee8+UnFWqtFD16pmypD/+WCOps9t9fvlll1q1WuOT59+5c4CkWMXGZur06Wg9//xydeq0P5/b2uf299/XqmLFXT4ZA3ILxs83gofzHRk4z5GJ8x5ZON+RJZzO94oV1eV0nq+aNVO0fPmPkqSDB0tL6qvdu5367rtZkhz66qtmmj3bNAvu0mWn5s1rKElq2/agKlRYolmzgjP+UBFO5zynVA+nungcSr3//vt6++23deONN2rhwoXq1auX5s+fr61bt6qSNR8oBI0fP1733Xdf9uXk5GTVq1dPffr0UYVQbfoTYtLT0zVv3jz17t1bsQGc0Ltli/THH+Zb9K67Kmn0aPu6UaM6Zi8N+s470Vq71uyXK+dUSkq0duwwgVTt2k7t3etQo0bnaMAAzwKipCRTxVO/flUNGDAg+3jDhtKjj5r9qlWdOnzYoZo1z9KAAc2yb7Ntm9mWLevU4MH9vfwfB8aMGdFaskQqW/bs7GPnndddZ59tznOLFrkXEWjQoL4GDKhb7Oc+eVJKTTXfQ1de6dCnn0oHD56rAQPyrsJ66im72q1Jk7YaMKB1sccAd8H6+UZwcL4jA+c5MnHeIwvnO7KE4/n+7Tcz2+GSS+Kz31NlZEi33OJURkaUOnYcoDlzHJo2zY4kxo6tq3nzpLg4pz75pJLOOmtAno8dCcLxnOdkzVIrjMeh1M6dO3XJJZdIknr06KHY2Fg99dRTIR1ISVKpUqVUyuqE7SI2NjZsT26wBPpr9tJL5hfXgAHSDTfE6NZbzUoNFStKjRvHyvH3InGuPaXuv98hqzAuKkq64AKHvvhCOnYsxuMGeVZD7QoVohQba08LrOuSybRs6dCiRVJKSrRiY+3gxAqDK1Z0hOz3V9WqZrt5sz3uqKjY7K9PZmZ0rvukpbn/P4vKWpmwbFnpmmui9Omn0uzZ0YqJic4+n65ce0qdOeObMSBv/E6MLJzvyMB5jkyc98jC+Y4s4XS+f/vNbC+4wH5PZa2kt2uXtGtXrJ55xv0+vXrFaNo0qUYNh1q3Do//p7+F0znPydNxe9zo/PTp0yrt8u4/Li5OCQkJBdyjcCkpKVq1apVWrVolSUpMTNSqVau0a5eZojN+/HiNHDnS7T7W7VNSUnTw4EGtWrVKGzZsKNY4EJqWLTPbW26R4uKkRo3M5TZt5BZgOF0KoG6/Xapd2+w3a2YvH+pNo/OTJ822bFn349aqdZJ0zjlmm7PReaivvCfZjc43bbKPua5sd+ZM7nRon2czHwtlrbxXu7bUs6cJFHftUva88U2bJNdAnUbnAAAAQPhIS5O++sqsjC6ZJueu6tUz23/9S9q50xQSnHee9Pjj5j3e8OFSr16BHTOCy6tG5++9957K/b0kWUZGhqZOnZqrj9Rdd93l8eMtW7ZMPXv2zL5sTbO7/vrrNXXqVO3bty87oLJ06NAhe3/58uWaNm2aGjRooB07dnjzX0GIy8qS/vzT7LdoYbbNm5vpcTkXeXQNhqpVk+6+Wxo7VurSxa4K8sXqe1FR0rx50tGj0okTuZ9bsgOVUF15T7JDKdcfGfdQKvd9fBVK/fWX2dapI8XHmz84s2aZVficTqldO6l1a2VPxySUAgAAAMJDZqY0bJj0zTf2sVat3G9Tv75Zlc9qlfTCC9I99wRqhAhFHodS9evX17///e/syzVr1tRHH33kdhuHw+FVKNWjRw85nfn3+Zk6dWquYwXdHiXH3r0mhIiJMb2cJGnQIOmHH6TBg91ve+yYve9wSGPGSI0bSxddJH35pTl++LDnz51fpZQk/T2DVV99lfu5JTukCodQylVhoZRV4VRcU6aYbfv2ZjtwoB1KWc+7bp0JJaOiCKUAAACAcPHRR+6BVP/+5jW9K6svsCTVrCm3vsGITB6HUlQiIZCsKqnGjZXd6+i226SbbjJT+VzlDIaioqQrrzT7ViHfgQOeP3d+lVKurNApv+l7oRxKuU5DtLiGUmlpua8/eFBKT5fHfbny8uuvpow3Nla6915zbOBAM+VyyRL30t49e6QaNeS2/CuhFAAAABC6li8326uvlmrVkm64IfdtXEOpsWOlMmUCMjSEMI97SgGBtHmz2Z51lvvxnIGUlDuUcmX1l/Jm+plVKVVSQ6miVEo5ndL+/cV73oULzXbIEPuPUYMG0tlnm8qojz+2b7txo3uVlEQoBQAAAISy7dvN9pJLpJdftmdHuGra1GypkoKFUAohyaqUat688NtaPafyquKxQqm9e90bohfECkPymr5nyS+UsnpKhUOjc1eFhVJS8ftKWf2kcp7TgQPNds8e+9jGjXbfLguhFAAAABC6rFCqceP8b3PJJdKLL0rff0+VFAxCKYQkb0Kpjz+Wrr3WXq3PVa1aZnv6dMEVVa48qZSygp0TJ0yVj6UkVErlNX1PKn4otXu32dat6368T5/ct50xQ7r1VvdjhFIAAABAaMrKkhITzX5BoVRUlGnl0bFjYMaF0OfV6ntAoHgTSjVubJrq5aV0aalKFbP63t69efdTysmbSimn0wRTOSunwi2UOn3a3rcqpZo0MX8sjh2T5s4tfrPz/EKpdu1y39ZaQlYy53f7dkIpAAAAIFTt22feR0RHS/XqBXs0CCdUSiHkpKXZKXvOnlJF4TqFzxOeVEqVKmX+Se5T+MIhlCpTRrr4Yvdj7tP3HJKkf/5T+vxz+5MOX03fy/lHqlo1+xxZypeX7rxT2rRJeucdc4xQCgAAAAhN1tS9Bg3MCuqAp4oUSm3btk2PPPKIhg8frgN/L2s2Z84crV+/3qeDQ2Tavl3KzDShUM2axX88b0MpTyqlJHtlP9fHDYdQSpLmzTM9nO64w1zOa/qeFbpZUyCLUyl1+rRZwU/KXSklSY0a2fu7dpkA7NVXTSgZH2+OE0oBAAAAocmTflJAXrwOpX766Se1adNGv/32m6ZPn66Uv9/Br1mzRo8//rjPB4jI4zp1z+Eo/uMVNZQqqFJKklq2NFvXLPbQIbP1ZJpgMDkc5utSpYq5nFej85yhVHEqpayvfZky9nO6sgI+yVRSuQaChFIAAABAaLNmRVirbAOe8jqUGjdunCZOnKh58+YpLi4u+3jPnj21dOlSnw4OkckKpXwxdU8q+vS9wiql2rQx23XrzDYjQ9qxw+w3aeLVEIOmdGmzLSiU8vbrlxfrj1TdunkHjVbAlxdCKQAAACC0Wa/VC/tgH8jJ61Bq7dq1Gjp0aK7jCQkJOnz4sE8GhdB08qSZ7vXFF/59ns2bzdaTJuee8CZUSUuT0tPNfmG/UFu3Ntu1a832r7/MfUuVkurUKdpYA81ahtWT6XvFqZTKr8m5ZexYqUcP6c03c19nBWeuzdgBAAAAhA7rtbr1/gLwlNehVKVKlbQvj3enK1euVJ1weSeOIrnllmi98YY0bJh/n8eblfc8Yc1r/v13s1RpQawqKcn7SqktW8y2SROz1Gk4yCuUyq9Sav9+Uw1WFElJZmsFXDlVqiQtWCDdemv+Yzxzxqx2CAAAACC0WO8nrA+UAU95/dZ5xIgRGjt2rJKSkuRwOJSVlaXFixdrzJgxGjlypD/GiBBw5Ehpff55YJIWX0/f69HDVD3t3i398UfBt7V6QsXFSbGxBd+2VSuz3b/fNPHeutVcbtq0WMMNKE9CqYQEE7I5ndLf6xp4zQr7ypf3/r6uf9iolgIAAABCD5VSKCqvU4annnpK9evXV506dZSSkqJWrVqpe/fu6tq1qx555BF/jBEhYO1auxN1bKz/KlaSk+2qmmbNfPOYZcpIgwaZ/S+/LPi28+aZ7bnnFv64ZcvaVVjr1pWcUCotzTR9skKp6Gh7FcSiTuHztE9XXgilAAAAgNBmvU6nUgre8jqUio2N1SeffKI///xTX3zxhT7++GNt2rRJH330kaKjo/0xRoSAxMQK2fvp6XmHA++/L91wg/Thh0V/HqtKqmZNqUKFgm/rjauuMtsvvyw4UPvuO7MdPNizx3WdwmeFUr4K0wKhoEopl3UMsqfdFbXZuRVKWU3LvRETY0+HJJQCAAAAQo/1foJKKXgrxts7/PTTT7rooovUpEkTNQmXJcZQbImJFd0uJye7/8I5cEC66Saz//HH0oUXmpQ8vx5C+fF1PylLv34mENmxQ1qxQurY0Rx3OqX33pN+/tn0hFq2zBz3NJRq3Vr69lvT7HzbNnMsnH4sPJm+J5m+UsuXB6dSyuEw30upqYRSAAAAQCiiUgpF5XWlVO/evVW/fn2NGzdO66wOzyjxduxwL1s6ftz9etewIjPTTGtr2dKEQN7wdT8pS3y8NHCg2Xedwrdpk/R//2eCtN9+M2Pv3NmM3ROulVJ//WX269f33bj9zQqlrD8iTqd9LmvUsG/nq0qpooRSUt7hGQAAAIDQQKNzFJXXodTevXv14IMP6pdfflHbtm3Vtm1bTZ48WbutNd9R4iQlScePl1ZUlFNVq5pjOUOpgwdz3+/4cenmm+3pcqdOSUeOFPxcmzebra8rpSTpyivN1nUKn9W4u2ZN6b//lVatkhYtMtU5nmjd2mxXrpROnDD74bQIZc6w5+TJWKWmmv983br27axQqqiVUqmpZlvUUMr640alFAAAABB6aHSOovI6lKpWrZruuOMOLV68WNu2bdOwYcP04YcfqmHDhurVq5c/xoggW73ahBTNmtkNr5OT3W+TVyglST/8IE2ZYkKgzp2lRo2kY8fyfy4r22zQoHhjzsuAASbc2LpVWrPGHLMqeOrUMaFVu3aFr7rnqnlzc3vrl3ClSmalv3BhhT1WKHXokDlQrZr7pxy1a5ttsCqlCKUAAACA0EWlFIrK61DKVaNGjTRu3DhNmjRJbdq00U8//eSrcSGErFljQqm2bZ2q+HdrKU8qpSpVMtv77pOWLDFT3JKT7UAoL1Y/I38k7OXKSf37m31rCl9KitkWNSyJjZVatLAvu1YXhYOclVKHD5sDOf8fxa2UKk6jc4lQCgAAAAhlVEqhqIocSi1evFi33XabatWqpREjRujss8/W999/78uxIURYoVS7ds7sFfE8CaUeeEDq1MncdsgQ+3hBlVJpaWbr2mTbl6wpfP/9r6neskKp4lQ3WVP4pPANpU6fNl+P/EIpq1IqGI3OJXpKAQAAAKGMRucoKq9DqYceekiNGjVSr169tHPnTr388stKSkrSxx9/rP5WGQpKFGv6nmulVM7pe4cOme1559nHWreWPvjAVBNZ10vS/v35P5cVSsXFFXPQ+Rg0yARemzdLGzbYYUlxQimr2bkUvqGUZP6QHDpUcKVUUpJpBu8tpu8BAAAAJRfT91BUXodSCxcu1JgxY7Rnzx7NnDlTI0aMUHxR5+Qg5J06Za+I58n0vU6d7GMtW5rA5uGH3W+blJT/81nT9/wVSlWoIPXta/a//LL40/ekklEpJZlzffiw+SuS8/9RvboUFSVlZeXfP6wgNDoHAAAASi6m76GovA6llixZottvv13VqlXzx3gQYtatk7KyHKpY8Yxq1VL29L38Gp136WICjYYNTVNzSRo/Xure3b5tQaGUv6fvSdIVV5jtzJm+qZQK51AqNlaKjjb7S5c6tHev+ULk/H/ExJhgSipas3MqpQAAAICSi0opFFWMJzeaMWOG+vfvr9jYWM2YMaPA21566aU+GRhCw+rVZtuw4XE5HJULrZSqXVvauFFyOEyQIZmqp4ULpTfekO68M7jT9yTp7LPNdu9e31RKNWhgQq2UFLOKX7gpV86cz6FDYyRVlZR3uFa7tgkU9+6VzjnH88fPyqJSCgAAACipMjLsFh9USsFbHoVSQ4YMUVJSkqpXr64hrh2rc3A4HMosSsMZhIz0dDOFbvp06eKL7VCqUaPjkvIPpayeUQkJeVcdORxSzZpm35NKKX+GUlVN7qLDh33T6DwqSrrhBmnWLPeeWuFi4kTpww+lgwedSkrKVP360Tr3XEeu27VsKa1YIf30k+nN5SnX5uRFnelLo3MAAAAgNLl+cEylFLzl0fS9rKwsVf977k5WVla+/wikwtvvv5vQoHx56frrpaFDpVWrzHUNG5r5enlN38vKMgGPJBU0q7NGDbMtqFLK6inlz+l7Vih1+rRd4VWcUEqSXntN2rpVqly5eI8TDHfcYc79n39m6LPPZmrduozs8+zq8svN1lq50FPW1D2p6KEUlVIAAABAaHL94JhQCt7yuqfUhx9+qDNWcuAiLS1NH374oU8GheD49FNTemn54w9p0SKz37ChKY3Kq1Jq3z4TTEkFh1KhUilVrpzppSRJu3aZbXGm71kcuYuLSpR+/UyotHOntHy55/ezpu6VKWOqyoqCUAoAAAAIHfPmSY0bSz//bL9Gj4sr+ut9RC6vv2VGjRql4znnbkk6ceKERo0a5ZNBITh+/tlsx46VrrnG/bq6dc08t7xCqQceMNv27e2wJy9WKJWS4l49Y8nMtOci+zOUcjikKlXM/s6dZlvcSqlIEB8v9e5t9q3vFVdZWWalxpxVVMVtci4RSgEAAACh5JNPpMRE6dVXaXKO4vE6lHI6nXLkURKye/duVbQSC4Sd48ftqXp33SVNmGBfd845WYqJMUmDNT3tyBGz/e9/TYVVdLT07rsFP0e5cnZvoLym8FlVUpJ/p+9J9hS+o0fN1heVUpHAanC+Zk3u6x58UDrrLOmll9yP+yKUoqcUAAAAEDp27DDb+fPt1/s0OUdReNToXJI6dOggh8Mhh8Ohiy++WDEx9l0zMzOVmJiofv36+WWQ8L8lS0ylS5MmZpU1SdqzR3rhBWngwCydOGGOWX2hDh401996q7n80EPSuecW/BwOh1S9uqlOOnDAlHu6cg2l/FkpJdmhlIVKKc+0bWu2VgN8Vy+8YLYPPijdd5993PojVdR+UhKVUgAAAEAosWacHD1q3ktKVEqhaDwOpaxV91atWqW+ffuqnMu7+Li4ODVs2FBXXHGFzweIwLCmY3Xvbh+rXdsEDenpTs2aZY4lJJhwKStLuuIK0+C8QwfpkUc8e56EBPMLzFqtz5VrKFXQNEBfIJQqmnbtzHbDBrNSY17nKecfI6bvAQAAACVHZqa0e7d9+bvvzJZKKRSFx6HU448/Lklq2LChhg0bptLEoCVKXqFUXmJiTKBz6JD0228mlPjwQ88rmxISzNZa9c6V1T8/Ls7/TcNzhlJM3/NMw4ZmdcYTJ6RNm6Q2bXLfJuevBqvROaEUAAAAEP727nVfIGvBArMlIkBReN1T6vrrryeQKmFSU81Ke1LhoZRkT+GTTHPz1q09fy5rdb68QqlArLxnoVKqaBwOewrfunV538aflVL0lAIAAACCy+onZVVGWe/jiAlQFF6HUpmZmXr++efVuXNn1axZU1WqVHH7h/Dz229mKladOlKjRoXf3jWU8uT2rgqqlApmKEWllOesnmN5TcGU/BNKWX/wqJQCAAAAgsvqJ3XeeVK9evZxpu+hKLwOpSZMmKAXX3xRV199tY4fP6777rtPl19+uaKiovTEE0/4YYjwN9epe55Mm/NFKJVXoOE6fc/fcuanVEp5rkIFs01Oto85nfZ+zlDKapJfnK8x0/cAAACA0GCFUg0aSJdcYh+nUgpF4XUo9cknn+jf//63xowZo5iYGA0fPlzvvfeeHnvsMf3666/+GCP87JdfzNaTqXuSeyjVsKF3z+XJ9L1Spbx7zKJwrZSKiQlMEFZSWKGUFTZJdjWUlPuP0b59Zuv6feMtQikAAAAgNFjvH5s0kXr3to9TKYWi8DqUSkpKUpu/uxuXK1dOx48flyQNGjRIM2fO9O3o4HdpafYSnkUJpcJ1+p41BU0yTfr83Vi9JMmrUuroUXs/59fSCqVcv+beoqcUAAAAEHxr10r/+595zT98uNSrl30dlVIoCq9Dqbp162rf3+8ymzZtqrlz50qS/vjjD5UKRIkLfGrFCvNGv1o1qWVLz+7jr1AqkNP3zj3XDlfgnfLlzdY1lDpyxN7PGRzt3Wu2tWoV/TnpKQUAAAAE3/PPm+0VV0hNm5r3htZCSIRSKAqvQ6mhQ4fqxx9/lCTdfffdevTRR9WsWTONHDlSN954o88HCP+y+kldcIHn1UJRLt81DRp493wF9ZQK5PS9qChp+XKpfn1p9Gj/P19JUlilVM5QypeVUoRSAAAAQHD89Zc0bZrZf+AB+3jfvmbLumcoihhv7zBp0qTs/SuvvFJ169bVkiVL1LRpU1166aU+HRz8z7XJuadatLD3vQ2QrJ5SJ06YyqhSpaQFC6SFC6UOHcx1gerv1LSpWc6UqXveyaunlGulVGqqve90+qZSilAKAAAACK633zatT7p3lzp3to+PHWsCqZEjgzc2hC+vQ6mcunTpoi5duvhiLAiwzExp0SKz700odd550mefSc2aef+clSqZxuIZGdKBA6Z6xpqHPGKE2Qay6TiBlPe8qZQ6dsyellmcUMqaMnjihJSeLsXGFv2xAAAAAHjPKmgYNcr9eNWq0rhxgR8PSgaPQqkZM2Z4/IBUS4WPtWul48fNG/527by777BhRXtOh8NMmdu+Xbr0Uummm+zrrGletCYLbXmFUvlVSllVUpUrF2+Oec2aUny8eezERKl586I/FgAAAADvZGVJq1aZ/U6dgjoUlDAehVJDhgzx6MEcDocyMzOLMx4EkFUl1a2bqV4KlDfekK65xvxSu+MO+/iBA2YbyEopeM+qWtqzR/rvf00l1OLF9vXp6aYSLibGN/2kJNMD7KyzpJUrpU2bCKUAAACAQNq6VUpJMR80u7ZzAYrLo0bnWVlZHv0jkAovW7aYrbVaQqD06ydt2CBddZX78T17zJZQKrRZlVKnTklXXy1dd5307bfut7Gm8FmVUsUNpSQTSkkmlAIAAAAQOCtWmG3btoEtaEDJ5/Xqeyg5duww24YNA//cNWpIX3whzZplpvNJpv+QxPS9UGeFUpYOHaTevc2ysBYrlLIqpYrTT8pifSKzeXPxHwsAAACA56xQ6pxzgjsOlDxeZ5xPPvlkgdc/9thjRR4MAmvnTrMNRihl6d9feugh6ZZb7GNUSoU2a/qe5d137XnlZcqYFfKsvlK+rJSyQikqpQAAAIDAOXNGmjbN7HfrFtyxoOTxOpT6+uuv3S6np6crMTFRMTExatKkCaFUGLEqpRo0COowlJDgfplQKrTlXPmuUSN7Pz7ehFL+qJRi+h4AAAAQeB99ZFqt1K6duwULUFxeh1IrV67MdSw5OVk33HCDhg4d6pNBwf+OHTMr70mhF0oxfS+8VKli75cpY7b+qJRq0sRsjxwxTRbLlSv+YwIAAADIX0aGNGmS2R8zhvdq8D2f9JSqUKGCnnzyST366KO+eDgEgDV1r1o1qWzZ4I6FSqnw5nDY+1Yo5Y9KqfLl7SDKelwAAIBwN3269P77wR4FkLcvv5S2bZOqVpVuvjnYo0FJ5LNG58eOHdNxq/QGIc8KpYJdJSURSoWznFP54uPNNjVVcjp9Wynl+jjW4wIAAISzI0fMYjE33cSHbgg9Tqf09NNm/+67makA//B6+t6rr77qdtnpdGrfvn366KOP1K9fP58NDP4VzJX3cqpcWYqOljIzzWVCqfBRtar7ZddKqePHTX8pyTeVUpIJpf78k1AKAACUDLNn2/uHD/vuNRPgCzNnSmvXmjDqjjuCPRqUVF6HUi+99JLb5aioKCUkJOj666/X+PHjfTYweCcjQzp40PM/ZH/9Zbb16vlvTJ6KijLhxoED5jLzlMNHly7ul10rpazgqHJlqXRp3zwflVIAAKAk+e47e//YsaANA8jTBx+Y7a23mtf0gD94HUolJib6Yxwopnvvld56S5ozR7rkEnNsxgzpkUekTz6R2rRxv731pr5OncCOMz/Vq9uhFJVSoW/hQvP99sor7sddK6V82U/KQigFAADCkdMp3Xefec1rfY5/+rR57W4hlEKo2b7dbHv0COowUML5rKcUgmvVKjP9zVoZQZIuu8yUW/bqlfv2e/aYbaiEUk2b2vuEUqHvooukzz6TatRwP55XpZSv+klJdsBFzwUAABBO/vxTevll6aGHpPR0c+zbb+3VsCVCKQROerqUnFz47az3jHXr+nc8iGxeV0qdPn1ar732mhYsWKADBw4oKyvL7foVK1b4bHDwXGqq2f74o7RundS6tX3doUPm0xnXVdL8ERgUR5s20jffmH2m74Uv10op63uSSikAABDprD6bkmm5Ubu2NGWK+20IpRAo/fpJK1dKy5ZJjRvnfZvTp837SCl0ChlQMnkdSt14442aN2+errzySnXu3FkO16QDQXPqlL3/2mvSO++Yeb9Hj5pjq1ZJHTqYfacz9CqlXKcXUikVvlwrpazvPV8Gn4RSAAAgHKWk2Pv795sZDnPnmsu9eknz5xNKITCSk833myTdf7/09dd53856vV26tFSlSmDGhsjkdSg1c+ZMzZo1S926dfPHeFBErqHURx9JTz7p/odt3jw7lEpO9k8VS3G0bWvvx3j9XYlQYS0Tm5zs/55SOav/AAAAQpXrNL39+6VZs8xrmYsukjp2JJRC4KxaZe9/9515XZ3Xh8i7d5ttnTq85oZ/ed1Tqk6dOipfvrw/xoJisEKpChXM/sSJ5g+dxXVWpZV6V6wolS0buDEWxLWnlFXFhfBTs6bZJiX5t6fUyZPSiRO+e1wAAAB/cu3fk5RkT9278UapUiWzb1WZ57Rxo+nl6fraHigq1/eFmZnS1q15345+UggUr0OpF154QWPHjtXOnTv9MR4UkRVK3Xab2b7+uvv1K1fa+6E2dU+SoqPt/VAaF7zj2ojcH5VSZcuaMFViCh8AAAgfrpVSX30lbdsmlS8vXXGFHUrlVyk1bJg0fLj00kv+HiUiQc4W0LNmmVW1MzPdj4fie0aUTF6HUp06ddLp06fVuHFjlS9fXlWqVHH7h+CwQqkbb5SqVbOPN2tmtlu22HPZQ63JuWXFCun5580fXYQn11DKX99nvu4rNXu21Lev9Ndfvnk8AACAnFwrpb7/3myHDTMfuBUUSu3fb1bTlkz/n/yqqQBP7N0rLVzofuzZZ01hw9Sp7set6XtUSsHfvO7eM3z4cO3Zs0dPP/20atSoQaPzEJCZaS8tW7my9M9/ml8ukukjdfKk+QW0erXUrVvopt4dOth9rxCerFBq06bcx3yldm1Txu6rUOrNN02j0a++ku65xzePCQAA4Mq1UsoyapTZVq5stseOSb/8Yl7nXHyx1KSJ9PPP7vf54Qfpqqv8N87MTGnSJNPr6oIL/Pc8CLyZM6UbbjAr6lWtKp1/vh2QSqYn8bXX2iuhh+p7RpQ8XodSS5Ys0dKlS9WuXTt/jAdF4NrkPD7eVEtZoVRUlAl69u41U/i6dZMOHDDX1agR+LGiZMsZQFWqJJUp49vn8HWl1JEjZrtrl28eDwAAIKecoVS9eiYUkOxKqRUrTBhk9Y5q2tSsfObK9YM/f3jtNemRR8w+PazC39GjJmh84w3piSfMsfbtpc8/Nx/Mutq1S3r/fbsdTFKS2YbKwlgoubyevteiRQudck1BEHSup6N0aal5c/ty8+ZS585mf/Fisz182GyrVg3M+BA5KlZ0f/Hkjz9ivg6lrFJ5pu8BAAB/cZ2+J5nWAdaEEyuUkkwQ1LatWY1661Zp3TpzvFMns/V3KDVnjr3PW77wlp5uAqiEBDuQuusu6ddfzXvEvN4LPvWUfd4PHTLbhIRAjBaRzOtQatKkSbr//vu1cOFCHT58WMnJyW7/EHjWL45SpUxllCRt3iyNHSuNGSN1726O/fyz+UNn/YJx7T0F+ILD4R5E+aNvma9DKas3A6EUAADwl5yVUn372vuuoVTz5qblxuHD0jffSLfcIo0eLT34oLnen6GU02mHYJK0YYP/ngv+t2GD+0yA/v2lV16xp+e5toOuXl2qX9+8vn7nHXOM94wIFK+n7/Xr10+SdPHFF7sddzqdcjgcyszZth9+l5pqtq7TpJo3N/PBJem886S4OPNLZvt2KqXgX7VqSYmJ9r6v+atSiul7AADAX3J+dt+rl73vGkpZb7EqVJAuu8z8k8wHzpIJpbKy/DPGjRvtPkKSCcc6dvTPc8H/li93v3zrre6XXUOpOnXMtL2bb5aeecb0KLZaXBBKwd+8DqUWLFjgj3GgGKxKqfx695QpY6bwLVok/fQToRT8q1w5e791a98/vi9DqTNn7J+fpCQpLc0EuAAAAL5kVUrdeKN0xRXugYBr64PBg/O+f+PGZkpfaqoJjmrW9P0Yv/nG/fKaNb5/DgSOayj1j3+YSilXru8Fq1eXrr/eBFLbt0v/+pcdfvKeEf7mdSh10UUX+WMcKIbCQinJTOFbtMhM4bNCKVJv+IPrvPM77vD947uGUk6n3Y+hKFyXXnY6zWM2bFic0QEAAORmVUrdeKNZeMiVwyF99JEJm/6elJJLbKxpfL5pk6lo8kco9eWXZnvBBeZ9w+rVvn8OBM6KFWY7bZo0fHju612D0Ro1zPfYE09II0dKzz1njlesaI4D/uR1KPVzznVJc+huNTBCwHgaSj39tDR/vv1GnNQb/jBunJSSIj36qFS2rO8f35oSeOaM6Qfl+gfVW1Y/KcuuXYRSAADA96xKqQoV8r7+2msLf4xmzUwotXWr1LOn78YmSdu2mZW6o6OliROlHj2k334zr7esHkQIH+npdqiY3xTMnD2lJGnECFMltWWLuUwRAwLB61CqR48euY45XEoV6CkVeJ6EUl27mj8yrs2cK1f277gQmVq3zl3+7UulSplA9fBhU9lUnFDKtVJKotk5AADwD6tSqmLFoj9GkyZmu21b8ceTk1Ul1bOn+TC7Zk3T2mDxYvf+VwgPS5aY94jVqpkKu7y4voa2wtLoaOnCCwmlEFher7539OhRt38HDhzQnDlzdO6552ru3Ln+GCMK4UkoVb68dM459uXKlc28dCAc+aqvVM5KKUIpAADga2fOmH9S6IdSV11lphP27m0uz5vn++eC/82ebbZ9+9qrs+fk+r3oOkXvrLPsfUIpBILXoVTFihXd/lWrVk29e/fW5MmT9aC1VikCygql4uMLvp3rzEqm7iGc+SqUylkpxQp8AADA16ype5L7gjDe8lcolZgoLVtmwoshQ8yxPn3MllAqPFmhVM7m5q5c+7K6Fis0b27vE0ohELwOpfKTkJCgzdZapQgoTyqlJMm1Rz2hFMKZv0IpKqUAAICvHTxotpUrm+lRRWWFUtu3mwVafOWrr8z2oovs3kLW+4ZVq8yKf5J5Tl8+L/xj3TqzcqLDYSqlCmIFUJddZh9zrZTiPSMCwesJXGtyrA3qdDq1b98+TZo0Se3atfPZwOA5T0OpCy4wv5ycTlJvhDer2bmvpu/VqiXt20coBQAAfG/nTrNt0KB4j9OwoalmSk01/Z585b//NdurrrKP1a1rPgTcu1davtwcu/ZaqUsX6fPPfffc8I2MDBN4OhzSpEnm2OWXF/6eb8UK6dAh9+9NK/yUTMN0wN+8DqXat28vh8MhZ46YvEuXLvrggw98NjB4ztNQqnJlqU0bk5yTeiOcWZVS+/Z5fp/Tp6XSpd2PWZVSbduax2L6HgAA8DVfhVJxcVK9eubxtm93FH4HD+zcKf3+uwkzhg61jzsc0nnnSV9/LT3yiGmcnZEhHThgPuB2+Obp4QOpqVKrVqbC6e23pc8+M8fHjy/8vmXL5l4tOy7O3j982HfjBPLj9fS9xMREbd++XYmJiUpMTNTOnTuVmpqqJUuWqEWLFv4YIwphldQWFkpJ9uoZder4bzyAv3k7fe+WW8zPR7t20r33Sj/9ZI5blVJt29qXT5707VgBAEBks0Kp+vWL/1i+7iv1889m26WLWXHPVZcu9m0yMsz+6dNSSkr+j5eaWvD18L3Vq8332Ny50j33SJmZplF9x45Ff8zhw8323nt9MkSgQF6HUg0aNHD7V69ePZXOWX6AgPK0Ukoyifkzz0h33eXfMQH+5G0oNX++2a5ZI738stSjhzRzpl0p1aCBvRQuU/gAAIAv+apSSnLtK+WbUiWr31WjRrmvu+ACs7WmhFmLKln3ySkrSzr/fKlFC+nECZ8MDx5wbaQ/Y4bZelIlVZCPPjKzCDp1Kt7jAJ7wOJSaP3++WrVqpeTk5FzXHT9+XGeffbZ++eUXnw4OnvEmlKpeXRo3LvcnIUA4cZ2+l5VV+O2t6qd//cteTWbyZLPajGR6StWrZ/aZwgcAAHwplEOpQ4fMNq/WHuefL733nqmUGjtWSkgwxw8cyPux1qwx//bskZYu9cnw4IGc56NLF/MBbHFER/N+EYHjcSj18ssv6+abb1YFq5zARcWKFTV69Gi9+OKLPh0cCvfTT9Kbb5p9T0IpoCSwXhSlp0t55OS5WKHUVVdJH3xglr39+We7cWfbtnYoRaUUAADwJf+EUsV/LMnuGZRXQ2yHQ/rnP+2KKWtlvvwqpX74wd5ftsw340PhcoZS48fT8wvhxeNQavXq1erXr1++1/fp00fLrXd4CBjXFJxQCpGiVCkTLEme9YCyblO2rOmnNniwfV18vNS4sd3ngVAKAAD4SlqavTBLuFVK5VRYpZRrKPX778UbFzy3f7+936ePNGhQ8MYCFIXHodT+/fsVGxub7/UxMTE6mF9sDr/IsQAioRQihsMhlStn9gvrWZCWZjfntFYXGTjQvr5NG7O8cs7pe6tXSwMGSBs3+m7cAAAgcqSnm8bTTqd53WKFOsVhhVKHDjmUmur1Quq5FFQplZM1/rze8mVm2k3TJenbb6Vhw2h6HghWSDhpkvS//5nXtUA48fhbtk6dOlq7dm2+169Zs0a1atXyyaDgmT173C9bvaWASFC+vNkW9mLHtZLKCqX69rWPWWFUzul7AwZIs2e7B1gAAACeOHzYvN546y27UbgvplRVqGAHSElJZYv9eN5USlnT9/KqlEpKst+LWKHIF19IN92U+4N0+JZ1PqzzA4Qbj0OpAQMG6LHHHtPp06dzXXfq1Ck9/vjjGkStYED9+af75Tp1gjMOIBisSilPQ6mYGCkuzuzXrWtfb5XS55y+Z63sZzVDBwAA8ERKimkSvmCBeb3yzTfS7bf77vGtaqmkpPhiP5ZVKeXN9L28KqWsvlkNG0r/+Y/5/0vS559LtB32L0IphDuPQ6lHHnlER44cUfPmzTV58mR9++23mjFjhp599lmdddZZOnLkiB5++GF/jhU5WKFU8+am2fkVVwR3PEAgeRtKlc3xYeLs2aas/JFHzGXXSqmcUwLz650AAACQ09y50pYtUo0aZhW6Sy/17ePboVTxKqWcTu+m7xXU6NwKperXl669VlqyRHr9dXPswQel+fOLNVTkY+1a03JCIpRC+PJ4InKNGjW0ZMkS3XrrrRo/frycf9dhOhwO9e3bV2+++aZq1Kjht4Eit82bzXbQIOnWW4M7FiDQihtK9etn/lms6qnU1NwvnBYvloYOLfpYAQChz+mUbrnF/H154YVgjwbh7KefzPaKK6TWrX3/+FYotW9f8UKpEydM3yvJu0qppCTzGqpWLWnKFHMsrxUGb7vNNDz/8EPzQeD27Xb7BRTfzp3SOeeYfl4SoRTCl1fd8Ro0aKBZs2bp6NGj2rp1q5xOp5o1a6bKlSv7a3wogGulFBBprBc1hTU6zy+Uyql0afNi6+BBU2bv6vvvCaUAoKRbv156912zP3EiC8ig6KxQ6qKL/PP4vqqUsqqkypQxqxEXxgo9Vq+2q3NeekmqVCnvUMrhkN5+21SOJSWZ+1xwQbGGDBe//WYv5iP5ppE+EAxF6s1fuXJlnXvuuercuTOBVBARSiGSFVYptWKF9NlnnodSkt1Xas4cs+3Vy2ynTbNfuAEASqbFi+19fuejqI4eldasMfvdu/vnOXwVSnnT5FzKe4qfNXPDWr3YNZSSTOBlvb46csT7MSJ/1tfe4kmwCIQiFowMYz/8YD556Ngx2CMBAq+wUOof/5CGDze9HCTPQimrr1RSkv0YHTpIp09L771XvPECAELbokX2PqEUimrFCjMVtEkTqWZN/zyHFUodPlxGaWlFfxxvmpxLpiIqp02bzDavSimL9fj8XPnWhg32Ps3kEc4IpcJYgwZS795maVgg0hQUSqWlSdu2mf2ffzZbb0IpS61a0t13m/033nAvkQYAlCxUSsEXtm412xYt/PccNWtK8fFOZWU5tGNH0R/H20qpChXMlDxXmzaZnxdrHFZVlKsqVcyWSinf2rjRbGfMkO69N7hjAYqDUApAWCqop9Tu3VJWltlftsxsvZm+Z6lVyzTmTEgwq/Ll7DUFACgZ9u6VEhPty9abdcBbVijVtKn/nsPhkBo1MvvbtzsKvnEBkpPNtmJFz24fFZW7WmrePOncc027hJo1pYYNc9/PCqUIe30nM9OevteyZXDHAhQXoRSAsFRQpZRVQu56vXX7guRVKVW6tDR6tLn86qvejxMIB38vqAtELNcqKYk3zyiamTNNSCNJzZr597kaNza/uD0JpZxOE5ZZH9hZvOm7ackZSi1fbgLdxo1NW5FSpXLfx6rEolKqeM6cidaVV0arWTPzgenp0+brbQWUQLgilAIQlgoKpfIqZfd2+p7DYa8yc+utUkyM9Msv0sqVXg8VCGkjR5oFMwpbyRIoyQilUFy//y4NGmSvSufPSilJatLECqUKv+3HH5uQbPJk9+OpqWbrTSiV1xpXffpIf/whtWmT932olPKNTZuqaMaMKG3dahrqS9KQIVJ0dFCHBRQboRSAsORppZTF21AqIcEEUZJUu7Z01VVmf8oU78YJhDKnU/riC/MJujXVFYhEVpNzaxo3b57hrfXr3S/7O5Rq3Nhst20rvFJq7lyznTrV/XhxK6WioqTnn5dmzbKDp7xQKeUbp06Z9KlNG/P9lpQkffppkAcF+AChFICw5I9KqVq17E+batVyv27AALO1PgEFSoLDh6UzZ8y+1QcFiDQpKdKqVWb/ssvMllAK3jp92v1yXqvQ+VJB0/dWrDCvW1atkj780P7QYfNmacsW+3ZFCaVcK6X+9S/p/vsLr9Sh0blvpKWZL3RCgtSqlVSjRu7G80A4ign2AACgKApqdG6FUg6H3SvHkxdcMTGmKuqvv3KHUq1ama3r8rtAuNuzx94nlEKk+v130zS4fn2pXTtzjFAK3nL9nilb1q629hcrlEpMNL2iolxKDfr1kw4elGbPzn2/776T7rvP7Be3UsrTBulWpRQ/V8VjhVJlygR5IICPUSkFICx5Mn2vSxf7mKcvuKwpfDVruh9v0cKEXIcOSQcOeDdWIFTt3m3vE0ohUllT97p1s988s/oevGV9zzRoIC1Z4v/na9BAiorK0unTDu3b537dwYP532/GDHu/uJVSOZue54dKKd8glEJJRSgFICzlF0plZJhKJ0kaONA+7ukLLqufSM5Kqfh4e3UTqqVQUhBKAXaT8wsuoKIDRWeFUnfcIbVt6//ni42VEhJOSZK2bbOPZ2YWfL9Fi+xwKFCVUlYodfKkPWUc3ktLM2/dCaVQ0hBKAQhL+YVSe/eaF2SxsVLv3vZxT19wXXutdPbZ0tChua9jCh9KkhEjpFtusS9v3WpPdwUigdMpPfOM3QS6WzepWjWzn1cotXChmfbUu7dZ/CIjI2BDRRiwvmes76FAqFnTpEquK/DltdiLJDVsKLVubV4jWdP6AlUpVbGiPb2QaqmiO3OGSimUTIRSAMKS1VPq9Gn3NwZWP6kGDUy4ZPH0BdfAgdK6ddK55+a+znq8nCvsAOEmMzP3ij2pqWYlHyBSbNggPfSQ2a9Wzbxhtyqljh1zf6O/e7dpHP3SS9IPP0hffin98UfAh4wQZlVKBTKUql49VZK0a5d9bONG99tERUldu0rTpkmXXmqOffed2QaqUioqyg6zqEIsOqbvoaQilAIQlsqXN9VQkjR/vn3cNZQqW1Zq3txc9sWLxBYtzHbz5uI/FhBM+fXLYQofIolr1eu8eWYFsYQE6fzzzbEhQ+ypUI8+Kp065f6GfP/+QI0U4cD6vWoFm4FQrZqZvucaSlnf1506STfeaBqhL15svq8HDzbXzZ4tpaUVP5TytFJKsnt23nWXdOWV5ucJ3iGUQklFKAUgLMXGSqNHm/1bbrHfOFhl6w0bmu2UKdKLL5oXZ8VlBVx//ln8xwKCKeeb6bg4syWUQiSxPmC4/nqpfXuz73BI//2vebO9dq2ZsrdqlfSf/5jr58yx39gTSsFVMKbvWT2l8gqlBg+W3n/f7pUpSZ07S9WrS8nJ0i+/FC2Ucg1EPK2UksyKgJK0YIH01Vem2hDeoacUSipCKQBh6+mnzZLLiYn20vaulVKSKVm/9173pZKLygql/vrLTHUCwtWBAw63yz16mO2WLYEfCxAs1gcMZ53lfrxOHVPJIZlprmPGmP5T//iHdN55Uo0a5rrt2+2/OYg8mZnSRx+Z76O0NOnECXM8VEIpqw+mq6goadAgsz9jRtFCqehoe9/q7+kJa+qgJa+fnW+/lS66yP3/AxuVUiipghpK/fzzzxo8eLBq164th8Ohb775ptD7/PTTT+rYsaNKly6txo0b6+233/b/QAGEpPLl7RVdjh4125yVUr5UtardE4GKEoQzq8KjYkXTW8T6BJvva0QSq1LK+sDB1YgRZvv++9KPP5pqwqefNsesUGryZLMq63XX2R+MIHLMnCmNHGmq7F5+2RyLivKueqi4qlWze0o5neaf1VMqr1BKsiv9vvuuaKFUly6mx+bgwd594Ne5s/vlnL2vJDNl9uefpdtv9/xxIwmNzlFSBTWUOnnypNq1a6fXX3/do9snJiZqwIABuvDCC7Vy5Uo99NBDuuuuu/TVV1/5eaQAQpUVSlmrueSslPIlh8P+RJ0pfAhnVqXUwIHmU/OmTc1xQilECqfTDqVyVkpJUvfu7otl3HmnCaAkO5SyfPyxeYxnn2UFy0iyerXZnjoljR1r9qtW9U1ltqeqVTudPYbDh004euKEqSK3fq/n1Lu3VKqUqTI/c8Yc8yaUioszU1u//da7sUZHm0UCunY1l3OuZJyWZu+zoEzeqJRCSRUTzCfv37+/+vfv7/Ht3377bdWvX18v//1xRMuWLbVs2TI9//zzuuKKK/w0SgChzLVSKivLLvn2R6WUZD5R//VXmp0jvFmVUtaba9dQyuk0ASxQkh08KB0/br7XmzTJfX10tOkfNWCAlJ4uPfywfZ1rKBUXZ3oWLlkijRtn/ibdfLP/x4/gs6Y7t2snrVljfncGssm5JMXGZqlmTaeSkhzatctutt60qd0rMKeyZaWLL5ZmzXI/5o2i/o24+GIT7jZpIm3aZKZAWtMB1661b3fokHlNF8iALxxQKYWSKqihlLeWLl2qPn36uB3r27ev3n//faWnpyvWWorLxZkzZ3TG+hhAUnJysiQpPT1d6enp/h1wCWF9nfh6lWzhep4rVYqWFKWDBzO0a5dT6emxio52KiEhQ/74rzRuHCUpWn/+maX09EzfP0GAhet5R9FY53nfPlPOUa1aptLTs1S3ruRwxOjECYf27k1X9erBHCWKK1J/rg8eNKGQa8+b/Kxa5ZAUo0aNnIqJyfvvRY0a0rJl5o1zTIyyb1O1qrmvJDVp4tSCBRn617+iNHFitB591KkrrshQ+fI++295LFLPe7D8+ad5/TF2bIYqVZLuvTdaw4dnKT09KyDPb53nunWzlJQUre3bM7Rzp0NStFq0KPg1Su/eUZo1y/ygOBxORUf75zVTXmrXlsqUidGpUw5t2JCevbLx0qXm9ZVkqr1Wr05X69b+Hcv27VKFCoHtA1ZU6enp2ZVSsbEZSk+nLLOkKwm/0z0de1iFUklJSaqRo2a6Ro0aysjI0KFDh1SrVq1c93nmmWc0YcKEXMfnzp2r+Ph4v421JJo3b16wh4AACLfznJp6jqR6Wrp0s44ePSLpQlWtmqq5c3/wy/MlJTWU1E5//pmkWbP+8MtzBEO4nfdwtmlTZX36aQuNHr1GtWufDMoYNm48Iqm69u9frVmz/pIkVavWWwcPxuvjj5eqRYujQRkXfCuSfq5Xr66mJ57oqjp1UvSPf2xS1657C6yy+PbbJpJaq3r1fV7/Lt+9u5ykiyVJFSokafbs39WunUMJCZdo//54PffcCnXpklT0/0wxRdJ5D6YNG/pJKqWkpF8UH5+sZ581x10rkAIhLi5JUh3Nnr1Ru3eXl9RQsbFbNGvWpnzvk5ycIMnMoytVKlOzZwd20PXrX6jNm6uoT58zevDBP9S4cbK++sq8nrO8+eYmDRq03W9jOHKklG680TRU/OYbL+ciFuLo0VL688/K6tw5yaeVx2lpF0mS1q37Q3FxB3z3wAhp4fw7PdXDlaHCKpSSJEeOn2zn35P3cx63jB8/Xvfdd1/25eTkZNWrV099+vRRhQoV/DfQEiQ9PV3z5s1T796986xGQ8kQruf5xx+jtHChVL16C9WubX4ftGxZRgMGDPDL8x096tDbb0vlytX023MEUrie93B05ozpeTZ0aIycToemTOmlxYsDW21nne/MTPOxcO/ebdW3bxtJUuvW0VqwQEpI6KoBA/gENpxF4s/1hg1Rcjod2r27vJ5//ly1auXUW29l6vzz8/5e/uILU3HQr18Nr3+XHz0q3XGH2e/cuXr2/T/6KFozZkh163bSgAGBqZZxFYnnPdAyM6VPPnHonHOcOnHCfI1vuOECr1ah8xXrfJ93XnUtWSLFx7fSyZPm/dDgwU00YEDjfO/bqpX0+ONmv3z56IC/nqlTR7riCqd27Sqn8eN7aNKkLC1fblLkSy/N0owZUVqypLXeeKOFkpOl775z6KqrnCpVyndj+OYb+72jr///l14arTlzojR+fKYmTPDN7wJTKWVeM3Tvfq66d+fvdElXEn6nW7PUChNWoVTNmjWVlOT+ydOBAwcUExOjqvlM4i5VqpRK5fEbLDY2NmxPbrDwNYsM4XaerR/95ORo7d5t9hs2jFJsrH8aEVSqZLapqf57jmAIt/Mejp58Upo40b78xx/B+x46eNC8GK9TJ0bWaW/WTFqwQPrnP2P00kvSF19ILVsGZXjwkUj6ubZe97ZqZZo9b9jg0GWXxWjZsrx7Rq1ZY7YdO0YrNtaD+X4uEhLs/SpV7PvXrGmOHTrk/WP6UiSd90B7+GHpuefsnj61akmVKwf3a920qfk7kpgYnd08vG1b+3d7Xhq75FXHjjkC/v3SqZO0cqVZvXDmTIfuvdf8vDRtKk2dGqW6dc3P8NKlsfr4Y+m998yqfFOm+G4MWS5ZUVRUrEfTfj01Z47ZPvNMtJ5+2ncPbDWDL1++4POLkiWcf6d7Ou6wekd1/vnn5ypfmzt3rjp16hS2JwpA8biuvmetvOevJueS3Qw0JcV/z4GSyTWQslirRgZSYmIFJSU5FBUl1a9vH3ddqWndOtPgeds203MDCHXHjpnt1VebvwVduphjl18u5Zw9cOqUvRx9hw7eP5drcf6559r7VoeJA8yqCXu7dkl33WUa2Lt67jmzPXXKbJs1C+y48tKokamY+fVXU8UXFWUWZSmIawATrHY1VapIM2ZIzzxjNzS/+WapcmXp2mvN5TfeMIGUJE2d6tvVLV1aDuv0ad89riS3voxHfTgbntX3UFIFNZRKSUnRqlWrtGrVKklSYmKiVq1apV1/L581fvx4jRw5Mvv2t9xyi3bu3Kn77rtPGzdu1AcffKD3339fY8aMCcbwAYSAypXN9uhRaedOs9+ggf+ezyrRJ5SCt/Kq1li8OPDj+Pprkz5ddZX7SlE531zt2GGCqmbNpF9+Cdz4gKKw3vhVqmT+ffmleWO4Zo2U82WitepX1aqm6XJRLFggvfyyCW8t1htRa3VLhK833pBee0264AIzVfPbb82/nEIplDp82LocPqFFVJRZtXLxYumFF6R77zXHb7/dbKdPd7991aq++3tkBYtS7uC6uFw/8PFljzFW30NJFdRQatmyZerQoYM6/P0x1X333acOHTrosccekyTt27cvO6CSpEaNGmnWrFlauHCh2rdvr3/961969dVXdcUVVwRl/ACCL9CVUoRS8KWffw7s8+3YIS1aVEeSNHas+3WulVItW9qBVVaWb6dMAP5ghVLWBxV16kgffWT2P/zQ/U1nYqLZNm1a9KXte/SQ7r7b/f5USpUcW7aYrdNpAqohQ8y/nEIhlKpf373yqVUrz+5nvX4KBV26SPfdp+wpaW3bmkAwM0fbxaNHpYEDpbVri/+crq1uXAMqX3CtvPrDh2vipKWZt+6EUihpghpK9ejRQ06nM9e/qVOnSpKmTp2qhQsXut3noosu0ooVK3TmzBklJibqlltuCfzAAYQM11DKyrCplEIosj7FfuopO+Tx5BPf48elhx6Sli8v/hheeSVKWVlRuuSSrFzTllx7jFxwgZkKctNN5vLXX9u9LIBQlDOUkqTevU3VyMmT0syZ9nF/fYBBpVTJsW2b2T7wgNSvn3TeeVL79lK7du63C4VQKjZWqlvXvuxpKHXxxf4Zj69Y1VKSCXxHj5bi46UTJ6R//av4j+86rc7XlVKuodTKlb55zPR0KSvLvHVnAXmUNGHVUwoAcrLegOzYYV4EREW5vzjzNSuUSk11b5IJFCQjw+55c/PNUs+eZn/58sIDzgsuMD03XBaSLZJDh6QPPjB/9seMyf3N6/oit107U0Xy9tumefOxY9IPPxTv+QF/yiuUcjhMjynJNO63+GuqtxVKUSkV3pxOO5T65z+l2bNNSL9ypbRqldS5s33bUAilJKliRXt/8GDP7vPWW+aDh6VL/TOm4rr8cnvxgEsvNX+PrOrimTNN2FwcrqGUryulXPtVrVrlm9eLrmOkUgolDaEUgLCWs/y8Th0pLs5/z2c1Opd8/8kaSi7XhuaVK5s3w/XqmbDq11/zv99335mm41LR+0+tXy9t3iy9/rp06pRDTZocU8+eeXeL/eQT82n0//2fuRwdLV15pdl3fVMPhJq8QinJfoPu+vPjr0opa/resWPub0oRXg4eNIGHw5H394jrsbx6BQbD6NGml9pHH0ndunl2n6pVpX//20ydC0VxcdLjj7v/HTrnHFPVm5pa/F5NgaqUSk62pwwXhxVKORxO5bGwPBDWCKUAhLVKldwv+3PqnmQ+nbJ6iDCFD56ypu5VqiTFxJj97t3NNr8pfJmZ0vjx9uWivPk5ccJ8qt+ihWnaK0lDh27Jt4/OiBHm02jXBW2vuspsv/mGN9oITU6nXYmYM5Rq1878zt63z55W569KKdef74MHffvYCByrSqpuXeX55t8KperWDZ1pVLfdZv7OWKvWlRS33GL+7vTpYy7nV/1YFNbvDMl/oZRVweaLKXxWKFW6dNF74QGhilAKQFjL2UvBn03OJfNCgL5SKMzBg9K8efby1VYo5branRVK5dfs/NtvTZWTxfUFtCfS06UNG+wX20eOSE2aOHX++Xu9epxu3aRatUxvq3nzvBsDEAgnTtgNkXN+UFGunNS8udlfvdps/VUpFRVFX6mSwAql8vsgwOq/d9ZZgRmPp6JK6Ls61ybukh1KzZxZvNdhgZi+17Wr2a5YUfzHtMbI1D2URCX01xeASOJaeu7vSinJDqWK288AJdOWLWaKQZ8+9ie5VihVrZp9OyuU+vXXvCuQZs82W2vawrFjdshVmM2bzRunnNMy7r03K9cL/MIwhQ+hznpzGReX9xu29u3NdtUq83N0/Li57I+/F1YotWeP7x8bvrV+vVmF1DWckKQlS8w2v1Dq6qtNb8AnnvDr8JCP9u1Nz8NTp9wXMPCWv6bvZWXZC4Ocf77Z+qJSyqq+IpRCSUQoBSDsub7x9nellESlFPK3YYMJm3bvNpdfecVsDx0yW9dKqbPOkhISzAvNZctyP5a1+OwVV5htWpp7n4r8/PWXWXXMGoOlZUvpuuuK1m3V+mT62289GwMQSK79pPKa1mKFUpMmmb6DkvlZdO0R6CvWqpbvvuv7x4ZvnX++NHmyNG6cfWzmTNMAXDLNtfNSubI5vxdc4P8xIjdfTeFzrT72ZaWU64dM1utT30zfM7/cCKVQEhFKAQh7ga6Ust7IjBljQohg2bTJNCllFcDQcfPNUlKS1Lq1mVq6dKl5MZrX9D2HQ7rwQrO/aJH74+zeLW3daqZj9O9vT1/IOYUvPd2snvTRR+by4cNS374mmHL1wgvSmjVFfzHbtatUu7Zp2Dp3btEeA/CX/JqcW6xqhaNHTUVEfLx0553+Gcv48ebndeZM30zZgf+cOGG28+ebrdNp9/G78878QykEnxVKzZpln0dvOJ3+q5Ry/eCmc2fzd3z/ftPXzltOp6mmPnHCHmPp0r4ZJxBKCKUAhL1zzrH369Xz//NZlVK//ur+CWugdepkVkn797+DNwbY9u+3p33MmmVXOL3xRt6hlCS1bWu2Vg8Ti1Ul1bGjaZRq9cnJOc3kq6+k99+XRo40lXsDBkgbN5pqkBEj7Nu1amU3YC6KqCi74TlT+BBqCguluneXPv9cmjbN/HwkJ5tVvfyhWTOpRw+zv3atf54DxedazWL9bpw925yzcuWkCROCMy54pm1b0yvu9Gnp+++9v//Jk2b1W4s/KqWioqQKFezeY0Wplpo/34Tqt9xih1Lx8R7O4wfCCKEUgLBXpox5s/Hcc2aVMX+zQinJ9CgJhhMn7J5WM2YEZwwl3W23Sbff7vnt58wx23POMeGodd9p00zVk+TeU0oyDcSl3J+gLlhgttabWyuUylkp5Xq5b1/p99+lKlVMNZP1SbLkm58L6/FmzGAKH0JLYaGUNd1n+HDzs+BtXzVvWeNginfo2rLF3rf+lk6aZLajR+f/vYTQ4HBIl19u9n/4wfv75/yAxx+VUqVKmXFaH5wWpXLSWp132zb790n58sUfIxBqCKUAlAjDh5vpdIHgGkr99ZfdNDeQrIocSdq+PfDPX9IdPmz6irz5plm1zhOzZpntwIFm262b+TT31Cnpm2/MMaufjcU1lPr1V9MTbcYMu1KqZ0+zzS+Ucv20f8kSE9DOmmUqo6ypgdWrS/Xre/Z/KEiXLmalyxMnWIUPgXf4sOnRllfQY/Vsq1IlsGPKD30HQ9/Gjfb+X39JP/5oAoDYWOnee4M3LnjOqoz3dmVayayQ68qXlVJWKGVNs7P6zBWlUmrNGrN1nb4XH1+88QGhiFAKALzkGkpJ0rp1gR+D9emZZHpLsfy4b7n26bJW0SnM8uVmawVJDoddLZWVZVYGGzzY/T6uodSAAdLOndJll5mgMTraBFtS/qFUzvPep4903nlmv0oVadcuU83ni6XCo6Ls3jw7dhT/8QBvDBsm3XOPqWLJyVrpLmfoGyyEUqHPNZSSzFR4yUyFDpXvIxSsOD9nO3e6X86rUmrhQul///P+sa0Pi3wRSllTgFNSpJQU0+g852tQoCQglAIAL+X8lCrQoVRWVu4eCq6VUyi+zEx7Pz3ds9vv2mX2mza1j19zjekJJUlDh+buKWWFUvv3555O0LGj6UcheR5KnXuu++V69ezn8AVr2kBRGssCxfHjj2Y7bVru66xQqm7dwI2nIIRSoW/zZvfL27ebDxIeeCA444H3ivP3KGcolbNSKivLfMDUr1/ulWwL4zp9T7JX/0xM9K6q6+RJu9/kiRP275Ny5egphZKHUAoAvJRzul6gm9n+97/S6tXmjU/v3ubYn38GdgwlnWsQ5TpFLj979pj7xMaaVeosZctKjz5qeknl9WanRg3zRsg1BLNYFVeS56FU586Fj7U4PHkTcPy49NprdlAAFFdhwbD1pjFUKlwIpUKfNX3Ltb/Y5ZfbTakR+nwRSllVxDkrpVx/dr3tBZVz+l6VKmZqvuRdH9L1683qe1LOUMq78QDhgFAKALyUlOR+OZCVUmlp0kMPmf0HHpC6djX7ViNt+IbrqjyehFLWdLb69XM3Ub7/fvMGqGPH3PeLiTE9n/JiNTmXPA+lOnUqfKzF4cmbgOuvl+66S7rgAoIp+EbOqVY5v++plDKVHUuWOLR/Pw1nPGF9uPTKK2Za6NCh0uTJQR0SvFScnzPrb3bLlmabM5Ry/RuXs6quMDlDKcmewudNKOX6gWdGhnT4sJm+V7asd+MBwgGhFAB4Kef0vbVr7U+z/O2dd8w0gxo1pPvuk5o0MccJpXzLtTLDk5XmEhPNtlEj758rr+l10dEm1LF4EkrVrev/FaMKC6X+9z/p22/N/o4d0jPP+Hc8iAw5e7GsXm3vZ2TYq1dGaih1/LgJpHv0iNGdd/bUtGmOwDxxGEtONtuzz5ZeekmaPl1q3Di4Y4J3fFEpZYVSOafvuT6m6+8bT1gfZFnT9yT7e+uvvzx/HKvJucX6QJRKKZREhFIA4KUXXjDNpKdNM6XfR46YFwtbt3oWYBRVcrL05JNm/4knzAsTq38RoZRvBTKUSkiw963zee657i888wqlnE47lJozx2607k+FvQmwep1Z4diyZf4fE0qenNWJOb+PrO/1nTtN8/2sLBPk5ld1GGiBDqVef90O7tLSYnTDDTG6+27P+uFFKqtSyur5h/Djy1CqoEopb0OpvCqlrGn9VoDuiZytIfbto9E5Si5CKQDwUrNm0q+/SsOH2yHC22+b45df7r/nff55s/R58+bSP/9pjlnPv3u3b5c0jnTehlLWVACrb4Q3XKd/vv++CaBuu839NlbIc/iwfez4cXtlwIsuCswb8sLeBFhfh1GjzHbtWvd+WWfOuK9sCOR0//3mTdeDD9rh1E8/ma01pfXzz00o+9BDdmBVu3buqbPBYv2cBCKUSk01lT6S9MEHGbrqKjPX6NVXpV69vHsTHEkIpcKf9XOWlub5KrmS+ft15IjZb9HCbAuqlNq4Me/V+fJTUCi1d69nj+F05l8pVbYsjc5R8hBKAUAxtGljtlYF0+zZ/nuuL74w2wkTTENtyTTQtlZos6p1UHzeNDrPzLQ/0SxKpdS4cWZ7441S9+5mFb7rrnO/jRV2WSvxSHaVVIUK7i9+/cnTUOqSS6QyZcwL+e3bzbHffjO9MCZM8PswEaaWLJFefNFMyXvuOTMl7Ycf7J+vd94xU2JWrzbNh12nrx44EJwx5yWQlVIrV5qwumZNafhwp665ZpO+/DJDFSpIixZJAwYEbnp5uEhPt0MGQqnw5Vox5M3PmhX2VK5sWiFIuUMna3qnZP7Gv/OO549vvWYoTiiVlGR+rqOi7AUcDhygUgolF6EUABSDFUq58tcbgEOHcj+nw0FfqcKkpUl33inNm+f5fTytlMrIMI29V6wwVRpFWf3ullukhQuld9/N/zbNm5vtrl32J7rWimM1a3r/nEVVUCjldNqhVOPGUuvWZt+a+vDAA+bF/ZNPmpDBm0+eERmef95se/Y001rXrbNXGG3TxvwcWNWo773n/sYxVKbuSYENpaw3uU2b2pVil17q1KJFZn/VKqbx5eT6fWN9qIPwExtr923K629Serr0r3+ZynZXr79utgMH2j1CC6qUkqRJk6STJz0bl/WawbWnlNU7cu9ez14jWkF806a5f7cRSqEkIpQCgGKw3ni7spaa9qWsLFNBI5nlhV1ZVTS7dvn+eUuCuXPNi9Abb/Q8MPQklEpLM1M4P/nErKL32Wd2QOiNuDgz/a6gqUfVqplpfU6nHT5a05batvX+OYuqoFDq6FH7TXj9+va4rFDKmi4jmesuu4wKDrizqj0feMAEUkOG2Nf17Gm2N91kttOmSX/+afZr1ZI++ihgwyxUMEIpqxLDYgXZkn97HYYj63dRfLxddYzwVNDfpHfekR57zPSde+wxU3W5a5f03/+a6++/3w6ltm+Xli6172s93qWXmr/rBw7YYVZh8pq+Z4VSJ0961gPLCqXatrX/jxZCKZREhFIAUAx5VUpZDTR96cQJuxdPzhXWrNJua1l0uLNeAO7e7XkzcE9Cqdtvl7780oRK06dLV15ZvHEWxOGw32Rab8R/+81szzvPf8+bU0FvAKwqqZo1zdS9du3M5TVrzKfQGze63/6HH8zXD7C4BizVq5ufq//8x1Q03H67ua5HDzNNNjnZDhc2bzbBbqhwDaX8HbxaXzPr74AlLs7eJ5RyRz+pkqOgAHjJEnv/X/8yVZevvmoqdnv1ktq3N3+rLD172j9P1t+4ypWlxx83+5Mnu1fZSeY1xbvv2q/PfvzR9MOT3EOpcuXsqjxPpvBZUwzbtMkdStFTCiURoRQAFEOTJrn7+fijYsmqkipdOvfzWW9GPO1VEGlc35B9841n9/Gkp5T1aeu0adLgwUUamlesUGrzZvNG15qSEKxQKuebbSuUatDAbF0rpZYty3sK0ZgxTOODkZ5u94WyqgocDmnkSLOqo/X9HxVlL/QgmWl+Od+0BZv1Rjkjw7sGzEVhfRiRs1LK4bD/VhBKubNCKabuhb+CPijJ62/3G2+Y7f33m23duvb0uDNnTE8718crX14aMcI0RD9yRHr5ZffH+7//k0aPlqZMMZcvucS+znX6nuTdCnyulVI5K6OolEJJRCgFAMUQHS21auV+zB+hlLVSTM4qKangSqmkJOmVV+xQKxK59or4+mvP7lNYpVRKiv3Gpk+foo/NG2edZbYffigNG2Ze2EZHSx07Bub5JfsNQGZm7q+LVSFoTSe1QqmdO03PLEnq1s1M2/v0U6lePfOzcs895v/2z3+aN/GuVq3yT+UhQo+1slRMjJmuWpAbbjDhlGT6l4WasmXtfX9P4ctv+p5kvykmlHJnVbtQKRX+Cgql8vqg7vRpEzD162cux8ebBUSsD6zefts0GHcNpaKjpSeeMJdffNH99ZQ1nX7SpNx/v3J+gOhps/OMDGnDBrOfV6UUoRRKIkIpACimnH2l/PEmOr9+UlLBoVT//uZNvzX1JRK5viHbsMGe/laQwkIp62tdvnzgqjSsqaKbN9tVWp072z0xAsH1xXDONwFWpZQVSlWubIInSZo502w7dzYv/v/xD7up9b//bc7JBx+YXkKW9eulc881oVukLGv/5JPmk3fXKrRVq8zKmyW1/9a4ceb7xJqOWquWHTjlp04d87tNCs1QKjranhaUVyh16pTpdeeLsKigUIpKqbwxfa/kyG/6ntNp/lbm5b773H/HlCtnekd16GB6Pr36qnsoJUlXXWX+Bh8/Lr3wgv2cVsC5dav5ANBVfqGUtUhJfrZsMVVbZcuaqcqEUogEhFIAUEw5+0r5c/qet5VSq1aZ7fff+35M4SLnqjqeVEsVFkpZLyrr1i36uLw1aJD05pvSU09JL71k+lh88UXgnl8yL+StKpD8Qilr+p5k95X6/XeztUIqybzIz9kH6Ntv7f3nnzefGB8+LN12W7GHHvIyM03vkn//2/56SSbAGzZM+uqr4I3NX5Yvl5591vw8WdNf8gpX8jJxomlgPHq0/8ZXHAX1unnqKalvX6l79+JPuyaU8sxvv5mfrxMnCKVKkvwqpQ4dyrtCvFo16dprcx93OKSHHjL7r75q/1xZUzyjoqQJE8z+K69Ix47lfs316KPul3NO32vUyGwLWynZmrrXurV5XtdQKioqK9fjAiUBoRQAFFP//uZTcWu6Un6fzhVHQaGU9WbkxIn8V3WJ5N4Z1hsy64VduIZS0dHSrbeaF8733CPdfHNgn9+S35uAnNP3JPtnwqrycQ2lHA6zmlGVKtKFF5pj1vf53r1mVUPLt9+a6w4fLrlTUV1X7bTe7Jw+bVf2Pf64Ca5KCqfT7usiST/9ZLaehlLt25tGxqHU4NxVQaGUNZ31jz9MNaC1kqa3XH/nW324XBFK2R56yFQi3nCDCRQkQqmSwPp79Oef5oOO+fPN5bxehz39tKnadW1u7mroUDOV/Ngx6X//c398yawG2qiR+Zlevtz+PV2vnvleyvkBWM7wqEWL/Mfmyrq+ZcvcYyhdOlMOR8H3B8IRoRQAFNPZZ5tPXn/4wVzesMG8efalgnpKuU4hy+9T90h+8W29ULzsMhOE/PZb4dUJhTU6t16MBiMUCrb8Qqmc0/cku1LK4hpKSeaT4MOH7SqgY8dM8PLaa+YcXHCBaXDtdJo3Gy1bmsfMq2l6uNu/397fts3eWoHehg3SZ58Ffly+tm2b+V05Y4YdRElm2oyUd7gSjvIKpZYula64Qlq82FyuV8/8LrrwQvfl6D1l/R7LbxoxoZTN+hs6fbr01ltmP5L/LpYU1s/Zq//f3p2HR1XebRy/Jwsh7IQlBAirgKgoohUQBFFURNy1SFXEV22pGy61Vvtat7Yur1JbKy51xVapxQXbYl1YqqCiIBUEBUQWgUBkDYuELOf94+nDOTOZTGaS2ef7ua5c58ySmZOcmZOce37P7/mDmc317LPNZVt56fWLX5gh5LXJzpZuu83/Ou/7yudz2zWsWOF+ONW7t3T99TUfL3CmPtsXsq5Qyh7/Dzmk5jbk51fW/AYgDRBKAUAU5OaaWaDsJ2H2pCMatm51h/ME6yklBR/C5+1BQ6WU+YRz0CCz7h0mFkwyVkoli2Ch1M6d7pCYLl3c6+sKpSxv2Prtt6bZrGRm5xs2zKy/8oqpJvr2WzOjX7qxjb4ltzoqcJjHXXfVbKabai66yEzNfs455nLg7JHhVkolO3uyPHeuGT79xhvS8cebUEQyx+QlS6QTTzTHmBdeiPw57FDx2o5DNpSqbQbRTGJDT8kN8wilUl9gGLtnjzl+2vfT/febZc+eCqvC6Ec/8n9dBD6+N1jyfjg1aZL/BAeS+VvlZWcQLS11q/WCscf9YKFUdnZ1nT8DkIoIpQAgiuwJ9PvvR+8xTz/dPZEJVikluaGUt8m6NzTI5FDKVko1buyeCNuZdmoTbihlf++ZJFgoZV937dr5/2N+yCHuUImcHKmwMPhj5uS4r9EHHzT/sPfuLZ15pvue8u6zaIa+ycIbSq1a5b8cM8YE0l9/nfo/u3eoWkGB6Y3mlS6hlH09//rX5nV87rn+txcWSq1aSRdcYC5v3Rr68YI1urcVFbU1e6dSyrVvn1n+4AfudYRSqS9YheA115iK2zFjpFtvlebNC78SMTfXPygPJ5Tq1Elq08b0fLQTMEg1Z8Zt3tw9voWqlrLv6549zdK7PRUV2eH9IECKIZQCgCiyvXE+/jg6j+c4/idxtYVSAwaYpXc4jPckN5PZE7L8fLf/zJdfhv4eKqVqFyyUCjZ0TzLDIexwh06dzOXa2CpAO7Tm5ptNk9fjjzeXDxxw7ztvXn22PLl5h+/ZSikbSvXv7/bnCjahQaoIrNj59a/N8Gevk0+O3/bE0g03SEOGmOFC9mvECPf2IUPMsm1bswwVSn39tQl8773X//pvvjFLe/IaiFDKZSulnnzSvJ8ktxIFqWvECDMDrW0iLrmtFO65xyyHDDHvn3DZvzlSzVDKVsO//bb02GNm3X44NX68NHOmeb8+/riZSTVQXUP49uxx/3ez7+uePaV335W6dnU0evSa8H8QIIUQSgFAFNmZx7xNixsisCdBbcP3TjnFLN991/1E3RtKBTbgzCT2hKxxY6lDB7NeWhq88sAK1VPKcdzKoEwMpewQvGXL3OvW/Pf/ZO/Me5YNU2obumd5X9sFBdKll5r1YL/jefNC779U5H2/lpSYpr3vvGMu9+rlvnZTOWz2HhenTDEnbd6gsm9f/+GfqWzUKPM6XbDA/Zo92wSO11zjDisKJ5S6/XbTe+1Xv/K/PrCiIpBttEwo5YZSbduaSubZs/2rWpCaBg0yH5B8841bCS2ZCsSjj67fY3pDqcAqcxsqeQX+jerZU5o4UWrUqOZ96wqlbNBcUOD/IeTIkdKqVZW68MKVoTceSFGEUgAQRbU1ga6vwBPQJk2C32/oUHMCsmmTWwXk/V47dCET2UAuP9/9tLS8vGbg5xWqUmrTJtM0Nzs7+D+o6e7EE81yzhzps8/MbFa33mqu835abdk+XnYmodp4Q6kjj3SH/eXl1Rxms3mz+897qqiqMidN11zjXrdunZmevEsX6Xe/87//9OluBVrv3m4o5a2oSjV22zt2NDNJ2kBq8mRTgVBXr7d00KuXmXXSDmUNJ5QKNoOfVHcoRaWUUVHhHtObNjV/p0eMMJWYSH12P/brZ5Y+n3T33fV/PG8z9Fat/G+z71erRQv/IaF1qSuUCuwnBWSKnERvAACkE/upWqjAIxKBoZQ9MQ2Un2+GDr73nqmWOuwwKqUsb6VUkyamAfGePaZaqraeIqFCqSVLzLJPH/ekL5PYUOrzz/17ZgwcKF11Vc37jx9v3hcnnRT6cdu0cdcDhwG2b+82Urfmzav9ZDwZrVrlhi7jx5v36W9/W/O9+fjj5udfvtx8tWtnfrd2aG4qV0qVlppl+/b+1994o/nKRN5QynGCN2MO1tzecdxglp5SoXk/lKntgx2kvtGjzZDgq682/wPVV8uWZnheebk7YYHl80lTp5rJZx580FyO5P+AukKpzz7zvx+QKQilACCKbCi1d6+pjAjVQycc9gS0cWPp0UfdqpNgTjnFDaUmTaJSyvJWSkmmQsGGUr16Bf+ecEIpOywt07Rvb4ISOxRr3DjzegucRc1q1Ej64Q/rflxvpVRgxVW7dm5/JWv+fOmyy8Lf7kTzVrsMHeoGDcOGmYopOyS0Vy/TV2nUKP/vT4fhezaUqq3hfSayYWxVlQleAyszJP9Qyv5d2brVVOT6fMErFCVCKcsO3cvKcoc0Iv0MGiTt2BGdiV1OPbX22y691B1eHikbNq1a5f8/4rJl5sMKG0qlS289IFwUrgJAFHmbYkZjCJ89AT3rLOnKK0NPaWz/iZo71zSF/uQT9zYqpdwTNFulYU+QgwnVU+rzz83yqKOis32p6JZbzCxFjz8uvfRS7YFUJLyhVLBKKcsOrUi1ZufeUKqy0gxhe+kl83794x/d2wKriKx0GL5XW6VUJmvc2K3GqG0In/d4ZCsGFy82y06daq/UIJQy7IcyTZuG/huK1NeyZXLv465dTTBaXu4/W/KDD7qBlBQ6FAPSEaEUAERRXp77SWw0hvDZUKq2YXteRx5pKkr27pX+/Gdp1iz3Niql6h9KBZ7Q/ec/ZpmplVKSCaV27zbNXKMl3FBqzBiz/PLL0H14ko03pL7nHumrr0yVmc9nmthK5tgR+LNbtrooVSqlxo0zwzttiCu5gRqhlL+6+krt2OGub99ulo88Ypb2/RAMoZRhK6UYuodEy852+0V5h/DZ97VVVBS/bQKSAaEUAERZNPtKRRJKZWW5J7dXXGGWNjihUsodvhdOKOUdLuM9ofvkExOG5ORIxx4b3e1MNdEeBuPt7xU4HMkbYvTu7TZN//DD6G5DLNlKqZNOku64w7+qsnFjaf1600MqcApyyx4DvvvODPtIZnv3StOmmU/+Bw2Snn/e9Ix6+GFzO8P3/NUVSnmr47ZvN0OI33rLHPN/9rPaH5dQyrChVNOmid0OQDKTOkj+oZR34o7HH4/v9gDJgFAKAKIsUaGUZPpKedmZvior/at/MkF1tfTMM26JfDQqpe67zywvvphqj2jz/p47dvS/zfu7LigwPZmk1BrCZyulAhvnWsXFtTeslkwVZFaWeV1v2WIC0tmzo7+d0eA9wdq/X7r8creyR+K9E8j2lQoWSlVWStu2uZe3b5ceeMCsX3hh6Gb/9pgXOAQ50xBKIZnY96ydXbWqyp1175tvoluBDKQKQikAiLJIQ6nqamn4cNOXJzA4amgodf757nqmVUv95jemD5cVSaVUsJ5Sy5ZJb7xhhlvdemtUNxVyPz2Wak4Q0K6du15QIA0ZYtZTMZSqrRKqLtnZ7u+hVy9zvDj5ZHdWvmRiQ6kBA8xQxcAeL96ZFhG6UsrOymd99pn017+a9bqOQ7aaMdMrpezwdYbvIRnYD11KSsxy3TrTBzQvT+rSJXHbBSQSoRQARJk96Qw3lFq7Vnr/fVP5YPsVWZs2mWW4/QU6d3bX27Y1J/D2hDDTQilv82jJrRqwQ4dCNYwOrJRyHOnee83lc891h48hek46SXruOWnRopq31VYptXBh6ryu7fC92iqlwmE/Yff2iFu2rP6PFyurV5vlIYeYoYoffyy9+qppji9Jhx+euG1LRjaUChaUBx6nfvlLU1lxyinS0UeHflyG7xlUSiGZ2FDK/n9nh/EdckjDZ2wGUhWhFABEma2UCnf2vaVL3fVPP3XX9+1zT1K6dg3/+R96yAzzefllE0jZCqFManZeXV3zBK++lVLffy/98IdudcJtt0VvO+Hy+aQJE0x1TSBvdVFBgRnm1qGD2U8LF8ZtExukoZVSkvTUU9Lvf29CnquuMtcFa3z+l7/4dOutJ+iLL9zr4hlM2EopG6Idd5x03nnSt9+a4D2wZ1im69XLLJ95xvQW86otPP/FL+p+XEIpg1AKycR+yGhDKXuc7tMnMdsDJANCKQCIskiH73lDqWuuMScoO3ZIa9aY61q1klq3Dv/5b7rJnITYpuc2jEmVipJo8J6MW/YEzYYC9kQlGG8o5TjS9OmmyuOxx2hwngjeULZ5cxNgpVpfKVsp1ZBQ6vDDpeuvN0P3OnUy1wWGFk88IV1+eY5WrCjQ3/5m/s2bPt087+9/X//njoStlArskVVYKB11VHy2IZVccYWZqXD7djM1vJf374M1YIA0YkTdj0soZdgPZAilkAy8w/cqK80xWzJtHIBMRSgFAFHWkFBKMg0vf/1rt9og0qoCn88dJiNlZqVUsOoZe4JWV5+VffvcAMEqLpY++EC6+urobSPC17696Z306aemClBKvVCqrkbnkbJ95ryVUo8+Kv30p+7lzZvN2N1588zJzy23BA85os0eu0I1boercWPpuuvM+ldfuddXV0tPPmnW7TTyknTJJTX7dNX2uFJkodRzz5kG6jt3hv89yeqPfzQn+vZ3SE8pJANbKfX996b69ZtvTJ89O2sykIlyEr0BAJBuGhpKSebk8sABs97QEzv7j3gmVUoFG9KU89+/eKFmpNq/3zSTtgFemzbSmWeaIZE0Z06sYcP8L9tm5/Pnm5P3rCT/mC0alVJegaHUCy+YKipJOuIIR1984TvYSNe+nisqzBDJjz/2D66jyXHcWaUIpcJnP3ywFbKS9Oc/S6tWmdfMBRdI999vrr/ggvAeM9JQynGk//kfs96qlfSnP4X3fcnqkUfcqj2JSikkh/x88/7audP03JOkG27g9YnMluT/wgFA6okklFq/Xlq50qzffLP0v/8rnX66OXm0jbob2n8lGpVSlZVmWODf/tawbYmXYKGUFepEbfVq/9/TI4+YygECqeTTv7+pOtq1S1q8ONFbU7doV0oFNuz/v/8zy5/9TPrNb6okSSUlppzGO1T1s89MuPHxxybsePzx4I/vOGa2yXvuMZMwhKuszA3U7TaibvY4v369aWT+2mtuQHTddebvgmR6qhUXh/eYkYZS9m+RZAKxXbvC+76GcBxpzhxpw4boP6434JM46UfysNVS27eb/xmvvTax2wMkGqEUAERZuKHU2rXSxRebE5ChQ81J5b33SpMn+8/AkgyVUm+9Jf3udyY0SwWhZtbzVkp5p1oPJlbVJGi4nBzp5JPN+ltvJXZbwhHLSqlVq8wsfDk50u23S0VF5oVtK6VsKHXiiWZ5zz3S4MFmm2obkvrOO2amyTvvlMaMCd2DzWv7drPMz3cDcdStY0dzvLE9ZsaONX8bxo83fxeGDZNmzfIf3leXSEOp99931/fvl/7xj/Cfq74eeMDMvHn22dF93K1bTQWlF8P3kCxsXynJ9BJt1SphmwIkBUIpAIiyukKpTZvMPyG9e5teL/n5ZtYl2yPk0EPN7VYyVEq9955ZhjujYKKFUykl1RzCF/g7IpRKbrZ6ZMaM8L9n2zZzsl1XIBltsaqUKi83Q/ck0/y6dWv3hKe01KeKCjdQ+p//MUFTZaX/YwULrJ991l3/7ju3GW9dtm0zy4KC8O4PIztb6tLFrF97rdlH48aZ/WCHpp50khleHC7bPy/YUOVgPvgg9OVoeP11U+X4xz9KL73kzmb62WcmXI2WYJVXVEohWdhjdH6+GboHZDpCKQCIMlsJESyU2rNH6tdPmjLFDNE7+WTzj3/v3v73u/NOM2QsJ0c64oiGbU80KqVsKJUqsziFUykl1fx5AhucE0olNxtKLVxoAhk7bCyUc881fcLeeSe22xbIhlLRqpTKz3cD8OnTzXL0aLNs21bKzjZlIlu2uKFU06ZmEoVAn33mf3nHDjfosw24H3wwvGopWynFkNfIeT+AOPNMaepU/6rZSNW3Usp+KOKtnIqGBQuk886TPv/c9D+bMMFcbz84eeON6D2XDaUaNXKvo1IKyeLII83y6qvNRB5ApiOUAoAoa9nSLIPNXvTNN+akrVkz00fjvffMVOCBCgpMH5d586TOnRu2PQ2tlNq0SVq+3KynSihlK6WC/bOXk+NWHhBKpbYuXaTLLjPrc+ear1AWLHCrP6JZlRGOaA/fk9whfCtWmGWnTmaZlSW1amXKYzZtct/7TZtKhx1W83E+/tgsV66U/vAHU7lZXi716SM9/LAZQlxaGl61lA2lqJSKXI5n+qEHHvC/XB+RhFLr10vr1pkQ7JZbzHVffmmq5KLFG3I5jvlg5oILTOApRTeU+vZbs7RDfKXwJx8BYu2666TZs837HAChFABEnR1WE2wImf0Hv0sXt79LbXr0kAYObPj2NLRSatYsd/377+M/7ClS+/e7DXoDK9AkM0zSDmshlEp9zz9verNJprfUzp0mWJk8ueZr9fe/d9ftMLN4cJzoD9+TajYSt4G4JBUUmBd3SYl/pZQkTZvmf/mxx6Thw00INWmSG0ocfrh5D9hecuFUSzF8r/7sBxSNGkl9+zb88SIJpWxYO2CA1LWr+/yfftrw7bBs4/GhQ034NWyY9OKLboXfwoXhDzWsi62U6tnTva6iIjqPDTRUXp6p7m1IJSSQTgilACDKvLOqBP6DbUOpSPqCNJStlAoMXMJlh+5Z4QyRSiQ7dK9RIzMMUjK9WLxqO1kjlEpN555rls89ZyoLJ00ys1l++KF7nw0b/GePtBU98bB/v9t0OZqVUoFD5LyhVOvW5sW9aVPNUGrsWFNJ8vXXZsjYmjXBh2rZKs1LLgm/Worhe/X3859Lv/qV/yx4DWGPc5WVNfuIBbKh1AknmKWd4S+a4a0NpS67zLz+Zs0y29i9uxlyeuCA9J//ROe5bCjVubN5zZ5wgjRxYnQeGwAQXYRSABBlBQVuH4vA3kaJCKUOOcQsp083szlFwnH8K6Wk5B/CZyvUCgulkSPNCd7Mmf738c7A50UolZpGjjRDnXbtMgGMHZ65dKl7n8ce8z8xj2ellHeCgGg2W27d2v+y7TElha6UkszJeocO5v190UVmhreFC/0fzwYT3mqpcEMpKqUi16KFdPfdplIpWo9nKzFKS4Pf529/k+64wx36OmyYWdrZwIINQ68vG0r16GE+vLHDE30+typ4wYLoPJcNpYqLpZ/8xISuBKUAkJwIpQAgynw+t9eLnZLdSkQodeWV5uT1yy+lv/41su9dsULauNGUmtvZARvSMD0ebBBohzb16uUO17OolEovLVtKjz4qjR9vQhY7m9GXX5rlvn3Sk0+a9XPOMct4hlL2xL5pUzcwi4bAUCpYpdTGjcFDKat7d+nll03oNGCA/0QA3n52ttpw/frQQ3jt75UAIPFyc92A6+uvg9/nhz80ze9tX7KhQ80y2qFUdbUbSgWbUfa448wyGqFUdbXbBzFaAR8AIHYIpQAgBpIplGrZ0gxlksyn8HUN4/CyQ/eGDo18JqdEsTOJhWoQTyiVfiZOlF54wYQnth+ODaVefNHMKNejh9sYPZ6h1L//bZbBmow3RKhQylZKrVvnVkjWNfuYzyd16+ZetpVSkhvyHjjg9mwLhkqp5GJ7KnlDqZkzzXsi8AOGww93w8Roh1IlJea1k53t/7qyBg0yS++Q2/r67DPz4USzZtKxxzb88QAAsUUoBQAxYPtKJUMoJZnptwsKzFC2l18O//tsKDVyZGqEUhUV0p/+ZNYvvLD2+xFKpbdgoZRkZjyy77149pR6802zPPvs6D6uN5TKzvYPnWwo5Q0jwhk66K0s8Qa7jRu7wwMDhyV7EUolFzt8e/Vqs5w+XRozxlQVfvSR/31tPykp+qGUrZLq0iX4rIKDB5vr1641s9Q2xD/+YZannVazShYAkHwIpQAgBpItlGre3J1RK9xqqcpKac4csz5ypNswPZmH782YYRo7t28vnX9+7fcjlEpvNpTasMH0c1q71lweMsStBIlXpdTevW64G8tQqkULd4ituc2tlJLMCb/tdReKN7jq2NH/NlstFSqUYvhecrGh1NdfS/Pmmab1dvilPb5bRx/trkczlHIcM0umZKoVg2ne3ARTkvTuuw17vr//3SzHjGnY4wAA4oNQCgBioK5Qqn37+G6PJF17rZnhaPVq6aWX6r7/Z59JZWXm5OToo1OjUmrKFLO86qrQn5Db2wil0lNBgfseW77cbX5fVOSGJTt3RjaUtb7eece8znr0MMOjoskbSnmH7klupZQVboN1bxVL4Ou/rlDKcdwqFyqlkoMdvjdzpglFvZM7zJ/vrvfr519dGs1Q6p//lJ55xoSmtt9bMCNHmmVDQqmNG83fLp9POv30+j8OACB+CKUAIAaSrVJKMv01rrrKrNseN6HY6pJ+/czQoGQPpZYvN5/8Z2VJP/5x6PtSKZX+bLXUBx+Ynko+nwlVvEHOjh2x344ZM8zyrLP8K5miIVQo1aLFAeXkuB3Jww2lbMPpYEKFUp98IvXv7wZ9hFLJwVZK7dljhlYOGmSqpSQ3lLrsMmnJEv/XUzRDKdu8/LLLQlcvjRjhf//6sDOtHnec+3oFACQ3QikAiIFgoVRVlTu0JRGhlOT2i9m6te772vvYbU324Xu2Suqss0zfklDCDaWC9T5BarCh1KxZZtm+vQkZc3LcACfWQ/gqK93+NtEeuieFDqWystwJF6TwQ6nrrjMz8QVrOG2rz7yh1P790q23mqFXS5aY4O2cc9xjIBKrRw83YDr8cNPfzL43Dhwwy2CTQkQzlFq1yn3+UOxw0YaExfb9duaZ9X8MAEB88e82AMRAsFBq2za3l0ei+q3YgMlWbIViQ6m2bc2ytiBn/35p4EDTE+T996M75X24du+Wpk4169dcU/f97c/iHcoiUSmVTgJDKW9I0qaNmUEu1s3OP/rIvO8LCswMltHmDaWaNat5e1GRow0bTHlWXTPvWY0aSffeG/y2wEqpBQukCROkr74yly+5RJo8OXGhO2rKzzfH5e++k4YPN1Wv3mb2UuxDKdts31Zt1cY+5969ZtKKSI+/33/vDv2jnxQApA5CKQCIAXsCXFpqKqSys90gqKAgcRU4NmCKpFIqMJQKrJR6/31TISGZk/AhQxq+nZF6/XUTTPXuLZ10Ut33Z/he+jvsMLOsqDBLb9PuNm1M76NYV0rZoXtnnBGb97w9ia9NfSqlQrGhVGmp6Tc3apQJLYqKpCeeMFWKSD79+vlfjjSUcpz6Dz11HLdSqlev0Pf1Vvvt2uX+7QnXnDnm71PnztKRR0b2vQCAxGH4HgDEQPv25p/4qio33LHNlr0nivHWkEopO3wvMMjxNqV95ZWGbV99bdhglkOGhFepxfC99GcrpSxvKGVf0/Y9GQuO44ZSsRi6J/nPpldVVfP2Tp0i7ykVirdS6ptvTGDRurW0bBmBVCoJDKWKi2vex4ZS1dXucbGy0sxuGomtW02A6fO5Tddrk5Pjvk537YrseSR36N6YMdHv3wYAiB1CKQCIgZwcNwCyQ/iSKZTaudOtIKlNuMP33nnHXZ8+3R2iGE/79plluCfedYVSTZuaIYn2fkg9HTuaIaWWd/ieDayWLYvd83/5pRm21KiRdOqpsXseq7q65nX9+8cmlFq92kwsIJmqFO8wQiQ/b0B7xBE1K6kkc+yzoefOnWbCgP79pU6dIpsdz1ZJde4c3vG0IcMG337bLBm6BwCphVAKAGIksK9UMoRSrVu7nyDXNXQpnOF7JSXu0D3JfIpen0+4G8puU7h9c/LyzNIbSlVVueHW11+bRs982p66fD7p+OPdy94TcXsS7n3tRputkjr5ZP9wLFaChVKDBrmhlLeqqr769TPHg+++ky6+2FzHDGepJztbuvFGM9vd7NnBq0t9PjcgOu88adgwN8T94ovwn8v2k6pr6J5V31CqvFxas8as/+AHkX0vACCxCKUAIEaSMZTKznabrNc1hM/eHmr43nvvmeUxx7gn3uEMDYw2GyaFG0oFq5SyjyGZ3iaJaNiO6HrwQXfdG57YfjNLlsSusi/WQ/cCBQulDj3UXbfhQEM0b+5fGSm5M/IhtUyebAKpUE3p7TFw4UKztO+hSD54sJVSdTU5t2xfqUg/3FizxryXmzen0T4ApBr+5QaAGAkMpeyMVYkMpST3H/ZQzc4dp/ZKqY0b3Vnr7Anqqae6j1taGt3tDYcNlGxwVpdgoZT9ebOyGLaXLo48Unr6aen8801Tbuuww8x+3rYtNn2lNm82M9NJsZ+a/sc/Nsu77qp5mzdYXbcuOs/Xv7//+4NKqfRVWemuf/ihdNllZr2sLPzHCLfJuVXfSikbuvbsSYUrAKQaQikAiJHaKqUSfRJnQ6ZQFU379rmBTWCl1BNPmOntq6v9QylbMZGqlVK2smXgQE5q0skVV5heZ97AsnFjM1OjFJshfJ9/bpaHHeY/bDAWnnjCBKrDhgW//U9/Mq/nRx+NzvP5fFKXLu7lRB/PEDt33ml6Ti1aJA0eLLVoYa6PJJSK1/C91avNsq5m6gCA5EMoBQAxkozD96S6K6XKy6Xx4816o0ZSs2Zm3VsdsXChOfEuLTUNlI8/PjkqpSINpWzFlyS99JJZ2l45SG82lLJ9aKLJzgbZrVv0HzuQz+cOyQ3myitNiDBuXPSe0/tzMXwvfV17rbR0qTRggLkcaSjlOPEbvmdDqXCfBwCQPAilACBGbChlw6hkCaXqqpT6+9+l114z6wcOuFVDgUPaXn3VLEeMMOFVIiulIm10HlgptWqV9OmnpufWhRdGf/uQfGwPtL17o//YNpTq3Dn6j10fNliOlq5d3XUqpTJHpKHU1q3mvj5f+BVM0Ri+BwBILYRSABAjNnwqKZEqKtzKpESHUraiqbbwqLbrA/s1TZ1qlna6+1SslLKhlK2SOuUUKj8yRdOmZhkYSu3ebQJXb+N7a/ly6aij3EC2NskWSkUboVRmijSUslVSnTuH36evocP3qJQCgNRDKAUAMeIdvldaaoYyeGe/SxR7Emkbrwfavdtdf+ghdz3wpOLbb83ShlKp1FMqL88s9+83+4Whe5mntlBq4kTpggukG26o+T0XXmh6UF1wQejHTvdQyttTihA3c9ihdeGGUpH2k/I+R6TD9zZuNMvi4si+DwCQeIRSABAjNpTav980ipVM0+Ps7MRtk1Sz11WgHTvMctIk6eab3euDfdLdoYPbm8dWSr38smm+HE8NmX1v0SJp5UrzvWefHZvtQ/KpLZSyAeWf/lTze5YvD++x0z2UshUzEqFUJqlvpVQkoVR9KqXKy933sR2eDgBIHYRSABAj+fnup75vvGGWxx2XsM05yDusMBh7MtC6tf/1wQKfvn3dnlPek9Of/jTyT7oboiHD92wIcdZZbp8hpD8bSgUbpmddfbVb7RGJdA+l7HEsK8utOkT6q28oFcmQuvqEUtu3m2VWln9gCgBIDTmJ3gAASGdFRSacef11c3ngwMRuj+RfKeU4NW+3JwP25MAKVinVp4+7biulrF273FAu1urb6HzvXmnaNLPO0L3MUlullNfjj5tZJufP93+v5IT472n7dvc9lK6hVFGRtGIFAUCm8YZSjuN+IFGbhgzf++orM0x2wADzfjvuOOnEE4N/z7ZtZllQYIIpAEBqIZQCgBgqKjL/XNuT1GQKpb7/3r9/lGWH7wWGUo0a1bzvoYe664HDePbsqfcmRizSSilb9bVunVk2bSqddlr0twvJq7ZQKi/PDAeyPv3ULDdtcq+rbYjQ2rVS9+5mPTc3vSvv7LBdZA4bSjmOed+EmtXRcepXKXXooabv4rZtZkIBO6lAixbmb1Ow0MmGUonu1wgAqB9CKQCIIRsASaaX1DHHJG5brCZNzD/4ZWXBh/DVNnwv2JANb6VUYaHUo4f0zTfmcrDAKxYqK6UDB8x6uKFU4P3atQseuiF92deAN5RyHKm62v9+dor5FSvc6+ysjda2bdJll0lVVe51RxwRvW0FkkF+vvk7VlVl/h6ECqW2bjX38fnc91A4WrWS1qwxYfCiRdJHH5lK47IyU30b+HdJIpQCgFRHKAUAMeQNpY46yq3OSLQOHcw/+Zs31xx/UdvwvWAnA95QKifHzEzWt6+ZmS9eoZQduieFH0oF7odwvw/pI1ilVFmZVFHhfz9bFfXVV+51u3f7D196+mnpn//0/77nnovu9gKJ5vO5FUtlZWbijtrYKqni4uBDv0Np3lw66STzJZnn3L3bBF2hQqmCgsieBwCQHBh5DQAx5A2lRoxI3HYEstt1yik5mj/f/8yitlDqlFOku+6SbrzRvc47NbxkTvQ7dTLr8Rq+5w2lwj35CQyhkiUsRPwEC6W++67m/WzD/g8/dK+rqvJ/3dmecdZvfmNCaCDdhNvs3PaTimToXm1sMLx1a/DbbaNzKqUAIDVRKQUAMWRnupOSM5SSpP/7vx/oN78x5SGO4/aUCvxE2ueT7rzTnJCXlpqT7uzsmo9t++jEq1LK9pPKz6+78a4VGEIRSmWecEOpHTvM++Lf//a/fvduE25u3CgtWOB/WyTDlYBUEm4oZfv12R5rDdG2rRnSV1soxfA9AEhtVEoBQAx5K3JOOCFx2xHIfrJs2aEW+/e7/ZkCK6Ws7Gzpz3+Wbrkl+O22z0i8KqUibXIumSbU3kCN4XuZx4ZS9vUjuaFUjx7SpElmfedOc0K8YYN53dhGyzZ0nTGj5mMTSiFdhRtKlZaaZWFhw5+zrkopQikASG2EUgAQQyNHSocdJl15ZXJNn37eef6Xn3kmS47jDt3LygrdxDaURFVKRRIs+Xz+1VFUSmWeUJVShx4q3XGHWd+zR3rvPbP+gx+41Y/2pDxw6J5EKIX0FW4oZd9LgbOy1ke4oRQ9pQAgNTF8DwBiqHlzadmyRG9FTZdfbobnlZZW6brrsjV5cra2bZOuvdbc3qpV+EPhAqVCpZS9vz2xIpTKPPb1sm+fmXEvK8s9kW7XTmrZ0r2vrYY68UR3ivrdu83QvrlzzeVBg6SPPzbrwZoxA+nAvi8Cq20D2UqpeIZSVEoBQGqiUgoAMlCjRtIPfyj9+MfVuuSS5crKcvTCC9Lo0eb2hpxUx7tSyjacjjSU8gZRDN/LPN79//33pm/U4sXmcrt2ZjZJG7DOmmWWw4e7lSK7d0v/+IdUWSkdfrh0003mevv6B9KRnXFv48bQ9yOUAgCEi1AKADKYzyddcMEq/etfVSosdCtFausnFY5IQ6mvvpKeecaEApHYs0eaOtU9OapPpZRFpVTm8e7/sjLpqqukV14xl+2kBDacLS83IdXxx7uv77Iyd+jeuedKF1wgTZvmBltAOiouNstvvw19v3iGUsy+BwCpjeF7AACdeKKjxYulcePMLGPdutX/sSIdvjdggKlUqaqSfvzj8J/nxhulp592L+fnh/+9Ej2lMl1WlnnNfP+9dPrp0uefm+ueeMKtGGzVyj35PvZY89q2oVRpqfSvf5n1884zAe/YsXH/MYC4CieUqqpyA6RohlLBZsesrnafy94PAJBaqJQCAEiSiopMQ+cZM6Q//rH+jxNppZQdfvfXv0b2PM8843+5IZVSDN/LTDaM/PxzKS9Pmj7dVExZ3mGsw4ebpR2+99pr5rXbtavUv39cNhdIuHBCqW3b3MrXaFQvhaqU2r7dhGCSGXYLAEg9hFIAgINycqSzznJnGKuP+jY6X7Mmsvs3bux/uSE9paiUykze/f7442YYnpd3GOuJJ5qlDV0/+MAsx4yp/6QAQKqxodTGjdK6dcHvY4futWlj/qY0VKhQyj5X69amVyIAIPUQSgEAoqq+jc4bGkrZMCxc9JSC9yR22LCat9tKqexsacgQs24rpayTT47NtgHJqLBQys016926mTBXMgHV3Lmm/1o0+0lJbii1Y4dUUeF/25Yt7nYBAFIToRQAIKpsOBROKBXY3DyS6qrAUKpHj/C/V2L2PfgPQerevebttlLqmGPcsNU7u15WlltBBWSCrCz/YXJXX23eO926mQkCHnss+qFUmzYmGJZq9pWK9nMBAOKPUAoAEFX2pD2cgMn2k7K++CL857Gf1luHHBL+90pUSkHav99dzwryH1HfvmZ55pnudd4hfQMG+PedAjLBpk3+l9euddeXLHGDo2gFRdnZ7mOVlLjXT58u/frXZp1KKQBIXcy+BwCIqkiG7wXeZ9UqadCg8J4n8Ht79Qrv+yx6SsGqbebGq64yr8fDDnOvO+ccaeZMadcu6fbb47J5QFIZPdq8B4YONe+Hfv3Msfvaa01o9NVX5n5du0bvOYuKzGNv3mwul5WZ2WIrK81lKqUAIHURSgEAosoO39u710zXHawCxQoMljZsCO85qqqknTv9r2tIpRTD9zLTRRdJ06ZJ998f/PasLOmoo/yv69hR+sc/Yr9tQLJ64gkz++RPfuIOo7ZDsTdvdhuSDxwYvee0k2/YUGrePDeQkqiUAoBURigFAIgqb8+dvXv9Lweqbyi1c2fNflSRNjqnUgrPPGOqOwYPTvSWAKmjuFiaNMn/OhsarVvnDt2ORShlh+/Nnet/O5VSAJC66CkFAIiq/Hy3786XX4a+b2Ao5W08Hcr27RFvVg2EUmjSxMyqF6qaD0DdbGi0a5epZO3YUercOXqPX1RklrZSKjCUolIKAFIX/4YBAKLK53NnJHvvvdD3rW+lVGAo1a9feN/n5Z29j+F7AFB/bdv6h7uDBpm/BdHiHb63a5e0aJH/7VRKAUDqIpQCAETdyJFmOWtW6PvZUKqgwCxDhVLemfq2bTPLbt1MP6CZMyPfRu8JE5VSAFB/3hnypOgO3ZP8Q6l580y/Qm8j9Xbtovt8AID4IZQCAETdySeb5fz5/mFSIBtK2dnNvvtO2r+/5v3++EdTzfT3v5vLtlLqkEOkW29t+DCR2mZfAwCExw6xk8KfRTXSxy4pcYfunXKK9Mor0uTJkc++CgBIHoRSAICo69PH9BQpLzfBVG1sKNW1qxsMbdpU837XXWeW48aZpQ2lbIVVfXgbpUdzmAkAZCJbzZSdLR1zTGwee/Nmac4cs37iidKFF0o33hjd5wIAxBehFAAg6nw+t1oq1BA+G0o1b+5WO4XT7NwO32tIKEUfKQCIHhsc9esX/SHRHTuasGvfPreflO1dCABIbYRSAICYCKevlDeU6tTJrG/cWPdjr11rlvZ76uOcc8w2/upX9X8MAIDRrZtZDh0a/cfOz5f693cv9+rVsOM/ACB5JDyUmjJlirp3767GjRvrmGOO0QcffBDy/o899pj69u2r/Px89enTR1OnTo3TlgIAImErpRYtknbsMMPlKiv97+MNpWyjWlsFFcqqVWbZu3f9t69RI+ndd6W7767/YwAAjGuukR56SPrf/43N459wgrtOlRQApI+EhlJ//etfdcMNN+iXv/ylFi9erBNOOEGnn3661q9fH/T+jz/+uG677TbdddddWrZsme6++25dc801+rvtfAsASBqdOpneUtXVpjHthRea3lE2iJL8Q6m2bc361q11P7YNpWhuCwDJoU0b6eabpcLC2Dy+N5QaMSI2zwEAiL+EhlKTJ0/WFVdcoSuvvFJ9+/bVI488ouLiYj3++ONB7//iiy/qJz/5icaOHasePXrooosu0hVXXKEHHnggzlsOAAiHdwjfq6+aJuZvv+3eHqxSKlQo5fOZqit7H0IpAMgMQ4dKWVnm78Dw4YneGgBAtCQslDpw4IAWLVqkU0891e/6U089VR9++GHQ7ykvL1fjxo39rsvPz9cnn3yiioqKmG0rAKB+7BC+GTPc67wNxsvKzNJbKfXdd6Ef01ZJFRVJzZpFZzsBAMmtfXvp5Zell14yjc8BAOkhJ1FPvHXrVlVVVakwoMa3sLBQmzdvDvo9p512mp5++mmdc845GjBggBYtWqRnn31WFRUV2rp1q4qKimp8T3l5ucrLyw9eLvvvGVBFRQVBVpjs74nfV3pjP2emWO/3IUOkrKwcbdjgO3hdVVWlKiocSdKuXTmSfMrPr1SrVpKUo+++q1ZFRVXAI+X+d+noyy+rJOWoV69g90MovM8zA/s5M2XCfj/3XLNM4x8xbJmwv+Fif2eedNjn4W57wkIpy+fz+V12HKfGddYdd9yhzZs3a9CgQXIcR4WFhZowYYIefPBBZWdnB/2e++67T3cH6WL7zjvvqAnzgUfk3XffTfQmIA7Yz5kplvu9XbuR2rLFnR98/vzPVF1dIkn69ttTJeVr5cp52rOnkaTjtWbNbs2cOffg/aurJelsSSbQeuut1ZIOVV7ees2c+XnMtjud8T7PDOznzMR+zyzs78zC/s48qbzP9+3bF9b9EhZKtW3bVtnZ2TWqokpLS2tUT1n5+fl69tln9eSTT2rLli0qKirSU089pebNm6utHfcR4LbbbtNNN9108HJZWZmKi4t16qmnqkWLFtH7gdJYRUWF3n33XZ1yyinKzc2t+xuQktjPmSke+71372xt2eJePvTQARo92lF1tVRWZv4MnXfeEH33nXTXXdKBAy00evTog/ffu9f93pycHElmyr0RI4o1ejRzgkeC93lmYD9nJvZ7ZmF/Zxb2d+ZJh31uR6nVJWGhVKNGjXTMMcfo3Xff1bm2FlcmCTz77LNDfm9ubq46d+4sSZo2bZrGjBmjrKzg7bHy8vKUl5cX9DFSdecmCr+zzMB+zkyx3O9du0offOBePnAgR7m5pll5ZaW5rlOnXOX89y/S1q0+5eTkasYMafJkM6OTVVXl0+rVppq2b99s5eYGr5JFaLzPMwP7OTOx3zML+zuzsL8zTyrv83C3O6HD92666SZdeumlOvbYYzV48GA99dRTWr9+vSZOnCjJVDlt3LhRU6dOlSStXLlSn3zyiQYOHKgdO3Zo8uTJ+uKLL/TCCy8k8scAAITQpYv/ZVv5ZAtl27SRGjVyw6eKCunTT6WLL5YCq36//15audKsM/MeAAAAkNoSGkqNHTtW27Zt0z333KOSkhIdccQRmjlzprp27SpJKikp0fr16w/ev6qqSg8//LBWrFih3NxcjRgxQh9++KG6deuWoJ8AAFCXwFDKBk12SJ8dsd2kifnat086//yagZQkOY6Zsc/nk3r2jN02AwAAAIi9hDc6v/rqq3X11VcHve3555/3u9y3b18tXrw4DlsFAIiW2kIpWynVoYN7W9u20vr10oYNUrt20iWXSL/7XfDHbNw4NtsLAAAAID6CN2ICACBKIgml2rVz16dOlY4+Ovhj9u4dve0DAAAAkBiEUgCAmCou9r9c2/A9SerRwyxvuUUaNco/sPKinxQAAACQ+hI+fA8AkN5atPC/HNjo3Bs8PfKINHasdM45NW/zIpQCAAAAUh+VUgCAmJs1Szr2WLMeavhex46myXl2ds3bvBi+BwAAAKQ+QikAQMyddJJ03XVmPdTwvUBt2gS/nkopAAAAIPURSgEA4qJJE7MMVSkVKCvIX6mcHKlbt6huGgAAAIAEIJQCAMSFN5SqrJS++85cDhVKBdO9u5SbG91tAwAAABB/hFIAgLiwodTevdLWrZLjmEqotm0jexyG7gEAAADpgVAKABAX3kopO3SvXTu3qXltzjzT/zKhFAAAAJAechK9AQCAzBAslApn6N60adLChdKBA9Ltt0vjx8duGwEAAADED6EUACAumjY1y337wpt5z2rSRBo2zKyPHBmbbQMAAAAQfwzfAwDEhbdSqqTErEfa5BwAAABA+iCUAgDEhQ2lJGntWrMklAIAAAAyF6EUACAu8vPd9W++Mctwhu8BAAAASE+EUgCAuMjJkRo1Mus2lKJSCgAAAMhchFIAgLixQ/gIpQAAAAAQSgEA4sbOwOc4ZsnwPQAAACBzEUoBAOImMISiUgoAAADIXIRSAIC4KSpy13NzpdatE7ctAAAAABKLUAoAEDcdO7rrhYVSFn+FAAAAgIzF6QAAIG4CQykAAAAAmYtQCgAQN95Qin5SAAAAQGYjlAIAxA2hFAAAAACLUAoAEDcM3wMAAABgEUoBAOLGG0q1bZu47QAAAACQeIRSAIC4adfOXWfmPQAAACCzcUoAAIib7Gx3neF7AAAAQGbLSfQGAAAyy9Sp0gcfSBdckOgtAQAAAJBIhFIAgLi69FLzBQAAACCzMXwPAAAAAAAAcUcoBQAAAAAAgLgjlAIAAAAAAEDcEUoBAAAAAAAg7gilAAAAAAAAEHeEUgAAAAAAAIg7QikAAAAAAADEHaEUAAAAAAAA4o5QCgAAAAAAAHFHKAUAAAAAAIC4I5QCAAAAAABA3BFKAQAAAAAAIO4IpQAAAAAAABB3hFIAAAAAAACIO0IpAAAAAAAAxB2hFAAAAAAAAOKOUAoAAAAAAABxRygFAAAAAACAuCOUAgAAAAAAQNwRSgEAAAAAACDuchK9AfHmOI4kqaysLMFbkjoqKiq0b98+lZWVKTc3N9GbgxhhP2cm9ntmYX9nBvZzZmK/Zxb2d2Zhf2eedNjnNnOxGUxtMi6U2r17tySpuLg4wVsCAAAAAACQvnbv3q2WLVvWervPqSu2SjPV1dXatGmTmjdvLp/Pl+jNSQllZWUqLi7Wt99+qxYtWiR6cxAj7OfMxH7PLOzvzMB+zkzs98zC/s4s7O/Mkw773HEc7d69Wx07dlRWVu2dozKuUiorK0udO3dO9GakpBYtWqTsGwLhYz9nJvZ7ZmF/Zwb2c2Ziv2cW9ndmYX9nnlTf56EqpCwanQMAAAAAACDuCKUAAAAAAAAQd4RSqFNeXp7uvPNO5eXlJXpTEEPs58zEfs8s7O/MwH7OTOz3zML+zizs78yTSfs84xqdAwAAAAAAIPGolAIAAAAAAEDcEUoBAAAAAAAg7gilAAAAAAAAEHeEUinqvvvu0w9+8AM1b95c7du31znnnKMVK1b43cdxHN11113q2LGj8vPzdeKJJ2rZsmUHb9++fbuuu+469enTR02aNFGXLl10/fXXa9euXQfvs3btWl1xxRXq3r278vPz1bNnT9155506cOBAndu4dOlSDR8+XPn5+erUqZPuueceeVuYlZSU6Ec/+pH69OmjrKws3XDDDQ3/xaSZdNjPc+fOlc/nq/H11VdfReE3lJ7SYb9L0mOPPaa+ffsqPz9fffr00dSpUxv4m0lP8drfknTWWWepS5cuaty4sYqKinTppZdq06ZNdW4jx/OGS4f9zPE8cumw3yWO5+GK5/62ysvL1b9/f/l8Pv3nP/+pcxs5nkdPOuxvjuuRSYd9LiXhMd1BSjrttNOc5557zvniiy+c//znP84ZZ5zhdOnSxdmzZ8/B+9x///1O8+bNnVdffdVZunSpM3bsWKeoqMgpKytzHMdxli5d6px33nnOm2++6Xz99dfOrFmznF69ejnnn3/+wcd46623nAkTJjhvv/22s3r1amfGjBlO+/btnZtvvjnk9u3atcspLCx0LrroImfp0qXOq6++6jRv3tx56KGHDt5nzZo1zvXXX++88MILTv/+/Z1JkyZF95eUBtJhP8+ZM8eR5KxYscIpKSk5+FVZWRnl31b6SIf9PmXKFKd58+bOtGnTnNWrVzsvv/yy06xZM+fNN9+M8m8r9cVrfzuO40yePNn56KOPnLVr1zrz5893Bg8e7AwePDjk9nE8j4502M8czyOXDvud43n44rm/reuvv945/fTTHUnO4sWLQ24fx/PoSof9zXE9Mumwz5PxmE4olSZKS0sdSc6///1vx3Ecp7q62unQoYNz//33H7zP/v37nZYtWzpPPPFErY/zyiuvOI0aNXIqKipqvc+DDz7odO/ePeT2TJkyxWnZsqWzf//+g9fdd999TseOHZ3q6uoa9x8+fDh/9MKQivvZ/rHbsWNHOD8igkjF/T548GDnZz/7md/3TZo0yRkyZEjIx0Z89/eMGTMcn8/nHDhwoNb7cDyPjVTczxzPGy4V9zvH8/qL9f6eOXOmc+ihhzrLli0L64SV43lspeL+5rjeMKm4z5PxmM7wvTRhy/0KCgokSWvWrNHmzZt16qmnHrxPXl6ehg8frg8//DDk47Ro0UI5OTkh72OfpzYfffSRhg8frry8vIPXnXbaadq0aZPWrl0bzo+EIFJ5Px999NEqKirSySefrDlz5oR8XPhLxf1eXl6uxo0b+31ffn6+PvnkE1VUVIR8/EwXr/29fft2/eUvf9Hxxx+v3NzcWh+H43lspPJ+5nhef6m43zme118s9/eWLVt01VVX6cUXX1STJk3C2h6O57GVyvub43r9pOI+T8ZjOqFUGnAcRzfddJOGDh2qI444QpK0efNmSVJhYaHffQsLCw/eFmjbtm2699579ZOf/KTW51q9erUeffRRTZw4MeQ2bd68Oehze7cNkUnV/VxUVKSnnnpKr776ql577TX16dNHJ598st5///2Qjw0jVff7aaedpqefflqLFi2S4zhauHChnn32WVVUVGjr1q0hHz+TxWN/33rrrWratKnatGmj9evXa8aMGSG3ieN59KXqfuZ43jCput85ntdPLPe34ziaMGGCJk6cqGOPPTbsbeJ4Hjupur85rtdfqu7zZDymE0qlgWuvvVZLlizRyy+/XOM2n8/nd9lxnBrXSVJZWZnOOOMMHXbYYbrzzjuDPs+mTZs0atQoXXjhhbryyisPXn/44YerWbNmatasmU4//fSQzx3seoQnVfdznz59dNVVV2nAgAEaPHiwpkyZojPOOEMPPfRQmD95ZkvV/X7HHXfo9NNP16BBg5Sbm6uzzz5bEyZMkCRlZ2eH8ZNnpnjs71tuuUWLFy/WO++8o+zsbI0fP/7g/uN4Hh+pup85njdMqu53juf1E8v9/eijj6qsrEy33XZbrc/P8Ty+UnV/c1yvv1Td58l4TK99DAdSwnXXXac333xT77//vjp37nzw+g4dOkgyiWhRUdHB60tLS2ukp7t379aoUaPUrFkzvf7660HLvDdt2qQRI0Zo8ODBeuqpp/xumzlz5sFSv/z8/IPPH5gGl5aWSqqZHKNu6bafBw0apD//+c91/tyZLpX3e35+vp599lk9+eST2rJly8FP4po3b662bdvW6/eR7uK1v9u2bau2bduqd+/e6tu3r4qLi/Xxxx9r8ODBHM/jIN32M8fz8KTyfud4HrlY7+/Zs2fr448/9huiI0nHHnusLr74Yr3wwgscz+Mo3fY3x/W6pfI+T8pjemxbViFWqqurnWuuucbp2LGjs3LlyqC3d+jQwXnggQcOXldeXl6jydquXbucQYMGOcOHD3f27t0b9Lk2bNjg9OrVy7nooovCnolhypQpTqtWrZzy8vKD191///00UoxQuu1n6/zzz3dGjBgR1nNkonTd78OGDXPGjRsX1nNkknju70Dr1693JDlz5syp9T4cz6Mj3fazxfE8tHTd7xzPg4vX/l63bp2zdOnSg19vv/22I8mZPn268+2339a6fRzPoyvd9rfFcb126brPE31MJ5RKUT/96U+dli1bOnPnzvWbvnPfvn0H73P//fc7LVu2dF577TVn6dKlzrhx4/ymoywrK3MGDhzo9OvXz/n666+DTgO6ceNG55BDDnFOOukkZ8OGDX73CWXnzp1OYWGhM27cOGfp0qXOa6+95rRo0cJvOkrHcZzFixc7ixcvdo455hjnRz/6kbN48WJn2bJlUf5tpa502M+/+93vnNdff91ZuXKl88UXXzi/+MUvHEnOq6++GoPfWHpIh/2+YsUK58UXX3RWrlzpLFiwwBk7dqxTUFDgrFmzJvq/sBQXr/29YMEC59FHH3UWL17srF271pk9e7YzdOhQp2fPnn6ztATieB4d6bCfOZ5HLh32O8fz8MVrfwdas2ZNWDNzcTyPrnTY3xzXI5MO+zwZj+mEUilKUtCv55577uB9qqurnTvvvNPp0KGDk5eX5wwbNsxZunTpwdvtFKDBvuyL8rnnnqv1PnVZsmSJc8IJJzh5eXlOhw4dnLvuuqtGQhvscbt27RqNX1FaSIf9/MADDzg9e/Z0Gjdu7LRu3doZOnSo889//jNqv6N0lA77ffny5U7//v2d/Px8p0WLFs7ZZ5/tfPXVV1H7HaWTeO3vJUuWOCNGjHAKCgqcvLw8p1u3bs7EiROdDRs21LmNHM8bLh32M8fzyKXDfud4Hr547e9A4Z6wOg7H82hKh/3NcT0y6bDPk/GY7nOc/3a+AgAAAAAAAOKE2fcAAAAAAAAQd4RSAAAAAAAAiDtCKQAAAAAAAMQdoRQAAAAAAADijlAKAAAAAAAAcUcoBQAAAAAAgLgjlAIAAAAAAEDcEUoBAAAAAAAg7gilAAAAAAAAEHeEUgAAAHEwYcIE+Xw++Xw+5ebmqrCwUKeccoqeffZZVVdXh/04zz//vFq1ahW7DQUAAIgTQikAAIA4GTVqlEpKSrR27Vq99dZbGjFihCZNmqQxY8aosrIy0ZsHAAAQV4RSAAAAcZKXl6cOHTqoU6dOGjBggG6//XbNmDFDb731lp5//nlJ0uTJk9WvXz81bdpUxcXFuvrqq7Vnzx5J0ty5c3X55Zdr165dB6uu7rrrLknSgQMH9POf/1ydOnVS06ZNNXDgQM2dOzcxPygAAEAYCKUAAAAS6KSTTtJRRx2l1157TZKUlZWlP/zhD/riiy/0wgsvaPbs2fr5z38uSTr++OP1yCOPqEWLFiopKVFJSYl+9rOfSZIuv/xyzZ8/X9OmTdOSJUt04YUXatSoUVq1alXCfjYAAIBQfI7jOIneCAAAgHQ3YcIE7dy5U2+88UaN2y666CItWbJEy5cvr3Hb3/72N/30pz/V1q1bJZmeUjfccIN27tx58D6rV69Wr169tGHDBnXs2PHg9SNHjtRxxx2n3/72t1H/eQAAABoqJ9EbAAAAkOkcx5HP55MkzZkzR7/97W+1fPlylZWVqbKyUvv379fevXvVtGnToN//2WefyXEc9e7d2+/68vJytWnTJubbDwAAUB+EUgAAAAn25Zdfqnv37lq3bp1Gjx6tiRMn6t5771VBQYHmzZunK664QhUVFbV+f3V1tbKzs7Vo0SJlZ2f73dasWbNYbz4AAEC9EEoBAAAk0OzZs7V06VLdeOONWrhwoSorK/Xwww8rK8u0/nzllVf87t+oUSNVVVX5XXf00UerqqpKpaWlOuGEE+K27QAAAA1BKAUAABAn5eXl2rx5s6qqqrRlyxb961//0n333acxY8Zo/PjxWrp0qSorK/Xoo4/qzDPP1Pz58/XEE0/4PUa3bt20Z88ezZo1S0cddZSaNGmi3r176+KLL9b48eP18MMP6+ijj9bWrVs1e/Zs9evXT6NHj07QTwwAAFA7Zt8DAACIk3/9618qKipSt27dNGrUKM2ZM0d/+MMfNGPGDGVnZ6t///6aPHmyHnjgAR1xxBH6y1/+ovvuu8/vMY4//nhNnDhRY8eOVbt27fTggw9Kkp577jmNHz9eN998s/r06aOzzjpLCxYsUHFxcSJ+VAAAgDox+x4AAAAAAADijkopAAAAAAAAxB2hFAAAAAAAAOKOUAoAAAAAAABxRygFAAAAAACAuCOUAgAAAAAAQNwRSgEAAAAAACDuCKUAAAAAAAAQd4RSAAAAAAAAiDtCKQAAAAAAAMQdoRQAAAAAAADijlAKAAAAAAAAcUcoBQAAAAAAgLj7fwPKUCAPcKlEAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "portfolio_0.plot_cumulative_returns()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe Ratio:  0.035397100272720444\n",
      "Mean Return:  0.0003626192731147615\n",
      "Volatility:  0.010244321436528009\n",
      "Annualized Sharpe Ratio:  0.5619115467266094\n"
     ]
    }
   ],
   "source": [
    "print(\"Sharpe Ratio: \", portfolio_0.sharpe)\n",
    "print(\"Mean Return: \", portfolio_0.mean)\n",
    "print(\"Volatility: \", portfolio_0.vol)\n",
    "trading_days_per_year: int = 252\n",
    "print(\"Annualized Sharpe Ratio: \", portfolio_0.sharpe * np.sqrt(trading_days_per_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def compute_annualized_sharpe_ratio(\n",
    "    returns: pd.Series | np.ndarray,\n",
    "    risk_free_rate: float = 0.02,\n",
    "    periods_per_year: int = 52,\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Compute the annualized Sharpe Ratio.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.Series | np.ndarray): Periodic returns of the portfolio.\n",
    "        risk_free_rate (float, optional): Annual risk-free rate (e.g., 0.02 for 2%). Defaults to 0.02.\n",
    "        periods_per_year (int, optional): Number of return periods in a year (e.g., 52 for weekly). Defaults to 52.\n",
    "\n",
    "    Returns:\n",
    "        float: Annualized Sharpe Ratio.\n",
    "    \"\"\"\n",
    "    if isinstance(returns, pd.Series):\n",
    "        returns = returns.dropna().values\n",
    "    else:\n",
    "        returns = np.array(returns)\n",
    "        returns = returns[~np.isnan(returns)]\n",
    "\n",
    "    if len(returns) == 0:\n",
    "        return np.nan\n",
    "\n",
    "    # Calculate excess returns by subtracting the per-period risk-free rate\n",
    "    excess_returns = returns - (risk_free_rate / periods_per_year)\n",
    "\n",
    "    # Calculate mean and standard deviation of excess returns\n",
    "    mean_excess_return = np.mean(excess_returns) * periods_per_year  # Annualize mean\n",
    "    std_excess_return = np.std(excess_returns, ddof=1) * np.sqrt(\n",
    "        periods_per_year\n",
    "    )  # Annualize std\n",
    "\n",
    "    # Compute Sharpe Ratio with numerical stability\n",
    "    sharpe_ratio = mean_excess_return / (\n",
    "        std_excess_return + 1e-18\n",
    "    )  # Add epsilon to prevent division by zero\n",
    "\n",
    "    return sharpe_ratio\n",
    "\n",
    "\n",
    "def analyze_returns(\n",
    "    returns: pd.DataFrame, risk_free_rate: float = 0.02, frequency: int = 52\n",
    ") -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Analyze the returns DataFrame to verify date index, count total weeks,\n",
    "    identify years covered, count weeks per year, and compute Sharpe Ratio per year.\n",
    "\n",
    "    Args:\n",
    "        returns (pd.DataFrame): DataFrame containing portfolio returns with a DatetimeIndex.\n",
    "        risk_free_rate (float, optional): Annual risk-free rate (default is 2%). Defaults to 0.02.\n",
    "        frequency (int, optional): Number of periods per year (default is 52 for weekly data). Defaults to 52.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, Any]: Dictionary containing analysis results.\n",
    "    \"\"\"\n",
    "    analysis_results: Dict[str, Any] = {}\n",
    "\n",
    "    # 1. Verify that the DataFrame is indexed by dates\n",
    "    if not isinstance(returns.index, pd.DatetimeIndex):\n",
    "        raise TypeError(\"The DataFrame index must be a pandas DatetimeIndex.\")\n",
    "    analysis_results[\"DateIndexValid\"] = True\n",
    "\n",
    "    # 2. Count the total number of weeks\n",
    "    total_weeks: int = len(returns)\n",
    "    analysis_results[\"TotalWeeks\"] = total_weeks\n",
    "\n",
    "    # 3. Identify all the years covered in the dataset\n",
    "    years: list[int] = returns.index.year.unique().tolist()\n",
    "    years.sort()  # Sort the years in ascending order\n",
    "    analysis_results[\"YearsCovered\"] = years\n",
    "\n",
    "    # 4. Count the number of weeks for each individual year\n",
    "    weeks_per_year: Dict[int, int] = {}\n",
    "    grouped = returns.groupby(returns.index.year)\n",
    "\n",
    "    for year, group in grouped:\n",
    "        weeks_count = len(group)\n",
    "        weeks_per_year[year] = weeks_count\n",
    "\n",
    "    analysis_results[\"WeeksPerYear\"] = weeks_per_year\n",
    "\n",
    "    # 5. Compute Sharpe Ratio for each year\n",
    "    sharpe_ratios_per_year: Dict[int, float] = {}\n",
    "    for year, group in grouped:\n",
    "        sharpe = compute_annualized_sharpe_ratio(\n",
    "            returns=group[\"rets\"],\n",
    "            risk_free_rate=risk_free_rate,\n",
    "            periods_per_year=analysis_results[\"WeeksPerYear\"][year],\n",
    "        )\n",
    "        sharpe_ratios_per_year[year] = sharpe\n",
    "\n",
    "    analysis_results[\"SharpeRatiosPerYear\"] = sharpe_ratios_per_year\n",
    "\n",
    "    return analysis_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
